{
  "version": "1.0.0",
  "generated_at": "2026-01-05T03:57:29.429Z",
  "total_skills": 44,
  "summaries": {
    "scaffolder": {
      "name": "scaffolder",
      "one_liner": "No description",
      "key_commands": ["/skills", "/scaffolder", "/scripts", "/scaffold", "/test-scaffold"],
      "token_count": {
        "minimal": 10,
        "essential": 326,
        "standard": 1640,
        "full": 5091
      },
      "levels": {
        "minimal": {
          "content": "**scaffolder**: No description available",
          "tokens": 10
        },
        "essential": {
          "content": "## Skill: scaffolder\n\nRule-Aware Scaffolder - Creates new code that automatically adheres to your project's coding standards.\n\n### Key Steps:\n: Load Rule Index\r\n\r\nLoad the rule index to discover relevant rules dynamically:\r\n- @.claude/context/rule-index.json\r\n\r\n\n### Step: Identify Target Framework and Query Index\r\n\r\nDetermine which technologies apply based on what you're scaffolding:\r\n\r\n**Component scaffolding**:\r\n- Detect: React, Next.js, TypeScript\r\n- Query: `index.technology_map['react']`, `index.technology_map['nextjs']`, `index.technology_map['typescript']`\r\n\r\n**API Route scaffolding**:\r\n- Detect: Next.js App Router or FastAPI\r\n- Query: `index.technology_map['nextjs']` or `index.technology_map['fastapi']`\r\n\r\n**Test File scaffolding**:\r\n- Detect: Jest, Cypress, Playwright, Vitest, pytest\r\n- Query: `index.technology_map['jest']`, `index.technology_map['cypress']`, etc.\r\n\r\n**Database Model scaffolding**:\r\n- Detect: Prisma, SQL, database patterns\r\n- Query: `index.technology_map['prisma']` or database-related rules\r\n\r\n\n### Step: Load Relevant Rules\r\n\r\nLoad only the relevant rule files from the index (progressive disclosure):\r\n- Master rules first (from `.claude/rules-master/`)\r\n- Library rules supplement (from `.claude/rules-library/`)\r\n- Load 3-5 most relevant rules, not all 1,081",
          "tokens": 326
        },
        "standard": {
          "content": "## Skill: scaffolder\n\nRule-Aware Scaffolder - Creates new code that automatically adheres to your project's coding standards.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Load Rule Index\r\n\r\nLoad the rule index to discover relevant rules dynamically:\r\n- @.claude/context/rule-index.json\r\n\r\n### Step 2: Identify Target Framework and Query Index\r\n\r\nDetermine which technologies apply based on what you're scaffolding:\r\n\r\n**Component scaffolding**:\r\n- Detect: React, Next.js, TypeScript\r\n- Query: `index.technology_map['react']`, `index.technology_map['nextjs']`, `index.technology_map['typescript']`\r\n\r\n**API Route scaffolding**:\r\n- Detect: Next.js App Router or FastAPI\r\n- Query: `index.technology_map['nextjs']` or `index.technology_map['fastapi']`\r\n\r\n**Test File scaffolding**:\r\n- Detect: Jest, Cypress, Playwright, Vitest, pytest\r\n- Query: `index.technology_map['jest']`, `index.technology_map['cypress']`, etc.\r\n\r\n**Database Model scaffolding**:\r\n- Detect: Prisma, SQL, database patterns\r\n- Query: `index.technology_map['prisma']` or database-related rules\r\n\r\n### Step 3: Load Relevant Rules\r\n\r\nLoad only the relevant rule files from the index (progressive disclosure):\r\n- Master rules first (from `.claude/rules-master/`)\r\n- Library rules supplement (from `.claude/rules-library/`)\r\n- Load 3-5 most relevant rules, not all 1,081\r\n\r\n### Step 4: Extract Patterns from Rules\r\n\r\nParse the loaded rule files to extract scaffolding patterns:\r\n\r\n**From Next.js rules** (TECH_STACK_NEXTJS.md or nextjs.mdc):\r\n- Server Components by default\r\n- 'use client' only when needed\r\n- Place in `app/` for routes, `components/` for shared\r\n- Use lowercase-with-dashes for directories\r\n\r\n**From TypeScript rules**:\r\n- Interfaces for object shapes\r\n- Proper return type annotations\r\n- Avoid `any`, use `unknown`\r\n- PascalCase for types/interfaces\r\n\r\n**From React rules**:\r\n- Functional components only\r\n- Custom hooks for reusable logic\r\n- Props interface for each component\r\n- Error boundaries for critical sections\r\n\r\n### Step 5: Check for Template Blocks\r\n\r\nBefore generating code, check for explicit template blocks in loaded rule files:\r\n\r\n1. **Look for `<template>` blocks** in rule files:\r\n   - Pattern: `<template name=\"component\">...</template>`\r\n   - Pattern: `<template name=\"api\">...</template>`\r\n   - Extract template content and variables (e.g., `{{Name}}`, `{{Props}}`)\r\n\r\n2. **Template Priority**:\r\n   - **First**: Use `<template>` blocks from loaded rule files (most specific)\r\n   - **Second**: Use explicit templates from `.claude/templates/` directory\r\n   - **Third**: Infer patterns from rule text (fallback)\r\n\r\n3. **Template Validation**:\r\n   - Verify template file exists (if using `.claude/templates/`)\r\n   - Check template syntax is valid\r\n   - Ensure required template variables are provided\r\n   - Validate template structure matches expected output type\r\n\r\n### Step 6: Generate Compliant Code\r\n\r\nApply extracted patterns or templates to generate code that passes rule-auditor.\r\n\r\n### Step 7: Validate Generated Code\r\n\r\nAfter generating code, validate it matches the template and rules:\r\n\r\n1. **Template Validation**:\r\n   - Check generated code matches template structure (if template was used)\r\n   - Verify all template variables were replaced\r\n   - Ensure no template placeholders remain (e.g., `{{Name}}`)\r\n\r\n2. **Rule Compliance Validation**:\r\n   - Run rule-auditor on generated code\r\n   - Fix any violations found\r\n   - Ensure generated code follows all loaded rules\r\n\r\n3. **Structure Validation**:\r\n   - Verify file structure matches expected (imports, exports, etc.)\r\n   - Check naming conventions are followed\r\n   - Ensure proper file organization\r\n</execution_process>\r\n\r\n<best_practices>\r\n1. **Always Audit After**: Run `/audit` after scaffolding to catch any edge cases\r\n2. **Customize Templates**: Add project-specific patterns to rules for consistent generation\r\n3. **Use for Consistency**: Scaffold even simple files to maintain team conventions\r\n4. **Review Generated Code**: Scaffolded code is a starting point, not final implementation\r\n5. **Keep Rules Updated**: As patterns evolve, update rules so scaffolder stays current\r\n</best_practices>\r\n\r\n<integration>\r\n### Component Generation Flow\r\n\r\n```\r\n1. User: /scaffold component UserDashboard\r\n2. Scaffolder reads: nextjs.mdc, typescript.mdc, react.mdc\r\n3. Extracts patterns: Server Component, Suspense, interfaces\r\n4. Generates compliant code structure\r\n5. Writes files to correct locations\r\n6. Runs rule-auditor to verify compliance\r\n7. Reports any manual adjustments needed\r\n```\r\n\r\n### Feature Module Generation\r\n\r\nFor larger features, scaffold generates a complete module:\r\n\r\n```\r\n/scaffold feature user-management\r\n\r\nGenerates:\r\napp/\r\n└── (dashboard)/\r\n    └── users/\r\n        ├── page.tsx           # List page\r\n        ├── [id]/\r\n        │   └── page.tsx       # Detail page\r\n        ├── new/\r\n        │   └── page.tsx       # Create page\r\n        └── components/\r\n            ├── user-list.tsx\r\n            ├── user-card.tsx\r\n            └── user-form.tsx\r\ncomponents/\r\n└── users/\r\n    └── ... (shared components)\r\nlib/\r\n└── users/\r\n    ├── api.ts                 # API functions\r\n    ├── types.ts               # Type definitions\r\n    └── validations.ts         # Zod schemas\r\n```\r\n</integration>\n\n### Example:\n**Next.js Server Component**\r\n\r\n**Command**: `/scaffold component UserProfile`\r\n\r\n**Generated**: `components/user-profile/index.tsx`\r\n\r\n```tsx\r\n// Server Component (default per nextjs.mdc)\r\n// Location: components/user-profile/ (lowercase-with-dashes per nextjs.mdc)\r\n\r\nimport { Suspense } from 'react'\r\nimport { UserProfileSkeleton } from './skeleton'\r\nimport { UserProfileContent } from './content'\r\n\r\n// Interface defined (per typescript.mdc)\r\ninterface UserProfileProps {\r\n  userId: string\r\n  showDetails?: boolean\r\n}\r\n\r\n// Async Server Component for data fetching (per nextjs.mdc > Data Fetching)\r\nexport async function UserProfile({ userId, showDetails = false }: UserProfileProps) {\r\n  return (\r\n    // Suspense boundary (per nextjs.mdc > Components)\r\n    <Suspense fallback={<UserProfileSkeleton />}>\r\n      <UserProfileContent userId={userId} showDetails={showDetails} />\r\n    </Suspense>\r\n  )\r\n}\r\n\r\n// Default export for dynamic imports (per nextjs.mdc)\r\nexport default UserProfile\r\n```\r\n\r\n**Also generates**:\r\n- `components/user-profile/content.tsx` - Async content component\r\n- `components/user-profile/skeleton.tsx` - Loading skeleton\r\n- `components/user-profile/types.ts` - Shared types\r\n- `components/user-profile/index.ts` - Barrel export",
          "tokens": 1640
        },
        "full": {
          "content": "---\r\nname: scaffolder\r\ndescription: Generates boilerplate code following loaded rules. Creates new components, modules, APIs, and features that automatically comply with your coding standards. Extracts patterns from rules and applies them consistently.\r\nallowed-tools: read, write, glob, search, codebase_search\r\nversion: 2.1\r\nexecutable: .claude/skills/scaffolder/scripts/scaffold.mjs\r\ntest_suite: .claude/skills/scaffolder/scripts/test-scaffold.mjs\r\nbest_practices:\r\n  - Identify target framework from manifest.yaml\r\n  - Extract patterns from relevant rule files\r\n  - Generate complete file structure (types, tests, etc.)\r\n  - Follow project naming conventions\r\n  - Include proper imports and exports\r\n  - Use executable script for programmatic invocation\r\nerror_handling: graceful\r\nstreaming: supported\r\ntemplates: [component, client-component, api, fastapi-route, test, hook, context, feature]\r\n---\r\n\r\n<identity>\r\nRule-Aware Scaffolder - Creates new code that automatically adheres to your project's coding standards.\r\n</identity>\r\n\r\n<capabilities>\r\n- Creating new React/Vue/Angular components\r\n- Adding new API endpoints or routes\r\n- Setting up new modules or packages\r\n- Generating test files for existing code\r\n- Creating data models or database schemas\r\n- Bootstrapping feature directories\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Load Rule Index\r\n\r\nLoad the rule index to discover relevant rules dynamically:\r\n- @.claude/context/rule-index.json\r\n\r\n### Step 2: Identify Target Framework and Query Index\r\n\r\nDetermine which technologies apply based on what you're scaffolding:\r\n\r\n**Component scaffolding**:\r\n- Detect: React, Next.js, TypeScript\r\n- Query: `index.technology_map['react']`, `index.technology_map['nextjs']`, `index.technology_map['typescript']`\r\n\r\n**API Route scaffolding**:\r\n- Detect: Next.js App Router or FastAPI\r\n- Query: `index.technology_map['nextjs']` or `index.technology_map['fastapi']`\r\n\r\n**Test File scaffolding**:\r\n- Detect: Jest, Cypress, Playwright, Vitest, pytest\r\n- Query: `index.technology_map['jest']`, `index.technology_map['cypress']`, etc.\r\n\r\n**Database Model scaffolding**:\r\n- Detect: Prisma, SQL, database patterns\r\n- Query: `index.technology_map['prisma']` or database-related rules\r\n\r\n### Step 3: Load Relevant Rules\r\n\r\nLoad only the relevant rule files from the index (progressive disclosure):\r\n- Master rules first (from `.claude/rules-master/`)\r\n- Library rules supplement (from `.claude/rules-library/`)\r\n- Load 3-5 most relevant rules, not all 1,081\r\n\r\n### Step 4: Extract Patterns from Rules\r\n\r\nParse the loaded rule files to extract scaffolding patterns:\r\n\r\n**From Next.js rules** (TECH_STACK_NEXTJS.md or nextjs.mdc):\r\n- Server Components by default\r\n- 'use client' only when needed\r\n- Place in `app/` for routes, `components/` for shared\r\n- Use lowercase-with-dashes for directories\r\n\r\n**From TypeScript rules**:\r\n- Interfaces for object shapes\r\n- Proper return type annotations\r\n- Avoid `any`, use `unknown`\r\n- PascalCase for types/interfaces\r\n\r\n**From React rules**:\r\n- Functional components only\r\n- Custom hooks for reusable logic\r\n- Props interface for each component\r\n- Error boundaries for critical sections\r\n\r\n### Step 5: Check for Template Blocks\r\n\r\nBefore generating code, check for explicit template blocks in loaded rule files:\r\n\r\n1. **Look for `<template>` blocks** in rule files:\r\n   - Pattern: `<template name=\"component\">...</template>`\r\n   - Pattern: `<template name=\"api\">...</template>`\r\n   - Extract template content and variables (e.g., `{{Name}}`, `{{Props}}`)\r\n\r\n2. **Template Priority**:\r\n   - **First**: Use `<template>` blocks from loaded rule files (most specific)\r\n   - **Second**: Use explicit templates from `.claude/templates/` directory\r\n   - **Third**: Infer patterns from rule text (fallback)\r\n\r\n3. **Template Validation**:\r\n   - Verify template file exists (if using `.claude/templates/`)\r\n   - Check template syntax is valid\r\n   - Ensure required template variables are provided\r\n   - Validate template structure matches expected output type\r\n\r\n### Step 6: Generate Compliant Code\r\n\r\nApply extracted patterns or templates to generate code that passes rule-auditor.\r\n\r\n### Step 7: Validate Generated Code\r\n\r\nAfter generating code, validate it matches the template and rules:\r\n\r\n1. **Template Validation**:\r\n   - Check generated code matches template structure (if template was used)\r\n   - Verify all template variables were replaced\r\n   - Ensure no template placeholders remain (e.g., `{{Name}}`)\r\n\r\n2. **Rule Compliance Validation**:\r\n   - Run rule-auditor on generated code\r\n   - Fix any violations found\r\n   - Ensure generated code follows all loaded rules\r\n\r\n3. **Structure Validation**:\r\n   - Verify file structure matches expected (imports, exports, etc.)\r\n   - Check naming conventions are followed\r\n   - Ensure proper file organization\r\n</execution_process>\r\n\r\n<best_practices>\r\n1. **Always Audit After**: Run `/audit` after scaffolding to catch any edge cases\r\n2. **Customize Templates**: Add project-specific patterns to rules for consistent generation\r\n3. **Use for Consistency**: Scaffold even simple files to maintain team conventions\r\n4. **Review Generated Code**: Scaffolded code is a starting point, not final implementation\r\n5. **Keep Rules Updated**: As patterns evolve, update rules so scaffolder stays current\r\n</best_practices>\r\n\r\n<integration>\r\n### Component Generation Flow\r\n\r\n```\r\n1. User: /scaffold component UserDashboard\r\n2. Scaffolder reads: nextjs.mdc, typescript.mdc, react.mdc\r\n3. Extracts patterns: Server Component, Suspense, interfaces\r\n4. Generates compliant code structure\r\n5. Writes files to correct locations\r\n6. Runs rule-auditor to verify compliance\r\n7. Reports any manual adjustments needed\r\n```\r\n\r\n### Feature Module Generation\r\n\r\nFor larger features, scaffold generates a complete module:\r\n\r\n```\r\n/scaffold feature user-management\r\n\r\nGenerates:\r\napp/\r\n└── (dashboard)/\r\n    └── users/\r\n        ├── page.tsx           # List page\r\n        ├── [id]/\r\n        │   └── page.tsx       # Detail page\r\n        ├── new/\r\n        │   └── page.tsx       # Create page\r\n        └── components/\r\n            ├── user-list.tsx\r\n            ├── user-card.tsx\r\n            └── user-form.tsx\r\ncomponents/\r\n└── users/\r\n    └── ... (shared components)\r\nlib/\r\n└── users/\r\n    ├── api.ts                 # API functions\r\n    ├── types.ts               # Type definitions\r\n    └── validations.ts         # Zod schemas\r\n```\r\n</integration>\r\n</instructions>\r\n\r\n<examples>\r\n<code_example>\r\n**Next.js Server Component**\r\n\r\n**Command**: `/scaffold component UserProfile`\r\n\r\n**Generated**: `components/user-profile/index.tsx`\r\n\r\n```tsx\r\n// Server Component (default per nextjs.mdc)\r\n// Location: components/user-profile/ (lowercase-with-dashes per nextjs.mdc)\r\n\r\nimport { Suspense } from 'react'\r\nimport { UserProfileSkeleton } from './skeleton'\r\nimport { UserProfileContent } from './content'\r\n\r\n// Interface defined (per typescript.mdc)\r\ninterface UserProfileProps {\r\n  userId: string\r\n  showDetails?: boolean\r\n}\r\n\r\n// Async Server Component for data fetching (per nextjs.mdc > Data Fetching)\r\nexport async function UserProfile({ userId, showDetails = false }: UserProfileProps) {\r\n  return (\r\n    // Suspense boundary (per nextjs.mdc > Components)\r\n    <Suspense fallback={<UserProfileSkeleton />}>\r\n      <UserProfileContent userId={userId} showDetails={showDetails} />\r\n    </Suspense>\r\n  )\r\n}\r\n\r\n// Default export for dynamic imports (per nextjs.mdc)\r\nexport default UserProfile\r\n```\r\n\r\n**Also generates**:\r\n- `components/user-profile/content.tsx` - Async content component\r\n- `components/user-profile/skeleton.tsx` - Loading skeleton\r\n- `components/user-profile/types.ts` - Shared types\r\n- `components/user-profile/index.ts` - Barrel export\r\n</code_example>\r\n\r\n<code_example>\r\n**Next.js Client Component**\r\n\r\n**Command**: `/scaffold client-component SearchBar`\r\n\r\n**Generated**: `components/search-bar/index.tsx`\r\n\r\n```tsx\r\n'use client'  // Required for useState (per nextjs.mdc > Components)\r\n\r\nimport { useState, useCallback } from 'react'\r\nimport { useDebounce } from '@/hooks/use-debounce'\r\n\r\n// Props interface (per typescript.mdc)\r\ninterface SearchBarProps {\r\n  onSearch: (query: string) => void\r\n  placeholder?: string\r\n  debounceMs?: number\r\n}\r\n\r\n// Functional component (per react.mdc)\r\nexport function SearchBar({\r\n  onSearch,\r\n  placeholder = 'Search...',\r\n  debounceMs = 300,\r\n}: SearchBarProps) {\r\n  // Minimal client state (per nextjs.mdc > State Management)\r\n  const [query, setQuery] = useState('')\r\n\r\n  // Debounced callback (per nextjs.mdc > Performance)\r\n  const debouncedSearch = useDebounce(onSearch, debounceMs)\r\n\r\n  const handleChange = useCallback((e: React.ChangeEvent<HTMLInputElement>) => {\r\n    const value = e.target.value\r\n    setQuery(value)\r\n    debouncedSearch(value)\r\n  }, [debouncedSearch])\r\n\r\n  return (\r\n    <input\r\n      type=\"search\"\r\n      value={query}\r\n      onChange={handleChange}\r\n      placeholder={placeholder}\r\n      className=\"w-full px-4 py-2 border rounded-lg\"  // Tailwind (per tailwind.mdc)\r\n      aria-label={placeholder}  // Accessibility\r\n    />\r\n  )\r\n}\r\n\r\nexport default SearchBar\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Next.js API Route (App Router)**\r\n\r\n**Command**: `/scaffold api users`\r\n\r\n**Generated**: `app/api/users/route.ts`\r\n\r\n```tsx\r\nimport { NextRequest, NextResponse } from 'next/server'\r\nimport { z } from 'zod'  // Zod for validation (per nextjs.mdc > Forms and Validation)\r\n\r\n// Request schema (per typescript.mdc > Type System)\r\nconst CreateUserSchema = z.object({\r\n  email: z.string().email(),\r\n  name: z.string().min(2),\r\n})\r\n\r\n// Response type (per typescript.mdc)\r\ninterface UserResponse {\r\n  id: string\r\n  email: string\r\n  name: string\r\n  createdAt: string\r\n}\r\n\r\n// GET handler (per nextjs.mdc > Routing)\r\nexport async function GET(request: NextRequest) {\r\n  try {\r\n    const { searchParams } = new URL(request.url)\r\n    const page = parseInt(searchParams.get('page') ?? '1')\r\n    const limit = parseInt(searchParams.get('limit') ?? '10')\r\n\r\n    // TODO: Replace with actual database query\r\n    const users: UserResponse[] = []\r\n\r\n    return NextResponse.json({\r\n      data: users,\r\n      pagination: { page, limit, total: 0 },\r\n    })\r\n  } catch (error) {\r\n    // Proper error handling (per nextjs.mdc > Data Fetching)\r\n    console.error('Failed to fetch users:', error)\r\n    return NextResponse.json(\r\n      { error: 'Failed to fetch users' },\r\n      { status: 500 }\r\n    )\r\n  }\r\n}\r\n\r\n// POST handler with validation\r\nexport async function POST(request: NextRequest) {\r\n  try {\r\n    const body = await request.json()\r\n\r\n    // Server-side validation (per nextjs.mdc > Forms and Validation)\r\n    const validated = CreateUserSchema.parse(body)\r\n\r\n    // TODO: Replace with actual database insert\r\n    const user: UserResponse = {\r\n      id: crypto.randomUUID(),\r\n      ...validated,\r\n      createdAt: new Date().toISOString(),\r\n    }\r\n\r\n    return NextResponse.json({ data: user }, { status: 201 })\r\n  } catch (error) {\r\n    if (error instanceof z.ZodError) {\r\n      return NextResponse.json(\r\n        { error: 'Validation failed', details: error.errors },\r\n        { status: 400 }\r\n      )\r\n    }\r\n    console.error('Failed to create user:', error)\r\n    return NextResponse.json(\r\n      { error: 'Failed to create user' },\r\n      { status: 500 }\r\n    )\r\n  }\r\n}\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**FastAPI Endpoint**\r\n\r\n**Command**: `/scaffold fastapi-route users`\r\n\r\n**Generated**: `app/routers/users.py`\r\n\r\n```python\r\n\"\"\"User management endpoints.\"\"\"\r\n# Type hints required (per python.mdc)\r\nfrom typing import Annotated\r\nfrom uuid import UUID\r\n\r\nfrom fastapi import APIRouter, Depends, HTTPException, Query, status\r\nfrom pydantic import BaseModel, EmailStr, Field\r\n\r\n# Router with tags (per fastapi.mdc > API Design)\r\nrouter = APIRouter(prefix=\"/users\", tags=[\"users\"])\r\n\r\n\r\n# Pydantic models (per fastapi.mdc > Components and Validation)\r\nclass UserCreate(BaseModel):\r\n    \"\"\"Schema for creating a user.\"\"\"\r\n    email: EmailStr\r\n    name: str = Field(..., min_length=2, max_length=100)\r\n\r\n\r\nclass UserResponse(BaseModel):\r\n    \"\"\"Schema for user response.\"\"\"\r\n    id: UUID\r\n    email: EmailStr\r\n    name: str\r\n    created_at: str\r\n\r\n    class Config:\r\n        from_attributes = True\r\n\r\n\r\nclass PaginatedResponse(BaseModel):\r\n    \"\"\"Paginated response wrapper.\"\"\"\r\n    data: list[UserResponse]\r\n    total: int\r\n    page: int\r\n    limit: int\r\n\r\n\r\n# Dependency injection (per fastapi.mdc > Dependency Injection)\r\nasync def get_db():\r\n    \"\"\"Database session dependency.\"\"\"\r\n    # TODO: Replace with actual database session\r\n    yield None\r\n\r\n\r\n# GET endpoint with pagination (per fastapi.mdc > Performance)\r\n@router.get(\"\", response_model=PaginatedResponse)\r\nasync def list_users(\r\n    db: Annotated[None, Depends(get_db)],\r\n    page: Annotated[int, Query(ge=1)] = 1,\r\n    limit: Annotated[int, Query(ge=1, le=100)] = 10,\r\n) -> PaginatedResponse:\r\n    \"\"\"\r\n    List all users with pagination.\r\n\r\n    - **page**: Page number (starting from 1)\r\n    - **limit**: Items per page (max 100)\r\n    \"\"\"\r\n    # TODO: Replace with actual database query\r\n    users: list[UserResponse] = []\r\n    total = 0\r\n\r\n    return PaginatedResponse(data=users, total=total, page=page, limit=limit)\r\n\r\n\r\n# POST endpoint with validation\r\n@router.post(\"\", response_model=UserResponse, status_code=status.HTTP_201_CREATED)\r\nasync def create_user(\r\n    user_data: UserCreate,\r\n    db: Annotated[None, Depends(get_db)],\r\n) -> UserResponse:\r\n    \"\"\"\r\n    Create a new user.\r\n\r\n    - **email**: Valid email address\r\n    - **name**: User's display name (2-100 chars)\r\n    \"\"\"\r\n    # TODO: Replace with actual database insert\r\n    # Check for existing user, create, return\r\n\r\n    raise HTTPException(\r\n        status_code=status.HTTP_501_NOT_IMPLEMENTED,\r\n        detail=\"Database integration pending\",\r\n    )\r\n\r\n\r\n# GET by ID endpoint\r\n@router.get(\"/{user_id}\", response_model=UserResponse)\r\nasync def get_user(\r\n    user_id: UUID,\r\n    db: Annotated[None, Depends(get_db)],\r\n) -> UserResponse:\r\n    \"\"\"Get a specific user by ID.\"\"\"\r\n    # TODO: Replace with actual database query\r\n    raise HTTPException(\r\n        status_code=status.HTTP_404_NOT_FOUND,\r\n        detail=f\"User {user_id} not found\",\r\n    )\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Test File (Vitest/Jest)**\r\n\r\n**Command**: `/scaffold test components/user-profile`\r\n\r\n**Generated**: `components/user-profile/__tests__/index.test.tsx`\r\n\r\n```tsx\r\n// Test file (per jest-*.mdc / vitest-*.mdc patterns)\r\nimport { render, screen, waitFor } from '@testing-library/react'\r\nimport { describe, it, expect, vi, beforeEach } from 'vitest'\r\nimport { UserProfile } from '../index'\r\n\r\n// Mock external dependencies (per testing best practices)\r\nvi.mock('@/lib/api', () => ({\r\n  fetchUser: vi.fn(),\r\n}))\r\n\r\ndescribe('UserProfile', () => {\r\n  // Clear mocks before each test (per clean-code.mdc)\r\n  beforeEach(() => {\r\n    vi.clearAllMocks()\r\n  })\r\n\r\n  // Descriptive test names (per testing guidelines)\r\n  it('renders loading skeleton initially', () => {\r\n    render(<UserProfile userId=\"123\" />)\r\n\r\n    expect(screen.getByTestId('user-profile-skeleton')).toBeInTheDocument()\r\n  })\r\n\r\n  it('displays user information after loading', async () => {\r\n    const mockUser = {\r\n      id: '123',\r\n      name: 'John Doe',\r\n      email: 'john@example.com',\r\n    }\r\n\r\n    const { fetchUser } = await import('@/lib/api')\r\n    vi.mocked(fetchUser).mockResolvedValue(mockUser)\r\n\r\n    render(<UserProfile userId=\"123\" />)\r\n\r\n    await waitFor(() => {\r\n      expect(screen.getByText('John Doe')).toBeInTheDocument()\r\n      expect(screen.getByText('john@example.com')).toBeInTheDocument()\r\n    })\r\n  })\r\n\r\n  it('handles error state gracefully', async () => {\r\n    const { fetchUser } = await import('@/lib/api')\r\n    vi.mocked(fetchUser).mockRejectedValue(new Error('Network error'))\r\n\r\n    render(<UserProfile userId=\"123\" />)\r\n\r\n    await waitFor(() => {\r\n      expect(screen.getByText(/failed to load/i)).toBeInTheDocument()\r\n    })\r\n  })\r\n\r\n  // Edge cases (per qa best practices)\r\n  it('shows details when showDetails prop is true', async () => {\r\n    render(<UserProfile userId=\"123\" showDetails />)\r\n\r\n    await waitFor(() => {\r\n      expect(screen.getByTestId('user-details-section')).toBeInTheDocument()\r\n    })\r\n  })\r\n})\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Cypress E2E Test**\r\n\r\n**Command**: `/scaffold e2e-test user-flow`\r\n\r\n**Generated**: `cypress/e2e/user-flow.cy.ts`\r\n\r\n```typescript\r\n// E2E test (per cypress-e2e-testing-*.mdc)\r\ndescribe('User Flow', () => {\r\n  // Setup before tests (per cypress best practices)\r\n  beforeEach(() => {\r\n    // Reset state and seed data\r\n    cy.task('db:seed')\r\n    cy.visit('/')\r\n  })\r\n\r\n  // Critical user flow (per cypress-e2e-testing guidelines)\r\n  it('allows user to sign up, login, and view profile', () => {\r\n    // Use data-testid selectors (per cypress best practices)\r\n    cy.get('[data-testid=\"signup-link\"]').click()\r\n\r\n    // Fill signup form\r\n    cy.get('[data-testid=\"email-input\"]').type('test@example.com')\r\n    cy.get('[data-testid=\"password-input\"]').type('SecurePass123!')\r\n    cy.get('[data-testid=\"name-input\"]').type('Test User')\r\n    cy.get('[data-testid=\"signup-submit\"]').click()\r\n\r\n    // Verify redirect to dashboard\r\n    cy.url().should('include', '/dashboard')\r\n\r\n    // Navigate to profile\r\n    cy.get('[data-testid=\"profile-link\"]').click()\r\n\r\n    // Verify profile data\r\n    cy.get('[data-testid=\"profile-name\"]').should('contain', 'Test User')\r\n    cy.get('[data-testid=\"profile-email\"]').should('contain', 'test@example.com')\r\n  })\r\n\r\n  // API mocking example (per cypress-api-testing guidelines)\r\n  it('handles API errors gracefully', () => {\r\n    // Mock API failure\r\n    cy.intercept('GET', '/api/users/*', {\r\n      statusCode: 500,\r\n      body: { error: 'Internal server error' },\r\n    }).as('getUserError')\r\n\r\n    cy.visit('/profile')\r\n\r\n    // Wait for mocked request\r\n    cy.wait('@getUserError')\r\n\r\n    // Verify error handling\r\n    cy.get('[data-testid=\"error-message\"]')\r\n      .should('be.visible')\r\n      .and('contain', 'Failed to load profile')\r\n\r\n    // Verify retry option\r\n    cy.get('[data-testid=\"retry-button\"]').should('be.visible')\r\n  })\r\n})\r\n```\r\n</code_example>\r\n\r\n<usage_example>\r\n**Programmatic Usage** (recommended for automation):\r\n\r\n```bash\r\n# Using executable script directly\r\nnode .claude/skills/scaffolder/scripts/scaffold.mjs component UserProfile\r\nnode .claude/skills/scaffolder/scripts/scaffold.mjs client-component SearchBar --path src/components\r\nnode .claude/skills/scaffolder/scripts/scaffold.mjs api users\r\nnode .claude/skills/scaffolder/scripts/scaffold.mjs test src/components/Button.tsx\r\n\r\n# List available templates\r\nnode .claude/skills/scaffolder/scripts/scaffold.mjs --list\r\n\r\n# Run tests\r\nnode .claude/skills/scaffolder/scripts/test-scaffold.mjs\r\n```\r\n\r\n**Quick Commands** (agent invocation):\r\n\r\n```\r\n# Generate a Server Component\r\n/scaffold component MyComponent\r\n\r\n# Generate a Client Component\r\n/scaffold client-component MyInteractiveWidget\r\n\r\n# Generate an API route\r\n/scaffold api resource-name\r\n\r\n# Generate a FastAPI router\r\n/scaffold fastapi-route resource-name\r\n\r\n# Generate test for existing file\r\n/scaffold test path/to/component\r\n\r\n# Generate E2E test\r\n/scaffold e2e-test flow-name\r\n\r\n# Generate with specific rules\r\n/scaffold component MyComponent --rules nextjs,typescript\r\n\r\n# Generate in specific location\r\n/scaffold component MyComponent --path src/features/auth\r\n\r\n# List available scaffold templates\r\n/scaffold --list\r\n```\r\n\r\n**Available Templates**:\r\n\r\n| Template | Framework | Files Generated |\r\n|----------|-----------|-----------------|\r\n| `component` | Next.js/React | index.tsx, types.ts, skeleton.tsx |\r\n| `client-component` | Next.js | index.tsx with 'use client' |\r\n| `page` | Next.js App Router | page.tsx, loading.tsx, error.tsx |\r\n| `api` | Next.js App Router | route.ts with handlers |\r\n| `fastapi-route` | FastAPI | router file with endpoints |\r\n| `hook` | React | Custom hook with types |\r\n| `context` | React | Context provider + hook |\r\n| `test` | Jest/Vitest | Test file for component |\r\n| `e2e-test` | Cypress/Playwright | E2E test spec |\r\n| `model` | Prisma | Schema model |\r\n| `migration` | Database | Migration file |\r\n</usage_example>\r\n</examples>\r\n",
          "tokens": 5091
        }
      }
    },
    "claude-md-generator": {
      "name": "claude-md-generator",
      "one_liner": "No description",
      "key_commands": [
        "/modules",
        "/identity",
        "/capabilities",
        "/templates",
        "/claude-md-template"
      ],
      "token_count": {
        "minimal": 13,
        "essential": 262,
        "standard": 1041,
        "full": 1994
      },
      "levels": {
        "minimal": {
          "content": "**claude-md-generator**: No description available",
          "tokens": 13
        },
        "essential": {
          "content": "## Skill: claude-md-generator\n\nclaude.md Generator Skill - Automatically generates claude.md files for new folders/modules that enable Claude Code to understand module-specific rules, patterns, and conventions.\n\n### Key Steps:\n: Identify Target Location\r\n\r\nDetermine where claude.md should be created:\r\n- Check if target directory exists\r\n- Identify parent directory and its claude.md (if exists)\r\n- Understand module purpose from directory structure\r\n- Check for existing claude.md in target directory\r\n\r\n\n### Step: Extract Context from Code\r\n\r\nAnalyze existing code to understand module:\r\n- Read key files in target directory (index files, main components, etc.)\r\n- Identify patterns and conventions used\r\n- Extract dependencies and relationships\r\n- Understand module responsibilities\r\n- Note any special rules or guidelines\r\n\r\n\n### Step: Load Template\r\n\r\nLoad claude.md template from `.claude/templates/claude-md-template.md`:\r\n- Use template as base structure\r\n- Customize sections based on module type\r\n- Include module-specific information",
          "tokens": 262
        },
        "standard": {
          "content": "## Skill: claude-md-generator\n\nclaude.md Generator Skill - Automatically generates claude.md files for new folders/modules that enable Claude Code to understand module-specific rules, patterns, and conventions.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Identify Target Location\r\n\r\nDetermine where claude.md should be created:\r\n- Check if target directory exists\r\n- Identify parent directory and its claude.md (if exists)\r\n- Understand module purpose from directory structure\r\n- Check for existing claude.md in target directory\r\n\r\n### Step 2: Extract Context from Code\r\n\r\nAnalyze existing code to understand module:\r\n- Read key files in target directory (index files, main components, etc.)\r\n- Identify patterns and conventions used\r\n- Extract dependencies and relationships\r\n- Understand module responsibilities\r\n- Note any special rules or guidelines\r\n\r\n### Step 3: Load Template\r\n\r\nLoad claude.md template from `.claude/templates/claude-md-template.md`:\r\n- Use template as base structure\r\n- Customize sections based on module type\r\n- Include module-specific information\r\n\r\n### Step 4: Generate claude.md Content\r\n\r\nCreate claude.md following this structure:\r\n\r\n```markdown\r\n# [Module/Feature Name]\r\n\r\n## Purpose\r\n[What this module/feature does - extracted from code analysis]\r\n\r\n## Key Patterns\r\n[Important patterns and conventions found in code]\r\n\r\n## Rules & Guidelines\r\n[Module-specific rules and guidelines]\r\n\r\n## Dependencies\r\n[Key dependencies and relationships]\r\n\r\n## Usage Examples\r\n[How to use this module/feature - from code examples]\r\n```\r\n\r\n### Step 5: Inherit from Parent\r\n\r\nIf parent directory has claude.md:\r\n- Reference parent claude.md for inherited rules\r\n- Add module-specific overrides\r\n- Maintain consistency with parent guidelines\r\n\r\n### Step 6: Validate Generated File\r\n\r\nEnsure generated claude.md:\r\n- Follows template structure\r\n- Has all required sections\r\n- Uses consistent formatting\r\n- Has valid markdown syntax\r\n- References parent claude.md if applicable\r\n</execution_process>\r\n\r\n<integration>\r\n**Integration with Developer Agent**:\r\nWhen Developer agent creates new modules:\r\n1. Developer creates module structure\r\n2. Developer invokes claude-md-generator: \"Generate claude.md for [path]\"\r\n3. Skill analyzes code and generates claude.md\r\n4. Developer reviews and customizes as needed\r\n\r\n**Integration with Technical Writer Agent**:\r\nTechnical Writer agent can:\r\n- Automatically generate claude.md for new modules\r\n- Update existing claude.md files\r\n- Validate claude.md files exist where required\r\n- Ensure consistency across claude.md files\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Extract from Code**: Always analyze existing code before generating\r\n2. **Follow Hierarchy**: Reference parent claude.md for inheritance\r\n3. **Be Specific**: Include module-specific patterns and rules\r\n4. **Keep Updated**: Update claude.md as module evolves\r\n5. **Validate Structure**: Ensure generated file follows template\r\n</best_practices>\n\n### Example:\n**Module claude.md**\r\n\r\n**Command**: \"Generate claude.md for src/modules/auth\"\r\n\r\n**Generated**: `src/modules/auth/CLAUDE.md`\r\n\r\n```markdown\r\n# Authentication Module\r\n\r\n## Purpose\r\nHandles user authentication, authorization, and session management. Provides JWT-based authentication with refresh token support.\r\n\r\n## Key Patterns\r\n- Use `useAuth()` hook for authentication state\r\n- Protect routes with `withAuth()` HOC\r\n- Use `AuthProvider` for context management\r\n- JWT tokens stored in httpOnly cookies\r\n\r\n## Rules & Guidelines\r\n- Always validate tokens server-side\r\n- Use refresh tokens for long-lived sessions\r\n- Implement proper error handling for auth failures\r\n- Follow OAuth2 best practices\r\n\r\n## Dependencies\r\n- `@/lib/jwt` - JWT token handling\r\n- `@/lib/db` - User database operations\r\n- `@/hooks/use-auth` - Authentication hook\r\n\r\n## Usage Examples\r\n\r\n### Using Authentication Hook\r\n```typescript\r\nimport { useAuth } from '@/modules/auth'\r\n\r\nfunction MyComponent() {\r\n  const { user, login, logout } = useAuth()\r\n  // ...\r\n}\r\n```\r\n\r\n### Protecting Routes\r\n```typescript\r\nimport { withAuth } from '@/modules/auth'\r\n\r\nexport default withAuth(ProtectedPage)\r\n```\r\n```",
          "tokens": 1041
        },
        "full": {
          "content": "---\r\nname: claude-md-generator\r\ndescription: Automatically generates claude.md files for new folders/modules following hierarchical structure. Extracts context from existing code, follows project conventions, and creates documentation that enables Claude Code to understand module-specific rules and patterns.\r\nallowed-tools: read, write, glob, search, codebase_search\r\nversion: 1.0\r\nbest_practices:\r\n  - Extract context from existing code in target directory\r\n  - Follow hierarchical claude.md structure (root → subdirectories)\r\n  - Reference parent claude.md for inheritance\r\n  - Include module-specific rules and patterns\r\n  - Validate generated claude.md structure\r\nerror_handling: graceful\r\nstreaming: supported\r\ntemplates: [module, feature, component, api, service]\r\n---\r\n\r\n<identity>\r\nclaude.md Generator Skill - Automatically generates claude.md files for new folders/modules that enable Claude Code to understand module-specific rules, patterns, and conventions.\r\n</identity>\r\n\r\n<capabilities>\r\n- Creating new modules or feature folders\r\n- Adding new major components or subsystems\r\n- Introducing new APIs or services\r\n- Setting up new directories that need documentation\r\n- Ensuring claude.md exists where required\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Identify Target Location\r\n\r\nDetermine where claude.md should be created:\r\n- Check if target directory exists\r\n- Identify parent directory and its claude.md (if exists)\r\n- Understand module purpose from directory structure\r\n- Check for existing claude.md in target directory\r\n\r\n### Step 2: Extract Context from Code\r\n\r\nAnalyze existing code to understand module:\r\n- Read key files in target directory (index files, main components, etc.)\r\n- Identify patterns and conventions used\r\n- Extract dependencies and relationships\r\n- Understand module responsibilities\r\n- Note any special rules or guidelines\r\n\r\n### Step 3: Load Template\r\n\r\nLoad claude.md template from `.claude/templates/claude-md-template.md`:\r\n- Use template as base structure\r\n- Customize sections based on module type\r\n- Include module-specific information\r\n\r\n### Step 4: Generate claude.md Content\r\n\r\nCreate claude.md following this structure:\r\n\r\n```markdown\r\n# [Module/Feature Name]\r\n\r\n## Purpose\r\n[What this module/feature does - extracted from code analysis]\r\n\r\n## Key Patterns\r\n[Important patterns and conventions found in code]\r\n\r\n## Rules & Guidelines\r\n[Module-specific rules and guidelines]\r\n\r\n## Dependencies\r\n[Key dependencies and relationships]\r\n\r\n## Usage Examples\r\n[How to use this module/feature - from code examples]\r\n```\r\n\r\n### Step 5: Inherit from Parent\r\n\r\nIf parent directory has claude.md:\r\n- Reference parent claude.md for inherited rules\r\n- Add module-specific overrides\r\n- Maintain consistency with parent guidelines\r\n\r\n### Step 6: Validate Generated File\r\n\r\nEnsure generated claude.md:\r\n- Follows template structure\r\n- Has all required sections\r\n- Uses consistent formatting\r\n- Has valid markdown syntax\r\n- References parent claude.md if applicable\r\n</execution_process>\r\n\r\n<integration>\r\n**Integration with Developer Agent**:\r\nWhen Developer agent creates new modules:\r\n1. Developer creates module structure\r\n2. Developer invokes claude-md-generator: \"Generate claude.md for [path]\"\r\n3. Skill analyzes code and generates claude.md\r\n4. Developer reviews and customizes as needed\r\n\r\n**Integration with Technical Writer Agent**:\r\nTechnical Writer agent can:\r\n- Automatically generate claude.md for new modules\r\n- Update existing claude.md files\r\n- Validate claude.md files exist where required\r\n- Ensure consistency across claude.md files\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Extract from Code**: Always analyze existing code before generating\r\n2. **Follow Hierarchy**: Reference parent claude.md for inheritance\r\n3. **Be Specific**: Include module-specific patterns and rules\r\n4. **Keep Updated**: Update claude.md as module evolves\r\n5. **Validate Structure**: Ensure generated file follows template\r\n</best_practices>\r\n</instructions>\r\n\r\n<examples>\r\n<code_example>\r\n**Module claude.md**\r\n\r\n**Command**: \"Generate claude.md for src/modules/auth\"\r\n\r\n**Generated**: `src/modules/auth/CLAUDE.md`\r\n\r\n```markdown\r\n# Authentication Module\r\n\r\n## Purpose\r\nHandles user authentication, authorization, and session management. Provides JWT-based authentication with refresh token support.\r\n\r\n## Key Patterns\r\n- Use `useAuth()` hook for authentication state\r\n- Protect routes with `withAuth()` HOC\r\n- Use `AuthProvider` for context management\r\n- JWT tokens stored in httpOnly cookies\r\n\r\n## Rules & Guidelines\r\n- Always validate tokens server-side\r\n- Use refresh tokens for long-lived sessions\r\n- Implement proper error handling for auth failures\r\n- Follow OAuth2 best practices\r\n\r\n## Dependencies\r\n- `@/lib/jwt` - JWT token handling\r\n- `@/lib/db` - User database operations\r\n- `@/hooks/use-auth` - Authentication hook\r\n\r\n## Usage Examples\r\n\r\n### Using Authentication Hook\r\n```typescript\r\nimport { useAuth } from '@/modules/auth'\r\n\r\nfunction MyComponent() {\r\n  const { user, login, logout } = useAuth()\r\n  // ...\r\n}\r\n```\r\n\r\n### Protecting Routes\r\n```typescript\r\nimport { withAuth } from '@/modules/auth'\r\n\r\nexport default withAuth(ProtectedPage)\r\n```\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Feature claude.md**\r\n\r\n**Command**: \"Generate claude.md for app/features/user-management\"\r\n\r\n**Generated**: `app/features/user-management/CLAUDE.md`\r\n\r\n```markdown\r\n# User Management Feature\r\n\r\n## Purpose\r\nComplete user management feature including CRUD operations, user profiles, and role management.\r\n\r\n## Key Patterns\r\n- Server Components for data fetching\r\n- Client Components for interactive UI\r\n- Zod schemas for validation\r\n- React Hook Form for form handling\r\n\r\n## Rules & Guidelines\r\n- Use Server Components by default\r\n- Add 'use client' only when needed\r\n- Validate all inputs with Zod\r\n- Use optimistic updates for better UX\r\n\r\n## Dependencies\r\n- `@/lib/api` - API client\r\n- `@/components/ui` - UI components\r\n- `@/lib/validations` - Validation schemas\r\n\r\n## Usage Examples\r\n\r\n### Creating a User\r\n```typescript\r\nimport { createUser } from '@/features/user-management/api'\r\n\r\nconst user = await createUser({\r\n  email: 'user@example.com',\r\n  name: 'John Doe'\r\n})\r\n```\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**API Service claude.md**\r\n\r\n**Command**: \"Generate claude.md for app/api/users\"\r\n\r\n**Generated**: `app/api/users/CLAUDE.md`\r\n\r\n```markdown\r\n# Users API\r\n\r\n## Purpose\r\nRESTful API endpoints for user management operations.\r\n\r\n## Key Patterns\r\n- Next.js App Router route handlers\r\n- Zod validation for request bodies\r\n- Proper error handling with status codes\r\n- Type-safe request/response types\r\n\r\n## Rules & Guidelines\r\n- Always validate request bodies\r\n- Use proper HTTP status codes\r\n- Return consistent error format\r\n- Implement rate limiting\r\n- Add authentication middleware\r\n\r\n## Dependencies\r\n- `@/lib/db` - Database operations\r\n- `@/lib/validations` - Validation schemas\r\n- `@/lib/auth` - Authentication\r\n\r\n## Usage Examples\r\n\r\n### GET /api/users\r\n```bash\r\ncurl -X GET http://localhost:3000/api/users?page=1&limit=10\r\n```\r\n\r\n### POST /api/users\r\n```bash\r\ncurl -X POST http://localhost:3000/api/users \\\r\n  -H \"Content-Type: application/json\" \\\r\n  -d '{\"email\": \"user@example.com\", \"name\": \"John Doe\"}'\r\n```\r\n```\r\n</code_example>\r\n\r\n<usage_example>\r\n**Quick Commands**:\r\n\r\n```\r\n# Generate claude.md for a module\r\nGenerate claude.md for src/modules/auth\r\n\r\n# Generate claude.md for a feature\r\nGenerate claude.md for app/features/user-management\r\n\r\n# Generate claude.md for an API\r\nGenerate claude.md for app/api/users\r\n\r\n# Generate with parent reference\r\nGenerate claude.md for src/modules/auth --parent src/modules/CLAUDE.md\r\n```\r\n\r\n**Template Customization**:\r\n\r\nCustomize templates in `.claude/templates/claude-md-template.md`:\r\n- Add project-specific sections\r\n- Include standard patterns\r\n- Define required sections\r\n- Set formatting standards\r\n</usage_example>\r\n</examples>\r\n\r\n",
          "tokens": 1994
        }
      }
    },
    "api-contract-generator": {
      "name": "api-contract-generator",
      "one_liner": "No description",
      "key_commands": ["/Swagger", "/response", "/api", "/users", "/endpoint"],
      "token_count": {
        "minimal": 13,
        "essential": 9,
        "standard": 9,
        "full": 975
      },
      "levels": {
        "minimal": {
          "content": "**api-contract-generator**: No description available",
          "tokens": 13
        },
        "essential": {
          "content": "## Skill: api-contract-generator\n",
          "tokens": 9
        },
        "standard": {
          "content": "## Skill: api-contract-generator\n",
          "tokens": 9
        },
        "full": {
          "content": "---\r\nname: api-contract-generator\r\ndescription: Generates OpenAPI/Swagger schemas for API endpoints. Creates comprehensive API contracts from endpoint implementations, ensuring consistency between code and documentation.\r\nallowed-tools: read, write, grep, codebase_search\r\n---\r\n\r\n# API Contract Generator Skill\r\n\r\nGenerates OpenAPI/Swagger schemas for API endpoints, creating comprehensive API contracts from endpoint implementations.\r\n\r\n## When to Use\r\n\r\n- After creating new API endpoints\r\n- When updating existing endpoints\r\n- To ensure API documentation matches implementation\r\n- To generate client SDKs from contracts\r\n\r\n## Instructions\r\n\r\n### Step 1: Analyze Endpoint Implementation\r\n\r\n1. **Read endpoint code**:\r\n   - Identify route handlers (Next.js App Router, FastAPI, Express, etc.)\r\n   - Extract HTTP methods (GET, POST, PUT, DELETE, etc.)\r\n   - Identify request/response types\r\n\r\n2. **Extract route information**:\r\n   - Path parameters (e.g., `/api/users/{id}`)\r\n   - Query parameters (e.g., `?page=1&limit=10`)\r\n   - Request body structure\r\n   - Response structure\r\n\r\n3. **Identify data models**:\r\n   - Find TypeScript interfaces or Python Pydantic models\r\n   - Extract field types and validation rules\r\n   - Identify nested objects and arrays\r\n\r\n### Step 2: Generate OpenAPI Schema\r\n\r\n1. **Create OpenAPI 3.0 structure**:\r\n   ```yaml\r\n   openapi: 3.0.0\r\n   info:\r\n     title: API Name\r\n     version: 1.0.0\r\n   paths:\r\n     /api/endpoint:\r\n       get:\r\n         summary: Endpoint description\r\n         parameters: [...]\r\n         responses: {...}\r\n   ```\r\n\r\n2. **Map request/response types**:\r\n   - Convert TypeScript interfaces to JSON Schema\r\n   - Convert Pydantic models to JSON Schema\r\n   - Handle nested types and arrays\r\n   - Include validation constraints (min, max, pattern, etc.)\r\n\r\n3. **Add endpoint documentation**:\r\n   - Extract JSDoc/Python docstrings for descriptions\r\n   - Include parameter descriptions\r\n   - Document response codes and error cases\r\n\r\n### Step 3: Validate Schema\r\n\r\n1. **Schema validation**:\r\n   - Verify OpenAPI schema is valid\r\n   - Check all referenced schemas exist\r\n   - Ensure required fields are marked\r\n\r\n2. **Implementation validation**:\r\n   - Verify schema matches actual implementation\r\n   - Check all endpoints are documented\r\n   - Ensure response types match\r\n\r\n### Step 4: Save Contract\r\n\r\n1. **Save OpenAPI schema**:\r\n   - Location: `.claude/context/artifacts/api-contract-{endpoint}.yaml`\r\n   - Or: `docs/api/openapi.yaml` (project convention)\r\n   - Include in artifact registry\r\n\r\n2. **Generate documentation** (optional):\r\n   - Use Swagger UI or Redoc for visualization\r\n   - Generate HTML documentation\r\n   - Include in project docs\r\n\r\n## Supported Frameworks\r\n\r\n- **Next.js App Router**: Analyzes `app/api/**/route.ts` files\r\n- **FastAPI**: Analyzes Pydantic models and route decorators\r\n- **Express**: Analyzes route handlers and middleware\r\n- **Django REST Framework**: Analyzes serializers and viewsets\r\n\r\n## Example Output\r\n\r\n```yaml\r\nopenapi: 3.0.0\r\ninfo:\r\n  title: User API\r\n  version: 1.0.0\r\npaths:\r\n  /api/users/{id}:\r\n    get:\r\n      summary: Get user by ID\r\n      parameters:\r\n        - name: id\r\n          in: path\r\n          required: true\r\n          schema:\r\n            type: string\r\n      responses:\r\n        '200':\r\n          description: User found\r\n          content:\r\n            application/json:\r\n              schema:\r\n                $ref: '#/components/schemas/User'\r\n        '404':\r\n          description: User not found\r\ncomponents:\r\n  schemas:\r\n    User:\r\n      type: object\r\n      properties:\r\n        id:\r\n          type: string\r\n        name:\r\n          type: string\r\n        email:\r\n          type: string\r\n          format: email\r\n```\r\n\r\n## Related Documentation\r\n\r\n- [CUJ-010](../../docs/cujs/CUJ-010.md) - API Endpoint Development\r\n- [OpenAPI Specification](https://swagger.io/specification/)\r\n\r\n",
          "tokens": 975
        }
      }
    },
    "rule-auditor": {
      "name": "rule-auditor",
      "one_liner": "No description",
      "key_commands": ["/audit", "/skills", "/rule-auditor", "/scripts", "/components"],
      "token_count": {
        "minimal": 11,
        "essential": 380,
        "standard": 3430,
        "full": 6415
      },
      "levels": {
        "minimal": {
          "content": "**rule-auditor**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: rule-auditor\n\nRule Auditor - Automatically validates code against your project's coding standards and rules.\n\n### Key Steps:\n: Load Rule Index\r\n\r\nLoad the rule index to discover all available rules dynamically:\r\n- @.claude/context/rule-index.json\r\n\r\nThe index contains metadata for all 1,081+ rules in `.claude/rules-master/` and `.claude/rules-library/` (formerly archive).\r\n\r\n\n### Step: Filter Relevant Rules\r\n\r\nQuery the index's `technology_map` based on target files:\r\n\r\n1. **Detect technologies** from target files:\r\n   - File extension (`.tsx` → TypeScript, React)\r\n   - Import statements (`next` → Next.js, `react` → React)\r\n   - Directory structure (`app/` → Next.js App Router)\r\n\r\n2. **Query technology_map**:\r\n   ```javascript\r\n   // Pseudocode\r\n   const detectedTech = ['nextjs', 'react', 'typescript'];\r\n   const relevantRules = [];\r\n   \r\n   detectedTech.forEach(tech => {\r\n     const rules = index.technology_map[tech] || [];\r\n     relevantRules.push(...rules);\r\n   });\r\n   ```\r\n\r\n3. **Load only relevant rule files** (progressive disclosure):\r\n   - Master rules take priority (from `.claude/rules-master/`)\r\n   - Library rules supplement (from `.claude/rules-library/`, formerly archive)\r\n   - Load 5-10 most relevant rules, not all 1,081\r\n\r\n\n### Step: Scan Target Files\r\n\r\nIdentify the files to audit based on the task:\r\n\r\n```bash\r\n# For a specific file\r\naudit: src/components/UserAuth.tsx\r\n\r\n# For a directory\r\naudit: src/components/\r\n\r\n# For recent changes\r\ngit diff --name-only HEAD~1\r\n```",
          "tokens": 380
        },
        "standard": {
          "content": "## Skill: rule-auditor\n\nRule Auditor - Automatically validates code against your project's coding standards and rules.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Load Rule Index\r\n\r\nLoad the rule index to discover all available rules dynamically:\r\n- @.claude/context/rule-index.json\r\n\r\nThe index contains metadata for all 1,081+ rules in `.claude/rules-master/` and `.claude/rules-library/` (formerly archive).\r\n\r\n### Step 2: Filter Relevant Rules\r\n\r\nQuery the index's `technology_map` based on target files:\r\n\r\n1. **Detect technologies** from target files:\r\n   - File extension (`.tsx` → TypeScript, React)\r\n   - Import statements (`next` → Next.js, `react` → React)\r\n   - Directory structure (`app/` → Next.js App Router)\r\n\r\n2. **Query technology_map**:\r\n   ```javascript\r\n   // Pseudocode\r\n   const detectedTech = ['nextjs', 'react', 'typescript'];\r\n   const relevantRules = [];\r\n   \r\n   detectedTech.forEach(tech => {\r\n     const rules = index.technology_map[tech] || [];\r\n     relevantRules.push(...rules);\r\n   });\r\n   ```\r\n\r\n3. **Load only relevant rule files** (progressive disclosure):\r\n   - Master rules take priority (from `.claude/rules-master/`)\r\n   - Library rules supplement (from `.claude/rules-library/`, formerly archive)\r\n   - Load 5-10 most relevant rules, not all 1,081\r\n\r\n### Step 3: Scan Target Files\r\n\r\nIdentify the files to audit based on the task:\r\n\r\n```bash\r\n# For a specific file\r\naudit: src/components/UserAuth.tsx\r\n\r\n# For a directory\r\naudit: src/components/\r\n\r\n# For recent changes\r\ngit diff --name-only HEAD~1\r\n```\r\n\r\n### Step 4: Extract Validation Patterns from Rules\r\n\r\nParse rule files to extract formalized validation patterns:\r\n\r\n1. **Look for `<validation>` block in rule file** (deterministic approach):\r\n   ```markdown\r\n   <validation>\r\n   forbidden_patterns:\r\n     - pattern: \"useEffect\\\\(.*fetch\"\r\n       message: \"Do not use useEffect for data fetching; use Server Components.\"\r\n       severity: \"error\"\r\n     - pattern: \"console\\\\.log\"\r\n       message: \"Remove console.log statements before commit.\"\r\n       severity: \"warning\"\r\n   </validation>\r\n   ```\r\n\r\n2. **OR look for `validation` section in rule frontmatter** (legacy support):\r\n   ```yaml\r\n   validation:\r\n     forbidden_patterns:\r\n       - pattern: \"useEffect\\\\(.*fetch\"\r\n         message: \"Do not use useEffect for data fetching; use Server Components.\"\r\n         severity: \"error\"\r\n   ```\r\n\r\n3. **Extract forbidden_patterns**:\r\n   - **First priority**: Load from `<validation>` block (deterministic, preferred)\r\n   - **Second priority**: Load from `validation.forbidden_patterns` in frontmatter\r\n   - Each pattern includes:\r\n     - `pattern`: Regex pattern to match\r\n     - `message`: Human-readable violation message\r\n     - `severity`: \"error\" or \"warning\"\r\n\r\n4. **Fallback to pattern extraction** (if no validation block/section):\r\n   - Parse rule text for common patterns\r\n   - Convert natural language rules to regex where possible\r\n   - Use grep/pattern matching for structure checks\r\n   - **Note**: This is slower and less consistent than using `<validation>` blocks\r\n\r\n**Pattern Categories to Check:**\r\n\r\n| Category | Example Rule | Check Method |\r\n|----------|--------------|--------------|\r\n| Naming | \"Use camelCase for functions\" | Regex scan |\r\n| Structure | \"Place components in `components/` dir\" | Path check |\r\n| Imports | \"Use ES modules, not CommonJS\" | Pattern match |\r\n| Types | \"Avoid `any`, prefer `unknown`\" | AST-level grep |\r\n| Performance | \"Use Server Components by default\" | Directive scan |\r\n| Security | \"Never hardcode secrets\" | Pattern detection |\r\n| **Formalized** | `validation.forbidden_patterns` | **Regex/grep (preferred)** |\r\n\r\n**Fix Field in Validation Patterns**:\r\n\r\nEach pattern can optionally include a `fix` field for auto-fixing:\r\n```yaml\r\n- pattern: \"console\\\\.log\\\\((.*)\\\\)\"\r\n  message: \"Remove console.log statements\"\r\n  severity: \"warning\"\r\n  fix: \"\"  # Empty string = delete the entire match\r\n\r\n- pattern: \"const (\\\\w+): any\"\r\n  message: \"Avoid using 'any' type\"\r\n  severity: \"error\"\r\n  fix: \"const $1: unknown\"  # $1 references first capture group\r\n\r\n- pattern: \"var (\\\\w+) =\"\r\n  message: \"Use 'const' or 'let' instead of 'var'\"\r\n  severity: \"warning\"\r\n  fix: \"const $1 =\"  # Replace var with const\r\n```\r\n\r\n**Fix Replacement Syntax**:\r\n- `\"\"` (empty string): Delete the entire matched pattern\r\n- `\"// Removed: $0\"`: Replace with comment (where $0 is the full match)\r\n- `\"const $1\"`: Use capture groups ($1, $2, etc.) from the pattern\r\n- Fixed string: Replace match with literal text\r\n\r\n### Step 5: Run Validation Checks\r\n\r\nFor each forbidden pattern:\r\n\r\n1. **Run grep/regex search** on target files:\r\n   - Use pattern from `validation.forbidden_patterns`\r\n   - Search across all target files\r\n   - Report matches with line numbers\r\n\r\n2. **Report matches**:\r\n   - Include line number and file path\r\n   - Include message from pattern definition\r\n   - Include severity (error/warning)\r\n   - Show code snippet with match highlighted\r\n\r\n3. **Aggregate results by severity**:\r\n   - Group errors separately from warnings\r\n   - Count violations per pattern\r\n   - Sort by severity and frequency\r\n\r\n### Step 6: Generate Compliance Report\r\n\r\nOutput a structured report with violations, warnings, and passed rules.\r\n\r\n### Step 7: Quick-Fix Mode (Optional)\r\n\r\nWhen `--fix`, `--fix-auto`, or `--fix-dry-run` flags are provided, automatically apply fixes for violations that have a `fix` field defined.\r\n\r\n**Fix Mode Behavior**:\r\n\r\n1. **--fix-dry-run** (Safe Preview):\r\n   - Scan for violations with fix definitions\r\n   - Show diff preview of changes without modifying files\r\n   - Display before/after for each fix\r\n   - No file modifications occur\r\n   - Useful for reviewing impact before applying\r\n\r\n2. **--fix** (Interactive Mode):\r\n   - Create `.bak` backup file before any modification\r\n   - Show diff preview for each fixable violation\r\n   - Prompt user for confirmation: \"Apply this fix? (y/n/all/skip)\"\r\n     - `y`: Apply this fix and continue\r\n     - `n`: Skip this fix and continue\r\n     - `all`: Apply all remaining fixes without prompting\r\n     - `skip`: Skip all remaining fixes\r\n   - Apply confirmed fixes using Edit tool\r\n   - Report summary of applied vs skipped fixes\r\n\r\n3. **--fix-auto** (Batch Mode):\r\n   - Create `.bak` backup file before any modification\r\n   - Apply all fixable violations automatically\r\n   - No user prompts (fully automated)\r\n   - Generate detailed log of all changes\r\n   - Useful for CI/CD pipelines or bulk cleanup\r\n\r\n**Backup Behavior**:\r\n- Backup file: `<original-file>.bak`\r\n- Created before first modification to each file\r\n- Contains original file contents\r\n- Allows manual rollback if needed\r\n- Example: `src/App.tsx` → `src/App.tsx.bak`\r\n\r\n**Diff Preview Format**:\r\n```diff\r\nFile: src/components/UserAuth.tsx\r\nLine 23:\r\n- console.log('User authenticated:', user);\r\n+ // Removed: console.log('User authenticated:', user);\r\n\r\nLine 45:\r\n- const user: any = await getUser();\r\n+ const user: unknown = await getUser();\r\n```\r\n\r\n**Fix Application Process**:\r\n1. Read target file\r\n2. Create backup if not in dry-run mode\r\n3. Apply regex replacement using `fix` pattern\r\n4. Handle capture group substitutions ($1, $2, etc.)\r\n5. Write modified content back to file\r\n6. Log change to fix report\r\n\r\n**Limitations**:\r\n- Only fixes violations with `fix` field defined in rule\r\n- Complex refactorings require manual intervention\r\n- Multiline fixes may need manual review\r\n- Some patterns may require AST-level transformation\r\n</execution_process>\r\n\r\n<audit_patterns>\r\n**Next.js / React Audit**:\r\n- CHECK: 'use client' directive present when using useState, useEffect, useContext\r\n- CHECK: Server Components for data fetching (no useEffect for fetch)\r\n- CHECK: Image optimization using next/image\r\n\r\n**TypeScript Audit**:\r\n- CHECK: Type safety - No `any` types, interfaces for object shapes\r\n- CHECK: Naming conventions - PascalCase for Components, camelCase for functions\r\n\r\n**Python/FastAPI Audit**:\r\n- CHECK: Async patterns - async def for I/O operations\r\n- CHECK: Type hints - All function parameters typed\r\n</audit_patterns>\r\n\r\n<integration>\r\n**Pre-Commit Hook**: Run rule audit on modified files before commit\r\n**CI/CD Integration**: Generate JSON reports for automated quality gates\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Run Early**: Audit during development, not just before commit\r\n2. **Fix as You Go**: Address violations immediately while context is fresh\r\n3. **Customize Rules**: Adjust rule severity in manifest.yaml for your team\r\n4. **Track Trends**: Monitor violation counts over time to measure improvement\r\n5. **Educate Team**: Use audit reports in code reviews to teach standards\r\n6. **Preview First**: Always run `--fix-dry-run` before `--fix-auto` to review changes\r\n7. **Test After Fixing**: Run tests after auto-fixing to ensure no functionality broke\r\n8. **Keep Backups**: Don't delete .bak files until changes are verified\r\n9. **Review Diffs**: Use `git diff` to review all changes before committing\r\n10. **Start Small**: Test auto-fix on single files before running on entire codebase\r\n</best_practices>\r\n\r\n## Quick-Fix Mode\r\n\r\nThe rule-auditor now supports automatic fixing of violations through three modes: preview, interactive, and batch.\r\n\r\n### Fix Modes\r\n\r\n| Mode | Flag | Behavior | Use Case |\r\n|------|------|----------|----------|\r\n| **Preview** | `--fix-dry-run` | Show changes without modifying files | Review impact before applying |\r\n| **Interactive** | `--fix` | Prompt for confirmation on each fix | Careful, selective fixing |\r\n| **Batch** | `--fix-auto` | Apply all fixes automatically | Bulk cleanup, CI/CD |\r\n\r\n### Adding Fix Definitions to Rules\r\n\r\nTo make violations auto-fixable, add a `fix` field to validation patterns in your rule files:\r\n\r\n**In `<validation>` block**:\r\n```markdown\r\n<validation>\r\nforbidden_patterns:\r\n  - pattern: \"console\\\\.log\\\\((.*)\\\\)\"\r\n    message: \"Remove console.log statements before commit\"\r\n    severity: \"warning\"\r\n    fix: \"\"  # Empty = delete entire match\r\n\r\n  - pattern: \"const (\\\\w+): any\"\r\n    message: \"Avoid using 'any' type\"\r\n    severity: \"error\"\r\n    fix: \"const $1: unknown\"  # Replace with unknown\r\n\r\n  - pattern: \"var (\\\\w+) =\"\r\n    message: \"Use 'const' or 'let' instead of 'var'\"\r\n    severity: \"warning\"\r\n    fix: \"const $1 =\"  # Replace var with const\r\n</validation>\r\n```\r\n\r\n**Or in frontmatter**:\r\n```yaml\r\n---\r\nvalidation:\r\n  forbidden_patterns:\r\n    - pattern: \"console\\\\.log\\\\((.*)\\\\)\"\r\n      message: \"Remove console.log statements\"\r\n      severity: \"warning\"\r\n      fix: \"\"\r\n---\r\n```\r\n\r\n### Fix Field Syntax\r\n\r\nThe `fix` field supports several replacement patterns:\r\n\r\n1. **Delete Match**: Empty string removes the matched pattern\r\n   ```yaml\r\n   fix: \"\"\r\n   ```\r\n\r\n2. **Capture Group Substitution**: Use $1, $2, etc. to reference regex groups\r\n   ```yaml\r\n   pattern: \"const (\\\\w+): any\"\r\n   fix: \"const $1: unknown\"\r\n   ```\r\n\r\n3. **Fixed Replacement**: Replace with literal text\r\n   ```yaml\r\n   pattern: \"var (\\\\w+) =\"\r\n   fix: \"const $1 =\"\r\n   ```\r\n\r\n4. **Comment Out**: Replace with comment preserving original code\r\n   ```yaml\r\n   pattern: \"debugger;\"\r\n   fix: \"// debugger;\"\r\n   ```\r\n\r\n### Safety Features\r\n\r\n1. **Automatic Backups**: Creates `.bak` file before any modification\r\n2. **Diff Preview**: Shows before/after for all fixes\r\n3. **Dry-Run Mode**: Test fixes without modifying files\r\n4. **Interactive Confirmation**: Review each fix before applying\r\n5. **Rollback Support**: Restore from .bak files if needed\r\n\r\n### Example Workflow\r\n\r\n```bash\r\n# 1. Preview what would be fixed\r\n/audit src/ --fix-dry-run\r\n\r\n# 2. Apply fixes with confirmation\r\n/audit src/components/UserAuth.tsx --fix\r\n\r\n# 3. Review changes\r\ngit diff\r\n\r\n# 4. Run tests\r\nnpm test\r\n\r\n# 5. If issues occur, rollback\r\nmv src/components/UserAuth.tsx.bak src/components/UserAuth.tsx\r\n\r\n# 6. If all good, commit\r\ngit add src/\r\ngit commit -m \"fix: auto-fix rule violations\"\r\n\r\n# 7. Clean up backups\r\nrm **/*.bak\r\n```\r\n\r\n### Creating Effective Fix Patterns\r\n\r\n**Good Fix Patterns** (Safe, Deterministic):\r\n- Simple find-replace operations\r\n- Type annotations (any → unknown)\r\n- Variable declarations (var → const)\r\n- Import statement updates\r\n- Comment/uncomment code\r\n- Formatting fixes\r\n\r\n**Poor Fix Patterns** (Manual Review Required):\r\n- Complex refactorings\r\n- Logic changes\r\n- Multiline transformations\r\n- Context-dependent fixes\r\n- AST-level transformations\r\n\r\n**Best Practices for Fix Definitions**:\r\n1. Keep fixes simple and deterministic\r\n2. Test fix patterns on sample code before deploying\r\n3. Use capture groups to preserve variable names\r\n4. Prefer commenting over deletion for debugging code\r\n5. Document why a fix is safe in the rule message\r\n6. Consider edge cases where fix might break code\r\n\r\n### Limitations\r\n\r\n- Only fixes violations with `fix` field defined\r\n- Regex-based replacements only (no AST manipulation)\r\n- Complex refactorings require manual intervention\r\n- Multiline patterns may need special handling\r\n- Some fixes may require post-fix manual adjustments\r\n\r\nFor complex transformations beyond regex replacement, consider using the `refactoring-specialist` agent.\n\n### Example:\n**JSON Output Format (for CI/CD)**:\r\n\r\n```json\r\n{\r\n  \"target\": \"src/components/\",\r\n  \"timestamp\": \"2025-11-29T10:00:00Z\",\r\n  \"rules_applied\": [\"nextjs.mdc\", \"typescript.mdc\"],\r\n  \"summary\": {\r\n    \"pass\": 12,\r\n    \"warn\": 3,\r\n    \"fail\": 2\r\n  },\r\n  \"violations\": [\r\n    {\r\n      \"severity\": \"fail\",\r\n      \"rule\": \"typescript.mdc\",\r\n      \"pattern\": \"Avoid using any\",\r\n      \"file\": \"src/components/UserAuth.tsx\",\r\n      \"line\": 45,\r\n      \"code\": \"const user: any = await getUser()\",\r\n      \"fix\": \"Define User interface\"\r\n    }\r\n  ]\r\n}\r\n```",
          "tokens": 3430
        },
        "full": {
          "content": "---\r\nname: rule-auditor\r\ndescription: Validates code against currently loaded rules and reports compliance violations. Supports auto-fixing violations with confirmation, dry-run mode, and automatic backups. Use after implementing features, during code review, or to ensure coding standards are followed. Provides actionable feedback with line-by-line issues and suggested fixes.\r\nallowed-tools: read, grep, glob, search, codebase_search, edit, write\r\nversion: 3.1\r\nexecutable: scripts/audit.mjs\r\nbest_practices:\r\n  - Run audits early in development cycle\r\n  - Focus on high-severity violations first\r\n  - Provide specific, actionable fixes\r\n  - Group violations by rule category\r\n  - Include code examples in suggestions\r\n  - Use --fix-dry-run to preview changes before applying\r\n  - Review backup files (.bak) after auto-fixing\r\nerror_handling: graceful\r\nstreaming: supported\r\noutput_formats: [markdown, json, inline_comments]\r\n---\r\n\r\n## Executable Script\r\n\r\nThe rule-auditor skill now includes an executable script for CLI usage and programmatic validation.\r\n\r\n### Installation\r\n\r\nNo installation required - the script uses Node.js built-in modules only.\r\n\r\n### CLI Usage\r\n\r\n```bash\r\n# Audit a directory\r\nnode .claude/skills/rule-auditor/scripts/audit.mjs src/components/\r\n\r\n# Audit specific file with JSON output\r\nnode .claude/skills/rule-auditor/scripts/audit.mjs src/App.tsx --format json\r\n\r\n# Preview fixes (dry run)\r\nnode .claude/skills/rule-auditor/scripts/audit.mjs src/ --fix-dry-run\r\n\r\n# Apply fixes (creates .bak backups)\r\nnode .claude/skills/rule-auditor/scripts/audit.mjs src/ --fix\r\n\r\n# Audit with specific rules only\r\nnode .claude/skills/rule-auditor/scripts/audit.mjs src/ --rules nextjs,typescript\r\n\r\n# Strict mode (fail on any violation)\r\nnode .claude/skills/rule-auditor/scripts/audit.mjs src/ --strict\r\n```\r\n\r\n### Output Schema\r\n\r\nAll output conforms to `.claude/schemas/skill-rule-auditor-output.schema.json` and includes:\r\n- `skill_name`: Always \"rule-auditor\"\r\n- `files_audited`: Array of audited files with line counts\r\n- `rules_applied`: Rules used during audit with violation counts\r\n- `compliance_score`: 0-100 score based on violations\r\n- `violations_found`: Detailed violations with locations\r\n- `fixes_applied`: Applied fixes (when using --fix or --fix-dry-run)\r\n- `rule_index_consulted`: Boolean confirming rule index was loaded\r\n- `technologies_detected`: Technologies detected in codebase\r\n- `audit_summary`: Summary statistics\r\n- `timestamp`: ISO 8601 timestamp\r\n\r\n### Testing\r\n\r\nRun the test suite to validate the audit script:\r\n\r\n```bash\r\nnode .claude/skills/rule-auditor/scripts/test-audit.mjs\r\n```\r\n\r\nTests cover:\r\n- Basic audit functionality\r\n- Technology detection\r\n- Dry-run fix mode\r\n- Fix mode with backups\r\n- Compliance score calculation\r\n- Exit codes\r\n- Output schema validation\r\n\r\n---\r\n\r\n<identity>\r\nRule Auditor - Automatically validates code against your project's coding standards and rules.\r\n</identity>\r\n\r\n<capabilities>\r\n- After implementing a new feature or component\r\n- During code review to check standards compliance\r\n- Before committing to ensure quality gates pass\r\n- When onboarding to understand project conventions\r\n- To generate compliance reports for teams\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Load Rule Index\r\n\r\nLoad the rule index to discover all available rules dynamically:\r\n- @.claude/context/rule-index.json\r\n\r\nThe index contains metadata for all 1,081+ rules in `.claude/rules-master/` and `.claude/rules-library/` (formerly archive).\r\n\r\n### Step 2: Filter Relevant Rules\r\n\r\nQuery the index's `technology_map` based on target files:\r\n\r\n1. **Detect technologies** from target files:\r\n   - File extension (`.tsx` → TypeScript, React)\r\n   - Import statements (`next` → Next.js, `react` → React)\r\n   - Directory structure (`app/` → Next.js App Router)\r\n\r\n2. **Query technology_map**:\r\n   ```javascript\r\n   // Pseudocode\r\n   const detectedTech = ['nextjs', 'react', 'typescript'];\r\n   const relevantRules = [];\r\n   \r\n   detectedTech.forEach(tech => {\r\n     const rules = index.technology_map[tech] || [];\r\n     relevantRules.push(...rules);\r\n   });\r\n   ```\r\n\r\n3. **Load only relevant rule files** (progressive disclosure):\r\n   - Master rules take priority (from `.claude/rules-master/`)\r\n   - Library rules supplement (from `.claude/rules-library/`, formerly archive)\r\n   - Load 5-10 most relevant rules, not all 1,081\r\n\r\n### Step 3: Scan Target Files\r\n\r\nIdentify the files to audit based on the task:\r\n\r\n```bash\r\n# For a specific file\r\naudit: src/components/UserAuth.tsx\r\n\r\n# For a directory\r\naudit: src/components/\r\n\r\n# For recent changes\r\ngit diff --name-only HEAD~1\r\n```\r\n\r\n### Step 4: Extract Validation Patterns from Rules\r\n\r\nParse rule files to extract formalized validation patterns:\r\n\r\n1. **Look for `<validation>` block in rule file** (deterministic approach):\r\n   ```markdown\r\n   <validation>\r\n   forbidden_patterns:\r\n     - pattern: \"useEffect\\\\(.*fetch\"\r\n       message: \"Do not use useEffect for data fetching; use Server Components.\"\r\n       severity: \"error\"\r\n     - pattern: \"console\\\\.log\"\r\n       message: \"Remove console.log statements before commit.\"\r\n       severity: \"warning\"\r\n   </validation>\r\n   ```\r\n\r\n2. **OR look for `validation` section in rule frontmatter** (legacy support):\r\n   ```yaml\r\n   validation:\r\n     forbidden_patterns:\r\n       - pattern: \"useEffect\\\\(.*fetch\"\r\n         message: \"Do not use useEffect for data fetching; use Server Components.\"\r\n         severity: \"error\"\r\n   ```\r\n\r\n3. **Extract forbidden_patterns**:\r\n   - **First priority**: Load from `<validation>` block (deterministic, preferred)\r\n   - **Second priority**: Load from `validation.forbidden_patterns` in frontmatter\r\n   - Each pattern includes:\r\n     - `pattern`: Regex pattern to match\r\n     - `message`: Human-readable violation message\r\n     - `severity`: \"error\" or \"warning\"\r\n\r\n4. **Fallback to pattern extraction** (if no validation block/section):\r\n   - Parse rule text for common patterns\r\n   - Convert natural language rules to regex where possible\r\n   - Use grep/pattern matching for structure checks\r\n   - **Note**: This is slower and less consistent than using `<validation>` blocks\r\n\r\n**Pattern Categories to Check:**\r\n\r\n| Category | Example Rule | Check Method |\r\n|----------|--------------|--------------|\r\n| Naming | \"Use camelCase for functions\" | Regex scan |\r\n| Structure | \"Place components in `components/` dir\" | Path check |\r\n| Imports | \"Use ES modules, not CommonJS\" | Pattern match |\r\n| Types | \"Avoid `any`, prefer `unknown`\" | AST-level grep |\r\n| Performance | \"Use Server Components by default\" | Directive scan |\r\n| Security | \"Never hardcode secrets\" | Pattern detection |\r\n| **Formalized** | `validation.forbidden_patterns` | **Regex/grep (preferred)** |\r\n\r\n**Fix Field in Validation Patterns**:\r\n\r\nEach pattern can optionally include a `fix` field for auto-fixing:\r\n```yaml\r\n- pattern: \"console\\\\.log\\\\((.*)\\\\)\"\r\n  message: \"Remove console.log statements\"\r\n  severity: \"warning\"\r\n  fix: \"\"  # Empty string = delete the entire match\r\n\r\n- pattern: \"const (\\\\w+): any\"\r\n  message: \"Avoid using 'any' type\"\r\n  severity: \"error\"\r\n  fix: \"const $1: unknown\"  # $1 references first capture group\r\n\r\n- pattern: \"var (\\\\w+) =\"\r\n  message: \"Use 'const' or 'let' instead of 'var'\"\r\n  severity: \"warning\"\r\n  fix: \"const $1 =\"  # Replace var with const\r\n```\r\n\r\n**Fix Replacement Syntax**:\r\n- `\"\"` (empty string): Delete the entire matched pattern\r\n- `\"// Removed: $0\"`: Replace with comment (where $0 is the full match)\r\n- `\"const $1\"`: Use capture groups ($1, $2, etc.) from the pattern\r\n- Fixed string: Replace match with literal text\r\n\r\n### Step 5: Run Validation Checks\r\n\r\nFor each forbidden pattern:\r\n\r\n1. **Run grep/regex search** on target files:\r\n   - Use pattern from `validation.forbidden_patterns`\r\n   - Search across all target files\r\n   - Report matches with line numbers\r\n\r\n2. **Report matches**:\r\n   - Include line number and file path\r\n   - Include message from pattern definition\r\n   - Include severity (error/warning)\r\n   - Show code snippet with match highlighted\r\n\r\n3. **Aggregate results by severity**:\r\n   - Group errors separately from warnings\r\n   - Count violations per pattern\r\n   - Sort by severity and frequency\r\n\r\n### Step 6: Generate Compliance Report\r\n\r\nOutput a structured report with violations, warnings, and passed rules.\r\n\r\n### Step 7: Quick-Fix Mode (Optional)\r\n\r\nWhen `--fix`, `--fix-auto`, or `--fix-dry-run` flags are provided, automatically apply fixes for violations that have a `fix` field defined.\r\n\r\n**Fix Mode Behavior**:\r\n\r\n1. **--fix-dry-run** (Safe Preview):\r\n   - Scan for violations with fix definitions\r\n   - Show diff preview of changes without modifying files\r\n   - Display before/after for each fix\r\n   - No file modifications occur\r\n   - Useful for reviewing impact before applying\r\n\r\n2. **--fix** (Interactive Mode):\r\n   - Create `.bak` backup file before any modification\r\n   - Show diff preview for each fixable violation\r\n   - Prompt user for confirmation: \"Apply this fix? (y/n/all/skip)\"\r\n     - `y`: Apply this fix and continue\r\n     - `n`: Skip this fix and continue\r\n     - `all`: Apply all remaining fixes without prompting\r\n     - `skip`: Skip all remaining fixes\r\n   - Apply confirmed fixes using Edit tool\r\n   - Report summary of applied vs skipped fixes\r\n\r\n3. **--fix-auto** (Batch Mode):\r\n   - Create `.bak` backup file before any modification\r\n   - Apply all fixable violations automatically\r\n   - No user prompts (fully automated)\r\n   - Generate detailed log of all changes\r\n   - Useful for CI/CD pipelines or bulk cleanup\r\n\r\n**Backup Behavior**:\r\n- Backup file: `<original-file>.bak`\r\n- Created before first modification to each file\r\n- Contains original file contents\r\n- Allows manual rollback if needed\r\n- Example: `src/App.tsx` → `src/App.tsx.bak`\r\n\r\n**Diff Preview Format**:\r\n```diff\r\nFile: src/components/UserAuth.tsx\r\nLine 23:\r\n- console.log('User authenticated:', user);\r\n+ // Removed: console.log('User authenticated:', user);\r\n\r\nLine 45:\r\n- const user: any = await getUser();\r\n+ const user: unknown = await getUser();\r\n```\r\n\r\n**Fix Application Process**:\r\n1. Read target file\r\n2. Create backup if not in dry-run mode\r\n3. Apply regex replacement using `fix` pattern\r\n4. Handle capture group substitutions ($1, $2, etc.)\r\n5. Write modified content back to file\r\n6. Log change to fix report\r\n\r\n**Limitations**:\r\n- Only fixes violations with `fix` field defined in rule\r\n- Complex refactorings require manual intervention\r\n- Multiline fixes may need manual review\r\n- Some patterns may require AST-level transformation\r\n</execution_process>\r\n\r\n<audit_patterns>\r\n**Next.js / React Audit**:\r\n- CHECK: 'use client' directive present when using useState, useEffect, useContext\r\n- CHECK: Server Components for data fetching (no useEffect for fetch)\r\n- CHECK: Image optimization using next/image\r\n\r\n**TypeScript Audit**:\r\n- CHECK: Type safety - No `any` types, interfaces for object shapes\r\n- CHECK: Naming conventions - PascalCase for Components, camelCase for functions\r\n\r\n**Python/FastAPI Audit**:\r\n- CHECK: Async patterns - async def for I/O operations\r\n- CHECK: Type hints - All function parameters typed\r\n</audit_patterns>\r\n\r\n<integration>\r\n**Pre-Commit Hook**: Run rule audit on modified files before commit\r\n**CI/CD Integration**: Generate JSON reports for automated quality gates\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Run Early**: Audit during development, not just before commit\r\n2. **Fix as You Go**: Address violations immediately while context is fresh\r\n3. **Customize Rules**: Adjust rule severity in manifest.yaml for your team\r\n4. **Track Trends**: Monitor violation counts over time to measure improvement\r\n5. **Educate Team**: Use audit reports in code reviews to teach standards\r\n6. **Preview First**: Always run `--fix-dry-run` before `--fix-auto` to review changes\r\n7. **Test After Fixing**: Run tests after auto-fixing to ensure no functionality broke\r\n8. **Keep Backups**: Don't delete .bak files until changes are verified\r\n9. **Review Diffs**: Use `git diff` to review all changes before committing\r\n10. **Start Small**: Test auto-fix on single files before running on entire codebase\r\n</best_practices>\r\n\r\n## Quick-Fix Mode\r\n\r\nThe rule-auditor now supports automatic fixing of violations through three modes: preview, interactive, and batch.\r\n\r\n### Fix Modes\r\n\r\n| Mode | Flag | Behavior | Use Case |\r\n|------|------|----------|----------|\r\n| **Preview** | `--fix-dry-run` | Show changes without modifying files | Review impact before applying |\r\n| **Interactive** | `--fix` | Prompt for confirmation on each fix | Careful, selective fixing |\r\n| **Batch** | `--fix-auto` | Apply all fixes automatically | Bulk cleanup, CI/CD |\r\n\r\n### Adding Fix Definitions to Rules\r\n\r\nTo make violations auto-fixable, add a `fix` field to validation patterns in your rule files:\r\n\r\n**In `<validation>` block**:\r\n```markdown\r\n<validation>\r\nforbidden_patterns:\r\n  - pattern: \"console\\\\.log\\\\((.*)\\\\)\"\r\n    message: \"Remove console.log statements before commit\"\r\n    severity: \"warning\"\r\n    fix: \"\"  # Empty = delete entire match\r\n\r\n  - pattern: \"const (\\\\w+): any\"\r\n    message: \"Avoid using 'any' type\"\r\n    severity: \"error\"\r\n    fix: \"const $1: unknown\"  # Replace with unknown\r\n\r\n  - pattern: \"var (\\\\w+) =\"\r\n    message: \"Use 'const' or 'let' instead of 'var'\"\r\n    severity: \"warning\"\r\n    fix: \"const $1 =\"  # Replace var with const\r\n</validation>\r\n```\r\n\r\n**Or in frontmatter**:\r\n```yaml\r\n---\r\nvalidation:\r\n  forbidden_patterns:\r\n    - pattern: \"console\\\\.log\\\\((.*)\\\\)\"\r\n      message: \"Remove console.log statements\"\r\n      severity: \"warning\"\r\n      fix: \"\"\r\n---\r\n```\r\n\r\n### Fix Field Syntax\r\n\r\nThe `fix` field supports several replacement patterns:\r\n\r\n1. **Delete Match**: Empty string removes the matched pattern\r\n   ```yaml\r\n   fix: \"\"\r\n   ```\r\n\r\n2. **Capture Group Substitution**: Use $1, $2, etc. to reference regex groups\r\n   ```yaml\r\n   pattern: \"const (\\\\w+): any\"\r\n   fix: \"const $1: unknown\"\r\n   ```\r\n\r\n3. **Fixed Replacement**: Replace with literal text\r\n   ```yaml\r\n   pattern: \"var (\\\\w+) =\"\r\n   fix: \"const $1 =\"\r\n   ```\r\n\r\n4. **Comment Out**: Replace with comment preserving original code\r\n   ```yaml\r\n   pattern: \"debugger;\"\r\n   fix: \"// debugger;\"\r\n   ```\r\n\r\n### Safety Features\r\n\r\n1. **Automatic Backups**: Creates `.bak` file before any modification\r\n2. **Diff Preview**: Shows before/after for all fixes\r\n3. **Dry-Run Mode**: Test fixes without modifying files\r\n4. **Interactive Confirmation**: Review each fix before applying\r\n5. **Rollback Support**: Restore from .bak files if needed\r\n\r\n### Example Workflow\r\n\r\n```bash\r\n# 1. Preview what would be fixed\r\n/audit src/ --fix-dry-run\r\n\r\n# 2. Apply fixes with confirmation\r\n/audit src/components/UserAuth.tsx --fix\r\n\r\n# 3. Review changes\r\ngit diff\r\n\r\n# 4. Run tests\r\nnpm test\r\n\r\n# 5. If issues occur, rollback\r\nmv src/components/UserAuth.tsx.bak src/components/UserAuth.tsx\r\n\r\n# 6. If all good, commit\r\ngit add src/\r\ngit commit -m \"fix: auto-fix rule violations\"\r\n\r\n# 7. Clean up backups\r\nrm **/*.bak\r\n```\r\n\r\n### Creating Effective Fix Patterns\r\n\r\n**Good Fix Patterns** (Safe, Deterministic):\r\n- Simple find-replace operations\r\n- Type annotations (any → unknown)\r\n- Variable declarations (var → const)\r\n- Import statement updates\r\n- Comment/uncomment code\r\n- Formatting fixes\r\n\r\n**Poor Fix Patterns** (Manual Review Required):\r\n- Complex refactorings\r\n- Logic changes\r\n- Multiline transformations\r\n- Context-dependent fixes\r\n- AST-level transformations\r\n\r\n**Best Practices for Fix Definitions**:\r\n1. Keep fixes simple and deterministic\r\n2. Test fix patterns on sample code before deploying\r\n3. Use capture groups to preserve variable names\r\n4. Prefer commenting over deletion for debugging code\r\n5. Document why a fix is safe in the rule message\r\n6. Consider edge cases where fix might break code\r\n\r\n### Limitations\r\n\r\n- Only fixes violations with `fix` field defined\r\n- Regex-based replacements only (no AST manipulation)\r\n- Complex refactorings require manual intervention\r\n- Multiline patterns may need special handling\r\n- Some fixes may require post-fix manual adjustments\r\n\r\nFor complex transformations beyond regex replacement, consider using the `refactoring-specialist` agent.\r\n\r\n</instructions>\r\n\r\n<examples>\r\n<formatting_example>\r\n**Markdown Report Format**:\r\n\r\n```markdown\r\n## Rule Audit Report\r\n\r\n**Target**: src/components/UserAuth.tsx\r\n**Rules Applied**: nextjs.mdc, typescript.mdc, react.mdc\r\n**Scan Date**: {{timestamp}}\r\n\r\n### Summary\r\n- **Pass**: 12 rules\r\n- **Warn**: 3 rules\r\n- **Fail**: 2 rules\r\n\r\n### Violations\r\n\r\n#### FAIL: Use Server Components by default\r\n- **File**: src/components/UserAuth.tsx:1\r\n- **Issue**: Missing 'use client' directive but uses useState\r\n- **Rule**: nextjs.mdc > Components\r\n- **Fix**: Add 'use client' at file top, or refactor to Server Component\r\n\r\n#### FAIL: Avoid using `any`\r\n- **File**: src/components/UserAuth.tsx:45\r\n- **Issue**: `const user: any = await getUser()`\r\n- **Rule**: typescript.mdc > Type System\r\n- **Fix**: Define proper User interface\r\n\r\n#### WARN: Minimize use of 'useEffect'\r\n- **File**: src/components/UserAuth.tsx:23\r\n- **Issue**: useEffect for data fetching\r\n- **Rule**: nextjs.mdc > Performance\r\n- **Suggestion**: Consider Server Component with async/await\r\n\r\n### Passed Rules\r\n- ✅ Use TypeScript strict mode\r\n- ✅ Use lowercase with dashes for directories\r\n- ✅ Implement proper error boundaries\r\n... (12 more)\r\n```\r\n</formatting_example>\r\n\r\n<code_example>\r\n**JSON Output Format (for CI/CD)**:\r\n\r\n```json\r\n{\r\n  \"target\": \"src/components/\",\r\n  \"timestamp\": \"2025-11-29T10:00:00Z\",\r\n  \"rules_applied\": [\"nextjs.mdc\", \"typescript.mdc\"],\r\n  \"summary\": {\r\n    \"pass\": 12,\r\n    \"warn\": 3,\r\n    \"fail\": 2\r\n  },\r\n  \"violations\": [\r\n    {\r\n      \"severity\": \"fail\",\r\n      \"rule\": \"typescript.mdc\",\r\n      \"pattern\": \"Avoid using any\",\r\n      \"file\": \"src/components/UserAuth.tsx\",\r\n      \"line\": 45,\r\n      \"code\": \"const user: any = await getUser()\",\r\n      \"fix\": \"Define User interface\"\r\n    }\r\n  ]\r\n}\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Inline Comments Format**:\r\n\r\n```typescript\r\n// RULE_VIOLATION: typescript.mdc > Avoid using `any`\r\n// FIX: Define User interface with proper types\r\nconst user: any = await getUser();  // ❌ FAIL\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Pre-Commit Hook**:\r\n\r\n```bash\r\n#!/bin/bash\r\n# .claude/hooks/pre-commit-audit.sh\r\n# Hook: PreToolUse (for Edit, Write tools)\r\n\r\n# Run rule audit on modified files\r\nmodified=$(git diff --cached --name-only)\r\nfor file in $modified; do\r\n  audit_result=$(claude skill rule-auditor --target \"$file\" --format json)\r\n  if echo \"$audit_result\" | jq -e '.summary.fail > 0' > /dev/null; then\r\n    echo \"Rule violations found in $file\"\r\n    exit 1\r\n  fi\r\ndone\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**CI/CD Integration (GitHub Actions)**:\r\n\r\n```yaml\r\n# GitHub Actions example\r\n- name: Rule Audit\r\n  run: |\r\n    claude skill rule-auditor --target src/ --format json > audit-report.json\r\n    if [ $(jq '.summary.fail' audit-report.json) -gt 0 ]; then\r\n      echo \"::error::Rule violations detected\"\r\n      exit 1\r\n    fi\r\n```\r\n</code_example>\r\n\r\n<usage_example>\r\n**Quick Commands**:\r\n\r\n```\r\n# Audit current file\r\n/audit this file\r\n\r\n# Audit a specific directory\r\n/audit src/components/\r\n\r\n# Audit with specific rules only\r\n/audit src/ --rules nextjs,typescript\r\n\r\n# Generate CI-friendly output\r\n/audit src/ --format json --strict\r\n\r\n# Show only failures\r\n/audit src/ --severity fail\r\n\r\n# Preview fixes without applying (dry-run)\r\n/audit src/components/ --fix-dry-run\r\n\r\n# Apply fixes with confirmation\r\n/audit src/components/UserAuth.tsx --fix\r\n\r\n# Apply all fixes automatically (batch mode)\r\n/audit src/ --fix-auto\r\n\r\n# Dry-run with JSON output for CI/CD\r\n/audit src/ --fix-dry-run --format json\r\n```\r\n</usage_example>\r\n\r\n<usage_example>\r\n**Quick-Fix Mode Examples**:\r\n\r\n**Example 1: Dry-Run Preview**\r\n\r\nCommand:\r\n```bash\r\n/audit src/components/UserAuth.tsx --fix-dry-run\r\n```\r\n\r\nOutput:\r\n```diff\r\n## Fix Preview (Dry-Run Mode)\r\n\r\n### Fixable Violations: 3\r\n\r\n#### Fix 1/3\r\nFile: src/components/UserAuth.tsx:23\r\nRule: Remove console.log statements\r\nSeverity: warning\r\n\r\n- console.log('User authenticated:', user);\r\n+ // Removed: console.log('User authenticated:', user);\r\n\r\n#### Fix 2/3\r\nFile: src/components/UserAuth.tsx:45\r\nRule: Avoid using 'any' type\r\nSeverity: error\r\n\r\n- const user: any = await getUser();\r\n+ const user: unknown = await getUser();\r\n\r\n#### Fix 3/3\r\nFile: src/components/UserAuth.tsx:67\r\nRule: Use 'const' or 'let' instead of 'var'\r\nSeverity: warning\r\n\r\n- var isAuthenticated = true;\r\n+ const isAuthenticated = true;\r\n\r\n---\r\nSummary: 3 fixable violations found\r\nNo files modified (dry-run mode)\r\n```\r\n\r\n**Example 2: Interactive Fix Mode**\r\n\r\nCommand:\r\n```bash\r\n/audit src/components/UserAuth.tsx --fix\r\n```\r\n\r\nInteractive Session:\r\n```\r\nCreating backup: src/components/UserAuth.tsx.bak\r\n\r\nFix 1/3:\r\nFile: src/components/UserAuth.tsx:23\r\nRule: Remove console.log statements\r\n\r\n- console.log('User authenticated:', user);\r\n+ // Removed: console.log('User authenticated:', user);\r\n\r\nApply this fix? (y/n/all/skip): y\r\n✓ Applied fix 1/3\r\n\r\nFix 2/3:\r\nFile: src/components/UserAuth.tsx:45\r\nRule: Avoid using 'any' type\r\n\r\n- const user: any = await getUser();\r\n+ const user: unknown = await getUser();\r\n\r\nApply this fix? (y/n/all/skip): all\r\n✓ Applied fix 2/3\r\n✓ Applied fix 3/3\r\n\r\n---\r\nFix Summary:\r\n- Total violations: 3\r\n- Fixes applied: 3\r\n- Fixes skipped: 0\r\n- Backup created: src/components/UserAuth.tsx.bak\r\n\r\nRun git diff to review changes.\r\n```\r\n\r\n**Example 3: Batch Auto-Fix**\r\n\r\nCommand:\r\n```bash\r\n/audit src/ --fix-auto\r\n```\r\n\r\nOutput:\r\n```\r\n## Auto-Fix Report\r\n\r\nCreating backups for modified files...\r\n✓ src/components/UserAuth.tsx.bak\r\n✓ src/components/Profile.tsx.bak\r\n✓ src/utils/helpers.ts.bak\r\n\r\nApplying fixes...\r\n\r\nsrc/components/UserAuth.tsx:\r\n  ✓ Line 23: Removed console.log statement\r\n  ✓ Line 45: Changed 'any' to 'unknown'\r\n  ✓ Line 67: Changed 'var' to 'const'\r\n\r\nsrc/components/Profile.tsx:\r\n  ✓ Line 12: Removed console.log statement\r\n  ✓ Line 89: Changed 'var' to 'const'\r\n\r\nsrc/utils/helpers.ts:\r\n  ✓ Line 34: Changed 'any' to 'unknown'\r\n  ✓ Line 78: Changed 'any' to 'unknown'\r\n\r\n---\r\nFix Summary:\r\n- Files modified: 3\r\n- Total fixes applied: 7\r\n- Backups created: 3\r\n\r\nNext steps:\r\n1. Run 'git diff' to review all changes\r\n2. Run tests to ensure fixes didn't break functionality\r\n3. If issues occur, restore from .bak files\r\n```\r\n\r\n**Example 4: Before/After Comparison**\r\n\r\n**Before** (src/components/UserAuth.tsx):\r\n```typescript\r\nimport { useState } from 'react';\r\n\r\nexport default function UserAuth() {\r\n  var isAuthenticated = false;\r\n  const user: any = await getUser();\r\n\r\n  console.log('User authenticated:', user);\r\n\r\n  return <div>Welcome {user.name}</div>;\r\n}\r\n```\r\n\r\n**After** (with `--fix-auto`):\r\n```typescript\r\nimport { useState } from 'react';\r\n\r\nexport default function UserAuth() {\r\n  const isAuthenticated = false;\r\n  const user: unknown = await getUser();\r\n\r\n  // Removed: console.log('User authenticated:', user);\r\n\r\n  return <div>Welcome {user.name}</div>;\r\n}\r\n```\r\n\r\n**Backup** (src/components/UserAuth.tsx.bak):\r\n```typescript\r\n// Original file preserved - can restore with:\r\n// mv src/components/UserAuth.tsx.bak src/components/UserAuth.tsx\r\n```\r\n</usage_example>\r\n\r\n<usage_example>\r\n**CI/CD Integration with Auto-Fix**:\r\n\r\n**.github/workflows/code-quality.yml**:\r\n```yaml\r\nname: Code Quality with Auto-Fix\r\n\r\non: [pull_request]\r\n\r\njobs:\r\n  audit-and-fix:\r\n    runs-on: ubuntu-latest\r\n    steps:\r\n      - uses: actions/checkout@v3\r\n\r\n      # Step 1: Audit and preview fixes\r\n      - name: Audit Code (Dry-Run)\r\n        run: |\r\n          claude skill rule-auditor --target src/ --fix-dry-run --format json > fix-preview.json\r\n\r\n      # Step 2: Apply fixes automatically\r\n      - name: Auto-Fix Violations\r\n        run: |\r\n          claude skill rule-auditor --target src/ --fix-auto --format json > fix-report.json\r\n\r\n      # Step 3: Commit fixes back to PR\r\n      - name: Commit Fixes\r\n        run: |\r\n          git config user.name \"Rule Auditor Bot\"\r\n          git config user.email \"bot@example.com\"\r\n          git add -A\r\n          git commit -m \"chore: auto-fix rule violations\" || echo \"No fixes applied\"\r\n          git push\r\n\r\n      # Step 4: Post summary as PR comment\r\n      - name: Post Fix Summary\r\n        uses: actions/github-script@v6\r\n        with:\r\n          script: |\r\n            const report = require('./fix-report.json');\r\n            const comment = `## Auto-Fix Summary\r\n            - Files modified: ${report.files_modified}\r\n            - Total fixes: ${report.total_fixes}\r\n            - See commit for details`;\r\n            github.rest.issues.createComment({\r\n              issue_number: context.issue.number,\r\n              owner: context.repo.owner,\r\n              repo: context.repo.repo,\r\n              body: comment\r\n            });\r\n```\r\n\r\n**Pre-Commit Hook with Auto-Fix**:\r\n\r\n**.claude/hooks/pre-commit-autofix.sh**:\r\n```bash\r\n#!/bin/bash\r\n# Auto-fix violations before commit\r\n\r\necho \"Running rule audit with auto-fix...\"\r\n\r\n# Get staged files\r\nstaged_files=$(git diff --cached --name-only --diff-filter=ACM | grep -E '\\.(ts|tsx|js|jsx)$')\r\n\r\nif [ -z \"$staged_files\" ]; then\r\n  echo \"No files to audit\"\r\n  exit 0\r\nfi\r\n\r\n# Run audit with auto-fix on staged files\r\nfor file in $staged_files; do\r\n  claude skill rule-auditor --target \"$file\" --fix-auto\r\n\r\n  # Re-stage the fixed file\r\n  git add \"$file\"\r\ndone\r\n\r\necho \"✓ Auto-fix complete. Review changes with 'git diff --cached'\"\r\n```\r\n</usage_example>\r\n</examples>\r\n",
          "tokens": 6415
        }
      }
    },
    "code-style-validator": {
      "name": "code-style-validator",
      "one_liner": "No description",
      "key_commands": ["/identity", "/CD", "/capabilities", "/class", "/JavaScript"],
      "token_count": {
        "minimal": 13,
        "essential": 143,
        "standard": 366,
        "full": 1277
      },
      "levels": {
        "minimal": {
          "content": "**code-style-validator**: No description available",
          "tokens": 13
        },
        "essential": {
          "content": "## Skill: code-style-validator\n\nCode Style Validator - Programmatically validates code style using AST (Abstract Syntax Tree) analysis. Complements code-style rules by providing automated checking.\n\n### Key Steps:\n: Identify Code Style Patterns\r\n\r\nAnalyze the codebase to identify style patterns:\r\n- Naming conventions (camelCase, PascalCase, snake_case)\r\n- Indentation style (spaces vs tabs, width)\r\n- Import organization\r\n- Function/class structure\r\n- Comment style\r\n\r\n\n### Step: AST-Based Validation\r\n\r\nUse language-specific AST parsers:\r\n\r\n**TypeScript/JavaScript**:",
          "tokens": 143
        },
        "standard": {
          "content": "## Skill: code-style-validator\n\nCode Style Validator - Programmatically validates code style using AST (Abstract Syntax Tree) analysis. Complements code-style rules by providing automated checking.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Identify Code Style Patterns\r\n\r\nAnalyze the codebase to identify style patterns:\r\n- Naming conventions (camelCase, PascalCase, snake_case)\r\n- Indentation style (spaces vs tabs, width)\r\n- Import organization\r\n- Function/class structure\r\n- Comment style\r\n\r\n### Step 2: AST-Based Validation\r\n\r\nUse language-specific AST parsers:\r\n\r\n**TypeScript/JavaScript**:\r\n</execution_process>\n\n### Example:\n**TypeScript/JavaScript AST Validation**:\r\n\r\n```javascript\r\nconst ts = require('typescript');\r\nconst fs = require('fs');\r\n\r\nfunction validateTypeScriptFile(filePath) {\r\n  const sourceCode = fs.readFileSync(filePath, 'utf8');\r\n  const sourceFile = ts.createSourceFile(\r\n    filePath,\r\n    sourceCode,\r\n    ts.ScriptTarget.Latest,\r\n    true\r\n  );\r\n  \r\n  const issues = [];\r\n  \r\n  // Validate naming conventions\r\n  ts.forEachChild(sourceFile, (node) => {\r\n    if (ts.isFunctionDeclaration(node) && node.name) {\r\n      if (!/^[a-z][a-zA-Z0-9]*$/.test(node.name.text)) {\r\n        issues.push({\r\n          line: sourceFile.getLineAndCharacterOfPosition(node.name.getStart()).line + 1,\r\n          message: `Function name \"${node.name.text}\" should be camelCase`\r\n        });\r\n      }\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n```",
          "tokens": 366
        },
        "full": {
          "content": "---\r\nname: code-style-validator\r\ndescription: Programmatic code style validation using AST analysis. Complements (not replaces) code-style rules by providing automated checking and instant feedback.\r\nallowed-tools: read, grep, bash, glob\r\n---\r\n\r\n<identity>\r\nCode Style Validator - Programmatically validates code style using AST (Abstract Syntax Tree) analysis. Complements code-style rules by providing automated checking.\r\n</identity>\r\n\r\n<capabilities>\r\n- Before committing code\r\n- In pre-commit hooks\r\n- During code review\r\n- In CI/CD pipelines\r\n- To enforce consistent code style\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Identify Code Style Patterns\r\n\r\nAnalyze the codebase to identify style patterns:\r\n- Naming conventions (camelCase, PascalCase, snake_case)\r\n- Indentation style (spaces vs tabs, width)\r\n- Import organization\r\n- Function/class structure\r\n- Comment style\r\n\r\n### Step 2: AST-Based Validation\r\n\r\nUse language-specific AST parsers:\r\n\r\n**TypeScript/JavaScript**:\r\n</execution_process>\r\n</instructions>\r\n\r\n<examples>\r\n<code_example>\r\n**TypeScript/JavaScript AST Validation**:\r\n\r\n```javascript\r\nconst ts = require('typescript');\r\nconst fs = require('fs');\r\n\r\nfunction validateTypeScriptFile(filePath) {\r\n  const sourceCode = fs.readFileSync(filePath, 'utf8');\r\n  const sourceFile = ts.createSourceFile(\r\n    filePath,\r\n    sourceCode,\r\n    ts.ScriptTarget.Latest,\r\n    true\r\n  );\r\n  \r\n  const issues = [];\r\n  \r\n  // Validate naming conventions\r\n  ts.forEachChild(sourceFile, (node) => {\r\n    if (ts.isFunctionDeclaration(node) && node.name) {\r\n      if (!/^[a-z][a-zA-Z0-9]*$/.test(node.name.text)) {\r\n        issues.push({\r\n          line: sourceFile.getLineAndCharacterOfPosition(node.name.getStart()).line + 1,\r\n          message: `Function name \"${node.name.text}\" should be camelCase`\r\n        });\r\n      }\r\n    }\r\n  });\r\n  \r\n  return issues;\r\n}\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Python AST Validation**:\r\n\r\n```python\r\nimport ast\r\nimport re\r\n\r\ndef validate_python_file(file_path):\r\n    with open(file_path, 'r') as f:\r\n        source_code = f.read()\r\n    \r\n    tree = ast.parse(source_code)\r\n    issues = []\r\n    \r\n    for node in ast.walk(tree):\r\n        if isinstance(node, ast.FunctionDef):\r\n            if not re.match(r'^[a-z][a-z0-9_]*$', node.name):\r\n                issues.append({\r\n                    'line': node.lineno,\r\n                    'message': f'Function name \"{node.name}\" should be snake_case'\r\n                })\r\n    \r\n    return issues\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Style Checks**:\r\n\r\n**Naming Conventions**:\r\n- Variables: camelCase (JS/TS) or snake_case (Python)\r\n- Functions: camelCase (JS/TS) or snake_case (Python)\r\n- Classes: PascalCase\r\n- Constants: UPPER_CASE\r\n- Private: prefix with underscore\r\n\r\n**Formatting**:\r\n- Indentation: 2 spaces (JS/TS) or 4 spaces (Python)\r\n- Line length: 88-100 characters\r\n- Trailing commas: Yes (JS/TS)\r\n- Semicolons: Consistent usage\r\n\r\n**Structure**:\r\n- Import order: external, internal, relative\r\n- Function length: < 50 lines\r\n- File organization: exports, helpers, types\r\n</code_example>\r\n\r\n<code_example>\r\n**Usage Examples**:\r\n\r\n**Validate Single File**:\r\n```bash\r\nnode .claude/tools/validate-code-style.js src/components/Button.tsx\r\n```\r\n\r\n**Validate Directory**:\r\n```bash\r\nnode .claude/tools/validate-code-style.js src/components/\r\n```\r\n\r\n**Output Format**:\r\n```json\r\n{\r\n  \"file\": \"src/components/Button.tsx\",\r\n  \"valid\": false,\r\n  \"issues\": [\r\n    {\r\n      \"line\": 15,\r\n      \"column\": 10,\r\n      \"rule\": \"naming-convention\",\r\n      \"message\": \"Variable 'UserData' should be camelCase: 'userData'\",\r\n      \"severity\": \"error\"\r\n    },\r\n    {\r\n      \"line\": 23,\r\n      \"column\": 5,\r\n      \"rule\": \"indentation\",\r\n      \"message\": \"Expected 2 spaces, found 4\",\r\n      \"severity\": \"warning\"\r\n    }\r\n  ],\r\n  \"summary\": {\r\n    \"total\": 2,\r\n    \"errors\": 1,\r\n    \"warnings\": 1\r\n  }\r\n}\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Pre-commit Hook**:\r\n\r\n```bash\r\n#!/bin/bash\r\n# .git/hooks/pre-commit\r\nchanged_files=$(git diff --cached --name-only --diff-filter=ACM | grep -E '\\.(ts|tsx|js|jsx|py)$')\r\n\r\nfor file in $changed_files; do\r\n  if ! node .claude/tools/validate-code-style.js \"$file\"; then\r\n    echo \"Code style validation failed for $file\"\r\n    exit 1\r\n  fi\r\ndone\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**CI/CD Integration**:\r\n\r\n```yaml\r\n# .github/workflows/code-style.yml\r\n- name: Validate code style\r\n  run: |\r\n    node .claude/tools/validate-code-style.js src/\r\n    if [ $? -ne 0 ]; then\r\n      echo \"Code style validation failed\"\r\n      exit 1\r\n    fi\r\n```\r\n</code_example>\r\n</examples>\r\n\r\n<instructions>\r\n<best_practices>\r\n1. **Complement, Don't Replace**: This tool complements code-style rules, doesn't replace them\r\n2. **Configurable Rules**: Allow teams to customize validation rules\r\n3. **Auto-fix When Possible**: Provide auto-fix suggestions for common issues\r\n4. **Fast Feedback**: Provide instant feedback during development\r\n5. **Clear Messages**: Show clear error messages with line numbers and suggestions\r\n</best_practices>\r\n</instructions>\r\n\r\n",
          "tokens": 1277
        }
      }
    },
    "fixing-rule-violations": {
      "name": "fixing-rule-violations",
      "one_liner": "No description",
      "key_commands": ["/identity", "/capabilities", "/path", "/context", "/rule-index"],
      "token_count": {
        "minimal": 13,
        "essential": 203,
        "standard": 497,
        "full": 979
      },
      "levels": {
        "minimal": {
          "content": "**fixing-rule-violations**: No description available",
          "tokens": 13
        },
        "essential": {
          "content": "## Skill: fixing-rule-violations\n\nFixing Rule Violations - Provides actionable fix instructions for rule violations by locating violated rules in the index and extracting fix patterns.\n\n### Key Steps:\n: Identify the Violation\r\n\r\nDetermine what rule was violated:\r\n- **From rule-auditor**: Violation report with rule name/path\r\n- **From user**: Description of the issue\r\n- **From code**: Analyze code to identify which rule applies\r\n\r\n\n### Step: Load Rule Index\r\n\r\nLoad the rule index to locate the violated rule:\r\n- @.claude/context/rule-index.json\r\n\r\n\n### Step: Find Violated Rule\r\n\r\nSearch the index for the violated rule:\r\n- **By name**: Search `rules` array for matching name\r\n- **By path**: If path is known, find rule with matching path\r\n- **By technology**: Query `technology_map` if rule type is known",
          "tokens": 203
        },
        "standard": {
          "content": "## Skill: fixing-rule-violations\n\nFixing Rule Violations - Provides actionable fix instructions for rule violations by locating violated rules in the index and extracting fix patterns.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Identify the Violation\r\n\r\nDetermine what rule was violated:\r\n- **From rule-auditor**: Violation report with rule name/path\r\n- **From user**: Description of the issue\r\n- **From code**: Analyze code to identify which rule applies\r\n\r\n### Step 2: Load Rule Index\r\n\r\nLoad the rule index to locate the violated rule:\r\n- @.claude/context/rule-index.json\r\n\r\n### Step 3: Find Violated Rule\r\n\r\nSearch the index for the violated rule:\r\n- **By name**: Search `rules` array for matching name\r\n- **By path**: If path is known, find rule with matching path\r\n- **By technology**: Query `technology_map` if rule type is known\r\n\r\n### Step 4: Load Rule File\r\n\r\nLoad the full rule file to get fix instructions:\r\n- Read the rule file from the path in the index\r\n- Extract sections related to the violation\r\n- Find fix patterns and examples\r\n\r\n### Step 5: Extract Fix Instructions\r\n\r\nFrom the rule file, extract:\r\n- **What's wrong**: The violation pattern\r\n- **Why it's wrong**: Explanation from the rule\r\n- **How to fix**: Specific fix instructions\r\n- **Example**: Before/after code examples\r\n\r\nSee [reference/fix-patterns.md](reference/fix-patterns.md) for common fix patterns.\r\n\r\n### Step 6: Generate Fix Instructions\r\n\r\nProvide actionable fix with:\r\n- **Exact code changes**: Show before/after\r\n- **Step-by-step**: Break down complex fixes\r\n- **Context**: Explain why the fix works\r\n- **Verification**: How to verify the fix\r\n</execution_process>\r\n\r\n<best_practices>\r\n1. **Be Specific**: Provide exact code changes, not vague suggestions\r\n2. **Show Examples**: Always include before/after code\r\n3. **Explain Why**: Help user understand the fix\r\n4. **Step-by-Step**: Break complex fixes into clear steps\r\n5. **Verify**: Include verification steps\r\n</best_practices>\n",
          "tokens": 497
        },
        "full": {
          "content": "---\r\nname: fixing-rule-violations\r\ndescription: Provides detailed fix instructions for coding rule violations. Uses the rule index to locate violated rules and extract fix patterns. Use when code violates rules or when the user asks how to fix compliance issues.\r\n---\r\n\r\n<identity>\r\nFixing Rule Violations - Provides actionable fix instructions for rule violations by locating violated rules in the index and extracting fix patterns.\r\n</identity>\r\n\r\n<capabilities>\r\n- Code violates a specific rule\r\n- User reports a compliance issue\r\n- Rule auditor identifies violations\r\n- User asks \"How do I fix this rule violation?\"\r\n- Code review finds standards violations\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Identify the Violation\r\n\r\nDetermine what rule was violated:\r\n- **From rule-auditor**: Violation report with rule name/path\r\n- **From user**: Description of the issue\r\n- **From code**: Analyze code to identify which rule applies\r\n\r\n### Step 2: Load Rule Index\r\n\r\nLoad the rule index to locate the violated rule:\r\n- @.claude/context/rule-index.json\r\n\r\n### Step 3: Find Violated Rule\r\n\r\nSearch the index for the violated rule:\r\n- **By name**: Search `rules` array for matching name\r\n- **By path**: If path is known, find rule with matching path\r\n- **By technology**: Query `technology_map` if rule type is known\r\n\r\n### Step 4: Load Rule File\r\n\r\nLoad the full rule file to get fix instructions:\r\n- Read the rule file from the path in the index\r\n- Extract sections related to the violation\r\n- Find fix patterns and examples\r\n\r\n### Step 5: Extract Fix Instructions\r\n\r\nFrom the rule file, extract:\r\n- **What's wrong**: The violation pattern\r\n- **Why it's wrong**: Explanation from the rule\r\n- **How to fix**: Specific fix instructions\r\n- **Example**: Before/after code examples\r\n\r\nSee [reference/fix-patterns.md](reference/fix-patterns.md) for common fix patterns.\r\n\r\n### Step 6: Generate Fix Instructions\r\n\r\nProvide actionable fix with:\r\n- **Exact code changes**: Show before/after\r\n- **Step-by-step**: Break down complex fixes\r\n- **Context**: Explain why the fix works\r\n- **Verification**: How to verify the fix\r\n</execution_process>\r\n\r\n<best_practices>\r\n1. **Be Specific**: Provide exact code changes, not vague suggestions\r\n2. **Show Examples**: Always include before/after code\r\n3. **Explain Why**: Help user understand the fix\r\n4. **Step-by-Step**: Break complex fixes into clear steps\r\n5. **Verify**: Include verification steps\r\n</best_practices>\r\n</instructions>\r\n\r\n<examples>\r\n<formatting_example>\r\n**Output Format**\r\n\r\nStructure fix instructions clearly:\r\n\r\n```markdown\r\n## Fix for [Rule Name] Violation\r\n\r\n**Violated Rule**: [rule name]\r\n**Rule Path**: [path from index]\r\n**Violation Location**: [file:line]\r\n\r\n### The Problem\r\n[Description of what's wrong]\r\n\r\n### Why This Violates the Rule\r\n[Explanation from rule file]\r\n\r\n### How to Fix\r\n\r\n**Step 1**: [Action]\r\n\\`\\`\\`[language]\r\n[Code showing fix]\r\n\\`\\`\\`\r\n\r\n**Step 2**: [Action]\r\n\\`\\`\\`[language]\r\n[Code showing fix]\r\n\\`\\`\\`\r\n\r\n### Before and After\r\n\r\n**Before** (violates rule):\r\n\\`\\`\\`[language]\r\n[violating code]\r\n\\`\\`\\`\r\n\r\n**After** (compliant):\r\n\\`\\`\\`[language]\r\n[fixed code]\r\n\\`\\`\\`\r\n\r\n### Verification\r\n[How to verify the fix works]\r\n```\r\n</formatting_example>\r\n</examples>\r\n\r\n<examples>\r\n<code_example>\r\n**Common Violation Types**:\r\n\r\n**TypeScript Violations**:\r\n- Using `any` instead of proper types\r\n- Missing type annotations\r\n- Incorrect interface definitions\r\n\r\n**React/Next.js Violations**:\r\n- Missing 'use client' directive\r\n- Using useEffect for data fetching\r\n- Not using Server Components when possible\r\n\r\n**Python Violations**:\r\n- Missing type hints\r\n- Not using async/await properly\r\n- Incorrect error handling\r\n\r\n**Code Quality Violations**:\r\n- Magic numbers\r\n- Unclear variable names\r\n- Missing error handling\r\n\r\nFor each type, see fix-patterns.md for standard fixes.\r\n</code_example>\r\n</examples>\r\n\r\n",
          "tokens": 979
        }
      }
    },
    "doc-generator": {
      "name": "doc-generator",
      "one_liner": "No description",
      "key_commands": [
        "/Swagger",
        "/identity",
        "/capabilities",
        "/execution_process",
        "/integration"
      ],
      "token_count": {
        "minimal": 11,
        "essential": 197,
        "standard": 399,
        "full": 968
      },
      "levels": {
        "minimal": {
          "content": "**doc-generator**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: doc-generator\n\nDocumentation Generator Skill - Generates comprehensive documentation from code, APIs, and specifications including API docs, developer guides, architecture documentation, and user manuals.\n\n### Key Steps:\n: Identify Documentation Type\r\n\r\nDetermine documentation type:\r\n- **API Documentation**: Endpoint references\r\n- **Developer Guide**: Setup and usage\r\n- **Architecture Docs**: System overview\r\n- **User Manual**: Feature guides\r\n\r\n\n### Step: Extract Information\r\n\r\nGather documentation content:\r\n- Read code and comments\r\n- Analyze API endpoints\r\n- Extract examples\r\n- Understand architecture\r\n\r\n\n### Step: Generate Documentation\r\n\r\nCreate documentation:\r\n- Follow documentation templates\r\n- Include examples\r\n- Add troubleshooting\r\n- Create clear structure",
          "tokens": 197
        },
        "standard": {
          "content": "## Skill: doc-generator\n\nDocumentation Generator Skill - Generates comprehensive documentation from code, APIs, and specifications including API docs, developer guides, architecture documentation, and user manuals.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Identify Documentation Type\r\n\r\nDetermine documentation type:\r\n- **API Documentation**: Endpoint references\r\n- **Developer Guide**: Setup and usage\r\n- **Architecture Docs**: System overview\r\n- **User Manual**: Feature guides\r\n\r\n### Step 2: Extract Information\r\n\r\nGather documentation content:\r\n- Read code and comments\r\n- Analyze API endpoints\r\n- Extract examples\r\n- Understand architecture\r\n\r\n### Step 3: Generate Documentation\r\n\r\nCreate documentation:\r\n- Follow documentation templates\r\n- Include examples\r\n- Add troubleshooting\r\n- Create clear structure\r\n\r\n### Step 4: Validate Documentation\r\n\r\nValidate quality:\r\n- Check completeness\r\n- Verify examples work\r\n- Ensure clarity\r\n- Validate links\r\n</execution_process>\r\n\r\n<integration>\r\n**Integration with Technical Writer Agent**:\r\n- Uses this skill for documentation generation\r\n- Ensures documentation quality\r\n- Validates completeness\r\n\r\n**Integration with Developer Agent**:\r\n- Generates API documentation\r\n- Creates inline documentation\r\n- Updates docs with code changes\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Extract from Code**: Use code as source of truth\r\n2. **Include Examples**: Provide working examples\r\n3. **Keep Updated**: Sync docs with code\r\n4. **Clear Structure**: Organize logically\r\n5. **User-Focused**: Write for users, not system\r\n</best_practices>\n",
          "tokens": 399
        },
        "full": {
          "content": "---\r\nname: doc-generator\r\ndescription: Generates comprehensive documentation from code, APIs, and specifications. Creates API documentation, developer guides, architecture docs, and user manuals with examples and tutorials.\r\nallowed-tools: read, write, glob, search, codebase_search\r\nversion: 1.0\r\nbest_practices:\r\n  - Extract documentation from code comments\r\n  - Generate OpenAPI/Swagger specs from code\r\n  - Create comprehensive examples\r\n  - Include troubleshooting guides\r\n  - Follow documentation standards\r\nerror_handling: graceful\r\nstreaming: supported\r\ntemplates: [api-docs, developer-guide, architecture-docs, user-manual]\r\n---\r\n\r\n<identity>\r\nDocumentation Generator Skill - Generates comprehensive documentation from code, APIs, and specifications including API docs, developer guides, architecture documentation, and user manuals.\r\n</identity>\r\n\r\n<capabilities>\r\n- Generating API documentation\r\n- Creating developer guides\r\n- Documenting architecture\r\n- Creating user manuals\r\n- Generating OpenAPI/Swagger specs\r\n- Updating existing documentation\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Identify Documentation Type\r\n\r\nDetermine documentation type:\r\n- **API Documentation**: Endpoint references\r\n- **Developer Guide**: Setup and usage\r\n- **Architecture Docs**: System overview\r\n- **User Manual**: Feature guides\r\n\r\n### Step 2: Extract Information\r\n\r\nGather documentation content:\r\n- Read code and comments\r\n- Analyze API endpoints\r\n- Extract examples\r\n- Understand architecture\r\n\r\n### Step 3: Generate Documentation\r\n\r\nCreate documentation:\r\n- Follow documentation templates\r\n- Include examples\r\n- Add troubleshooting\r\n- Create clear structure\r\n\r\n### Step 4: Validate Documentation\r\n\r\nValidate quality:\r\n- Check completeness\r\n- Verify examples work\r\n- Ensure clarity\r\n- Validate links\r\n</execution_process>\r\n\r\n<integration>\r\n**Integration with Technical Writer Agent**:\r\n- Uses this skill for documentation generation\r\n- Ensures documentation quality\r\n- Validates completeness\r\n\r\n**Integration with Developer Agent**:\r\n- Generates API documentation\r\n- Creates inline documentation\r\n- Updates docs with code changes\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Extract from Code**: Use code as source of truth\r\n2. **Include Examples**: Provide working examples\r\n3. **Keep Updated**: Sync docs with code\r\n4. **Clear Structure**: Organize logically\r\n5. **User-Focused**: Write for users, not system\r\n</best_practices>\r\n</instructions>\r\n\r\n<examples>\r\n<formatting_example>\r\n**API Documentation**\r\n\r\n```markdown\r\n# Users API\r\n\r\n## Endpoints\r\n\r\n### GET /api/users\r\nList all users with pagination.\r\n\r\n**Query Parameters:**\r\n- `page` (number): Page number (default: 1)\r\n- `limit` (number): Items per page (default: 10)\r\n\r\n**Response:**\r\n```json\r\n{\r\n  \"data\": [\r\n    {\r\n      \"id\": \"uuid\",\r\n      \"email\": \"user@example.com\",\r\n      \"name\": \"User Name\"\r\n    }\r\n  ],\r\n  \"pagination\": {\r\n    \"page\": 1,\r\n    \"limit\": 10,\r\n    \"total\": 100\r\n  }\r\n}\r\n```\r\n\r\n**Example:**\r\n```bash\r\ncurl -X GET \"http://localhost:3000/api/users?page=1&limit=10\"\r\n```\r\n```\r\n</formatting_example>\r\n\r\n<formatting_example>\r\n**Developer Guide**\r\n\r\n```markdown\r\n# Developer Guide\r\n\r\n## Getting Started\r\n\r\n### Prerequisites\r\n- Node.js 18+\r\n- pnpm 8+\r\n\r\n### Installation\r\n```bash\r\npnpm install\r\n```\r\n\r\n### Development\r\n```bash\r\npnpm dev\r\n```\r\n\r\n## Architecture\r\n\r\n[Architecture overview]\r\n\r\n## Development Workflow\r\n\r\n[Development process]\r\n```\r\n</formatting_example>\r\n</examples>\r\n\r\n<examples>\r\n<usage_example>\r\n**Example Commands**:\r\n\r\n```\r\n# Generate API documentation\r\nGenerate API documentation for app/api/users\r\n\r\n# Generate developer guide\r\nGenerate developer guide for this project\r\n\r\n# Generate architecture docs\r\nGenerate architecture documentation\r\n\r\n# Generate OpenAPI spec\r\nGenerate OpenAPI specification from API routes\r\n```\r\n</usage_example>\r\n</examples>\r\n\r\n",
          "tokens": 968
        }
      }
    },
    "diagram-generator": {
      "name": "diagram-generator",
      "one_liner": "No description",
      "key_commands": [
        "/identity",
        "/capabilities",
        "/execution_process",
        "/integration",
        "/best_practices"
      ],
      "token_count": {
        "minimal": 12,
        "essential": 229,
        "standard": 548,
        "full": 1165
      },
      "levels": {
        "minimal": {
          "content": "**diagram-generator**: No description available",
          "tokens": 12
        },
        "essential": {
          "content": "## Skill: diagram-generator\n\nDiagram Generator Skill - Generates architecture, database, and system diagrams using Mermaid syntax to visualize system structure, relationships, and flows.\n\n### Key Steps:\n: Identify Diagram Type\r\n\r\nDetermine what type of diagram is needed:\r\n- **Architecture Diagram**: System structure and components\r\n- **Database Diagram**: Schema and relationships\r\n- **Component Diagram**: Component interactions\r\n- **Sequence Diagram**: Process flows\r\n- **Flowchart**: Decision flows\r\n\r\n\n### Step: Extract Structure\r\n\r\nAnalyze code and documentation:\r\n- Read architecture documents\r\n- Analyze component structure\r\n- Extract database schema\r\n- Identify relationships\r\n- Understand data flows\r\n\r\n\n### Step: Generate Mermaid Diagram\r\n\r\nCreate diagram using Mermaid syntax:\r\n- Use appropriate diagram type\r\n- Define nodes and relationships\r\n- Add labels and descriptions\r\n- Include styling if needed",
          "tokens": 229
        },
        "standard": {
          "content": "## Skill: diagram-generator\n\nDiagram Generator Skill - Generates architecture, database, and system diagrams using Mermaid syntax to visualize system structure, relationships, and flows.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Identify Diagram Type\r\n\r\nDetermine what type of diagram is needed:\r\n- **Architecture Diagram**: System structure and components\r\n- **Database Diagram**: Schema and relationships\r\n- **Component Diagram**: Component interactions\r\n- **Sequence Diagram**: Process flows\r\n- **Flowchart**: Decision flows\r\n\r\n### Step 2: Extract Structure\r\n\r\nAnalyze code and documentation:\r\n- Read architecture documents\r\n- Analyze component structure\r\n- Extract database schema\r\n- Identify relationships\r\n- Understand data flows\r\n\r\n### Step 3: Generate Mermaid Diagram\r\n\r\nCreate diagram using Mermaid syntax:\r\n- Use appropriate diagram type\r\n- Define nodes and relationships\r\n- Add labels and descriptions\r\n- Include styling if needed\r\n\r\n### Step 4: Embed in Documentation\r\n\r\nEmbed diagram in markdown:\r\n- Use mermaid code blocks\r\n- Add diagram description\r\n- Reference in documentation\r\n</execution_process>\r\n\r\n<integration>\r\n**Integration with Architect Agent**:\r\n- Generates architecture diagrams\r\n- Documents system structure\r\n- Visualizes component relationships\r\n\r\n**Integration with Database Architect Agent**:\r\n- Generates database schema diagrams\r\n- Documents table relationships\r\n- Visualizes data models\r\n\r\n**Integration with Technical Writer Agent**:\r\n- Embeds diagrams in documentation\r\n- Creates visual documentation\r\n- Enhances documentation clarity\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Use Mermaid**: Standard syntax for compatibility\r\n2. **Keep Clear**: Simple, readable diagrams\r\n3. **Show Relationships**: Include all important connections\r\n4. **Add Labels**: Clear node and edge labels\r\n5. **Update Regularly**: Keep diagrams current with code\r\n</best_practices>\n\n### Example:\n**Architecture Diagram**\r\n\r\n```mermaid\r\ngraph TB\r\n    Client[Client Application]\r\n    API[API Gateway]\r\n    Auth[Auth Service]\r\n    User[User Service]\r\n    DB[(Database)]\r\n    \r\n    Client --> API\r\n    API --> Auth\r\n    API --> User\r\n    User --> DB\r\n    Auth --> DB\r\n```",
          "tokens": 548
        },
        "full": {
          "content": "---\r\nname: diagram-generator\r\ndescription: Generates architecture, database, and system diagrams using Mermaid syntax. Creates visual representations of system architecture, database schemas, component relationships, and data flows.\r\nallowed-tools: read, write, glob, search, codebase_search\r\nversion: 1.0\r\nbest_practices:\r\n  - Use Mermaid syntax for diagrams\r\n  - Extract structure from code and documentation\r\n  - Create clear, readable diagrams\r\n  - Include relationships and dependencies\r\n  - Generate both high-level and detailed views\r\nerror_handling: graceful\r\nstreaming: supported\r\ntemplates: [architecture-diagram, database-diagram, component-diagram, sequence-diagram]\r\n---\r\n\r\n<identity>\r\nDiagram Generator Skill - Generates architecture, database, and system diagrams using Mermaid syntax to visualize system structure, relationships, and flows.\r\n</identity>\r\n\r\n<capabilities>\r\n- Creating architecture diagrams\r\n- Documenting database schemas\r\n- Visualizing component relationships\r\n- Documenting data flows\r\n- Creating sequence diagrams\r\n- Generating system overviews\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Identify Diagram Type\r\n\r\nDetermine what type of diagram is needed:\r\n- **Architecture Diagram**: System structure and components\r\n- **Database Diagram**: Schema and relationships\r\n- **Component Diagram**: Component interactions\r\n- **Sequence Diagram**: Process flows\r\n- **Flowchart**: Decision flows\r\n\r\n### Step 2: Extract Structure\r\n\r\nAnalyze code and documentation:\r\n- Read architecture documents\r\n- Analyze component structure\r\n- Extract database schema\r\n- Identify relationships\r\n- Understand data flows\r\n\r\n### Step 3: Generate Mermaid Diagram\r\n\r\nCreate diagram using Mermaid syntax:\r\n- Use appropriate diagram type\r\n- Define nodes and relationships\r\n- Add labels and descriptions\r\n- Include styling if needed\r\n\r\n### Step 4: Embed in Documentation\r\n\r\nEmbed diagram in markdown:\r\n- Use mermaid code blocks\r\n- Add diagram description\r\n- Reference in documentation\r\n</execution_process>\r\n\r\n<integration>\r\n**Integration with Architect Agent**:\r\n- Generates architecture diagrams\r\n- Documents system structure\r\n- Visualizes component relationships\r\n\r\n**Integration with Database Architect Agent**:\r\n- Generates database schema diagrams\r\n- Documents table relationships\r\n- Visualizes data models\r\n\r\n**Integration with Technical Writer Agent**:\r\n- Embeds diagrams in documentation\r\n- Creates visual documentation\r\n- Enhances documentation clarity\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Use Mermaid**: Standard syntax for compatibility\r\n2. **Keep Clear**: Simple, readable diagrams\r\n3. **Show Relationships**: Include all important connections\r\n4. **Add Labels**: Clear node and edge labels\r\n5. **Update Regularly**: Keep diagrams current with code\r\n</best_practices>\r\n</instructions>\r\n\r\n<examples>\r\n<code_example>\r\n**Architecture Diagram**\r\n\r\n```mermaid\r\ngraph TB\r\n    Client[Client Application]\r\n    API[API Gateway]\r\n    Auth[Auth Service]\r\n    User[User Service]\r\n    DB[(Database)]\r\n    \r\n    Client --> API\r\n    API --> Auth\r\n    API --> User\r\n    User --> DB\r\n    Auth --> DB\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Database Schema Diagram**\r\n\r\n```mermaid\r\nerDiagram\r\n    USERS ||--o{ ORDERS : places\r\n    USERS {\r\n        uuid id PK\r\n        string email\r\n        string name\r\n    }\r\n    ORDERS ||--|{ ORDER_ITEMS : contains\r\n    ORDERS {\r\n        uuid id PK\r\n        uuid user_id FK\r\n        date created_at\r\n    }\r\n    ORDER_ITEMS {\r\n        uuid id PK\r\n        uuid order_id FK\r\n        uuid product_id FK\r\n        int quantity\r\n    }\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Component Diagram**\r\n\r\n```mermaid\r\ngraph LR\r\n    A[Component A] --> B[Component B]\r\n    A --> C[Component C]\r\n    B --> D[Component D]\r\n    C --> D\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Sequence Diagram**\r\n\r\n```mermaid\r\nsequenceDiagram\r\n    participant User\r\n    participant API\r\n    participant Auth\r\n    participant DB\r\n    \r\n    User->>API: Login Request\r\n    API->>Auth: Validate Credentials\r\n    Auth->>DB: Query User\r\n    DB-->>Auth: User Data\r\n    Auth-->>API: JWT Token\r\n    API-->>User: Auth Response\r\n```\r\n</code_example>\r\n</examples>\r\n\r\n<examples>\r\n<usage_example>\r\n**Example Commands**:\r\n\r\n```\r\n# Generate architecture diagram\r\nGenerate architecture diagram for the authentication system\r\n\r\n# Generate database schema diagram\r\nGenerate database schema diagram for the user management module\r\n\r\n# Generate component diagram\r\nGenerate component diagram showing API service relationships\r\n\r\n# Generate sequence diagram\r\nGenerate sequence diagram for user login flow\r\n```\r\n</usage_example>\r\n</examples>\r\n\r\n",
          "tokens": 1165
        }
      }
    },
    "summarizer": {
      "name": "summarizer",
      "one_liner": "No description",
      "key_commands": ["/context", "/runs", "/artifacts", "/docs", "/SUMMARIZATION_PATTERNS"],
      "token_count": {
        "minimal": 10,
        "essential": 6,
        "standard": 6,
        "full": 790
      },
      "levels": {
        "minimal": {
          "content": "**summarizer**: No description available",
          "tokens": 10
        },
        "essential": {
          "content": "## Skill: summarizer\n",
          "tokens": 6
        },
        "standard": {
          "content": "## Skill: summarizer\n",
          "tokens": 6
        },
        "full": {
          "content": "---\r\nname: summarizer\r\ndescription: Generate summaries of documents, code, and conversations. Use for documentation, reports, and content condensation.\r\nallowed-tools: read, write, grep, glob\r\nversion: 1.0\r\nbest_practices:\r\n  - Specify summary length\r\n  - Focus on key points\r\n  - Maintain context\r\n  - Preserve important details\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# Summarizer Skill\r\n\r\n## Identity\r\n\r\nSummarizer - Generates concise summaries of documents, code, conversations, and other content.\r\n\r\n## Capabilities\r\n\r\n- **Document Summarization**: Summarize long documents\r\n- **Code Summarization**: Summarize code files and functions\r\n- **Conversation Summarization**: Summarize conversation threads\r\n- **Multi-Document Summarization**: Summarize multiple documents\r\n\r\n## Usage\r\n\r\n### Document Summarization\r\n\r\n**When to Use**:\r\n- Long documents need condensation\r\n- Executive summaries needed\r\n- Quick content overview\r\n- Documentation summaries\r\n\r\n**How to Invoke**:\r\n```\r\n\"Summarize the project requirements document\"\r\n\"Create an executive summary of the technical spec\"\r\n\"Generate a summary of the meeting notes\"\r\n```\r\n\r\n**What It Does**:\r\n- Analyzes document content\r\n- Extracts key points\r\n- Generates concise summary\r\n- Preserves important details\r\n\r\n### Code Summarization\r\n\r\n**When to Use**:\r\n- Large codebases need overview\r\n- Function documentation\r\n- Code review summaries\r\n- Architecture summaries\r\n\r\n**How to Invoke**:\r\n```\r\n\"Summarize the authentication module\"\r\n\"Create a summary of the API routes\"\r\n\"Generate an overview of the codebase structure\"\r\n```\r\n\r\n## Best Practices\r\n\r\n1. **Specify Length**: Request specific summary length\r\n2. **Key Points**: Focus on important information\r\n3. **Context Preservation**: Maintain relevant context\r\n4. **Detail Balance**: Preserve critical details\r\n5. **Structure**: Use clear structure and formatting\r\n\r\n## Integration\r\n\r\n### With Technical Writer\r\n\r\nSummarizer helps technical writer:\r\n- Create executive summaries\r\n- Condense documentation\r\n- Generate overviews\r\n- Create abstracts\r\n\r\n### With Artifact Publisher\r\n\r\nSummaries can be published as artifacts:\r\n- Save to `.claude/context/runs/{run-id}/artifacts/` (use `path-resolver.mjs` to resolve paths)\r\n- Register in artifact registry via `run-manager.mjs`\r\n- Reference in workflow outputs\r\n\r\n## Examples\r\n\r\n### Example 1: Document Summary\r\n\r\n```\r\nUser: \"Summarize the project requirements document\"\r\n\r\nSummarizer:\r\n1. Analyzes document\r\n2. Extracts key points:\r\n   - Project goals\r\n   - Key features\r\n   - Technical requirements\r\n   - Timeline\r\n3. Generates concise summary\r\n4. Preserves critical details\r\n```\r\n\r\n### Example 2: Code Summary\r\n\r\n```\r\nUser: \"Summarize the authentication module\"\r\n\r\nSummarizer:\r\n1. Analyzes code files\r\n2. Extracts:\r\n   - Main components\r\n   - Key functions\r\n   - Authentication flow\r\n   - Security features\r\n3. Generates overview\r\n```\r\n\r\n## Related Skills\r\n\r\n- **technical-writer**: Use summaries in documentation\r\n- **artifact-publisher**: Publish summaries as artifacts\r\n\r\n## Related Documentation\r\n\r\n- [Summarization Patterns](../docs/SUMMARIZATION_PATTERNS.md) - Comprehensive guide\r\n\r\n",
          "tokens": 790
        }
      }
    },
    "pdf-generator": {
      "name": "pdf-generator",
      "one_liner": "No description",
      "key_commands": ["/context", "/runs", "/artifacts", "/docs", "/DOCUMENT_GENERATION"],
      "token_count": {
        "minimal": 11,
        "essential": 6,
        "standard": 6,
        "full": 1193
      },
      "levels": {
        "minimal": {
          "content": "**pdf-generator**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: pdf-generator\n",
          "tokens": 6
        },
        "standard": {
          "content": "## Skill: pdf-generator\n",
          "tokens": 6
        },
        "full": {
          "content": "---\r\nname: pdf-generator\r\ndescription: Generate formatted PDF documents with text, tables, and images. Use for reports, documentation, and formal documents.\r\nallowed-tools: read, write, memory\r\nversion: 1.0\r\nbest_practices:\r\n  - Use structured content\r\n  - Include tables and formatting\r\n  - Apply consistent styling\r\n  - Organize content logically\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# PDF Generator Skill\r\n\r\n## Identity\r\n\r\nPDF Generator - Creates formatted PDF documents with text, tables, and images using Claude's built-in `pdf` skill.\r\n\r\n## Capabilities\r\n\r\n- **Document Creation**: Generate formatted PDF documents\r\n- **Text Formatting**: Rich text with formatting\r\n- **Tables**: Create structured tables\r\n- **Images**: Include images and graphics\r\n- **Professional Layout**: Professional document structure\r\n\r\n## Usage\r\n\r\n### Basic PDF Generation\r\n\r\n**When to Use**:\r\n- Formal reports\r\n- Documentation\r\n- Technical specifications\r\n- Business documents\r\n- Legal documents\r\n\r\n**How to Invoke**:\r\n```\r\n\"Generate a PDF report summarizing the project\"\r\n\"Create a technical documentation PDF\"\r\n\"Generate a formal business document\"\r\n```\r\n\r\n**What It Does**:\r\n- Uses Claude's built-in `pdf` skill (skill_id: `pdf`)\r\n- Creates PDF documents with formatting\r\n- Includes tables, images, and structured content\r\n- Returns file_id for download\r\n\r\n### Advanced Features\r\n\r\n**Document Structure**:\r\n- Title page\r\n- Table of contents\r\n- Sections and subsections\r\n- Appendices\r\n\r\n**Content Types**:\r\n- Text with formatting\r\n- Tables and data\r\n- Images and graphics\r\n- Charts and diagrams\r\n\r\n**Formatting**:\r\n- Professional styling\r\n- Consistent formatting\r\n- Brand guidelines\r\n- Visual hierarchy\r\n\r\n## Best Practices\r\n\r\n### Document Structure\r\n\r\n**Recommended Approach**:\r\n- **Clear organization**: Logical sections and flow\r\n- **Structured content**: Use headings and subheadings\r\n- **Visual elements**: Tables, charts, images\r\n- **Professional polish**: Consistent formatting\r\n\r\n**For Complex Documents**:\r\n1. **Plan structure**: Outline before generation\r\n2. **Use templates**: Consistent formatting\r\n3. **Include metadata**: Title, author, date\r\n4. **Professional quality**: High-quality output\r\n\r\n### Performance Tips\r\n\r\n- **PDF generation**: Very reliable for complex content\r\n- **Structured data**: More efficient than prose\r\n- **Batch operations**: Process multiple documents\r\n- **Template reuse**: Use consistent templates\r\n\r\n## Integration\r\n\r\n### With Other Document Generators\r\n\r\nPDF can combine content from:\r\n- Excel data and charts\r\n- PowerPoint slides\r\n- Text documents\r\n- Images and graphics\r\n\r\n### With Artifact Publisher\r\n\r\nPDF files can be published as artifacts:\r\n- Save to `.claude/context/runs/{run-id}/artifacts/` (use `path-resolver.mjs` to resolve paths)\r\n- Register in artifact registry via `run-manager.mjs`\r\n- Reference in workflow outputs\r\n\r\n### With Workflows\r\n\r\nPDF generation integrates with workflows:\r\n- Documentation workflows\r\n- Reporting workflows\r\n- Publication workflows\r\n\r\n## Examples\r\n\r\n### Example 1: Technical Report\r\n\r\n```\r\nUser: \"Generate a PDF report summarizing the project\"\r\n\r\nPDF Generator:\r\n1. Creates PDF document with:\r\n   - Title page\r\n   - Executive summary\r\n   - Technical details\r\n   - Results and analysis\r\n   - Conclusions\r\n2. Includes tables and charts\r\n3. Applies professional formatting\r\n4. Returns file_id for download\r\n```\r\n\r\n### Example 2: Documentation\r\n\r\n```\r\nUser: \"Create a technical documentation PDF\"\r\n\r\nPDF Generator:\r\n1. Creates documentation PDF\r\n2. Includes code examples\r\n3. Structures content logically\r\n4. Adds table of contents\r\n```\r\n\r\n### Example 3: Business Document\r\n\r\n```\r\nUser: \"Generate a formal business document\"\r\n\r\nPDF Generator:\r\n1. Creates formal document\r\n2. Includes required sections\r\n3. Applies business formatting\r\n4. Adds signatures and metadata\r\n```\r\n\r\n## Technical Details\r\n\r\n### API Usage\r\n\r\nUses Claude's beta Skills API:\r\n```python\r\nresponse = client.beta.messages.create(\r\n    model=\"claude-sonnet-4-5\",\r\n    container={\"type\": \"skills\", \"skills\": [{\"type\": \"anthropic\", \"skill_id\": \"pdf\", \"version\": \"latest\"}]},\r\n    messages=[{\"role\": \"user\", \"content\": \"Create PDF document...\"}]\r\n)\r\n```\r\n\r\n### File Download\r\n\r\nFiles are returned as `file_id`:\r\n```python\r\nfile_id = response.content[0].file_id\r\nfile_content = client.beta.files.content(file_id)\r\n```\r\n\r\n## Related Skills\r\n\r\n- **excel-generator**: Create data for PDFs\r\n- **powerpoint-generator**: Convert slides to PDF\r\n- **artifact-publisher**: Publish PDFs as artifacts\r\n\r\n## Related Documentation\r\n\r\n- [Document Generation Guide](../docs/DOCUMENT_GENERATION.md) - Comprehensive guide\r\n- [Skills Cookbook](https://github.com/anthropics/anthropic-cookbook/tree/main/skills) - Reference implementation\r\n\r\n",
          "tokens": 1193
        }
      }
    },
    "powerpoint-generator": {
      "name": "powerpoint-generator",
      "one_liner": "No description",
      "key_commands": ["/context", "/artifacts", "/docs", "/DOCUMENT_GENERATION", "/github"],
      "token_count": {
        "minimal": 13,
        "essential": 8,
        "standard": 8,
        "full": 1285
      },
      "levels": {
        "minimal": {
          "content": "**powerpoint-generator**: No description available",
          "tokens": 13
        },
        "essential": {
          "content": "## Skill: powerpoint-generator\n",
          "tokens": 8
        },
        "standard": {
          "content": "## Skill: powerpoint-generator\n",
          "tokens": 8
        },
        "full": {
          "content": "---\r\nname: powerpoint-generator\r\ndescription: Generate professional PowerPoint presentations with slides, charts, and transitions. Use for executive presentations, reports, and visual communication.\r\nallowed-tools: read, write, memory\r\nversion: 1.0\r\nbest_practices:\r\n  - Use clear slide structure\r\n  - Include visualizations from data\r\n  - Apply consistent formatting\r\n  - Keep slides focused and concise\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# PowerPoint Generator Skill\r\n\r\n## Identity\r\n\r\nPowerPoint Generator - Creates professional PowerPoint presentations with slides, charts, and transitions using Claude's built-in `pptx` skill.\r\n\r\n## Capabilities\r\n\r\n- **Presentation Creation**: Generate multi-slide presentations\r\n- **Charts and Visualizations**: Include charts and graphs\r\n- **Formatting**: Apply professional formatting and styling\r\n- **Transitions**: Add slide transitions and animations\r\n- **Content Organization**: Structure content logically\r\n\r\n## Usage\r\n\r\n### Basic PowerPoint Generation\r\n\r\n**When to Use**:\r\n- Executive presentations\r\n- Quarterly reports\r\n- Project updates\r\n- Training materials\r\n- Visual communication\r\n\r\n**How to Invoke**:\r\n```\r\n\"Generate a PowerPoint presentation for Q4 results\"\r\n\"Create an executive presentation from the financial data\"\r\n\"Generate a project update presentation\"\r\n```\r\n\r\n**What It Does**:\r\n- Uses Claude's built-in `pptx` skill (skill_id: `pptx`)\r\n- Creates PowerPoint presentations with multiple slides\r\n- Includes charts, formatting, and transitions\r\n- Returns file_id for download\r\n\r\n### Advanced Features\r\n\r\n**Multi-Slide Presentations**:\r\n- Title slide\r\n- Content slides\r\n- Summary slides\r\n- Appendix slides\r\n\r\n**Charts and Visualizations**:\r\n- Data visualizations from Excel\r\n- Trend charts\r\n- Comparison charts\r\n- Process diagrams\r\n\r\n**Formatting**:\r\n- Professional templates\r\n- Consistent styling\r\n- Brand guidelines\r\n- Visual hierarchy\r\n\r\n## Best Practices\r\n\r\n### Presentation Structure\r\n\r\n**Recommended Approach**:\r\n- **Clear slide structure**: Title, content, summary\r\n- **Visual focus**: Use charts and diagrams\r\n- **Consistent formatting**: Apply templates\r\n- **Concise content**: Keep slides focused\r\n\r\n**For Complex Presentations**:\r\n1. **Create from data**: Use Excel data as source\r\n2. **Visualize key insights**: Focus on important metrics\r\n3. **Tell a story**: Logical flow and narrative\r\n4. **Professional polish**: Consistent formatting\r\n\r\n### Performance Tips\r\n\r\n- **PowerPoint generation**: Very reliable for complex content\r\n- **Chart integration**: Works well with Excel data\r\n- **Batch operations**: Process multiple presentations\r\n- **Template reuse**: Use consistent templates\r\n\r\n## Integration\r\n\r\n### With Excel Generator\r\n\r\nPowerPoint can use Excel data:\r\n- Import charts from Excel\r\n- Reference data from spreadsheets\r\n- Create visualizations from analysis\r\n\r\n### With Artifact Publisher\r\n\r\nPowerPoint files can be published as artifacts:\r\n- Save to `.claude/context/artifacts/`\r\n- Include in artifact manifests\r\n- Reference in workflow outputs\r\n\r\n### With Workflows\r\n\r\nPowerPoint generation integrates with workflows:\r\n- Reporting workflows\r\n- Presentation workflows\r\n- Communication workflows\r\n\r\n## Examples\r\n\r\n### Example 1: Executive Presentation\r\n\r\n```\r\nUser: \"Generate a PowerPoint presentation for Q4 results\"\r\n\r\nPowerPoint Generator:\r\n1. Creates presentation with slides:\r\n   - Title slide\r\n   - Executive summary\r\n   - Financial highlights\r\n   - Key metrics\r\n   - Trends and analysis\r\n   - Next steps\r\n2. Includes charts from Excel data\r\n3. Applies professional formatting\r\n4. Returns file_id for download\r\n```\r\n\r\n### Example 2: Project Update\r\n\r\n```\r\nUser: \"Create a project update presentation\"\r\n\r\nPowerPoint Generator:\r\n1. Creates presentation with:\r\n   - Project overview\r\n   - Progress update\r\n   - Milestones achieved\r\n   - Challenges and solutions\r\n   - Next steps\r\n2. Includes visualizations\r\n3. Applies project branding\r\n```\r\n\r\n### Example 3: Training Materials\r\n\r\n```\r\nUser: \"Generate training presentation\"\r\n\r\nPowerPoint Generator:\r\n1. Creates educational presentation\r\n2. Includes diagrams and examples\r\n3. Structures content logically\r\n4. Adds interactive elements\r\n```\r\n\r\n## Technical Details\r\n\r\n### API Usage\r\n\r\nUses Claude's beta Skills API:\r\n```python\r\nresponse = client.beta.messages.create(\r\n    model=\"claude-sonnet-4-5\",\r\n    container={\"type\": \"skills\", \"skills\": [{\"type\": \"anthropic\", \"skill_id\": \"pptx\", \"version\": \"latest\"}]},\r\n    messages=[{\"role\": \"user\", \"content\": \"Create PowerPoint presentation...\"}]\r\n)\r\n```\r\n\r\n### File Download\r\n\r\nFiles are returned as `file_id`:\r\n```python\r\nfile_id = response.content[0].file_id\r\nfile_content = client.beta.files.content(file_id)\r\n```\r\n\r\n## Related Skills\r\n\r\n- **excel-generator**: Create data for presentations\r\n- **pdf-generator**: Convert PowerPoint to PDF\r\n- **artifact-publisher**: Publish presentations as artifacts\r\n\r\n## Related Documentation\r\n\r\n- [Document Generation Guide](../docs/DOCUMENT_GENERATION.md) - Comprehensive guide\r\n- [Skills Cookbook](https://github.com/anthropics/anthropic-cookbook/tree/main/skills) - Reference implementation\r\n\r\n",
          "tokens": 1285
        }
      }
    },
    "excel-generator": {
      "name": "excel-generator",
      "one_liner": "No description",
      "key_commands": ["/CSV", "/context", "/artifacts", "/docs", "/DOCUMENT_GENERATION"],
      "token_count": {
        "minimal": 12,
        "essential": 7,
        "standard": 7,
        "full": 1283
      },
      "levels": {
        "minimal": {
          "content": "**excel-generator**: No description available",
          "tokens": 12
        },
        "essential": {
          "content": "## Skill: excel-generator\n",
          "tokens": 7
        },
        "standard": {
          "content": "## Skill: excel-generator\n",
          "tokens": 7
        },
        "full": {
          "content": "---\r\nname: excel-generator\r\ndescription: Generate Excel workbooks with formulas, charts, and formatting. Use for financial reports, data analysis, dashboards, and structured data presentation.\r\nallowed-tools: read, write, memory\r\nversion: 1.0\r\nbest_practices:\r\n  - Use 2-3 sheets per workbook for optimal performance\r\n  - Focus each sheet on a specific purpose\r\n  - Add complexity incrementally\r\n  - Use structured data (JSON/CSV) for efficiency\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# Excel Generator Skill\r\n\r\n## Identity\r\n\r\nExcel Generator - Creates professional Excel workbooks with formulas, charts, and formatting using Claude's built-in `xlsx` skill.\r\n\r\n## Capabilities\r\n\r\n- **Workbook Creation**: Generate multi-sheet Excel workbooks\r\n- **Formulas and Calculations**: Include complex formulas and calculations\r\n- **Charts and Visualizations**: Create charts and graphs\r\n- **Formatting**: Apply professional formatting and styling\r\n- **Data Analysis**: Generate pivot tables and analysis sheets\r\n\r\n## Usage\r\n\r\n### Basic Excel Generation\r\n\r\n**When to Use**:\r\n- Financial reports and analysis\r\n- Data dashboards\r\n- Budget planning\r\n- Performance metrics\r\n- Structured data presentation\r\n\r\n**How to Invoke**:\r\n```\r\n\"Generate an Excel workbook with Q4 financial data\"\r\n\"Create a budget spreadsheet with formulas\"\r\n\"Generate a data analysis dashboard in Excel\"\r\n```\r\n\r\n**What It Does**:\r\n- Uses Claude's built-in `xlsx` skill (skill_id: `xlsx`)\r\n- Creates Excel workbooks with multiple sheets\r\n- Includes formulas, charts, and formatting\r\n- Returns file_id for download\r\n\r\n### Advanced Features\r\n\r\n**Multi-Sheet Workbooks**:\r\n- Create 2-3 sheets per workbook (optimal performance)\r\n- Each sheet focused on specific purpose\r\n- Link data between sheets\r\n\r\n**Formulas and Calculations**:\r\n- Complex financial formulas\r\n- Statistical calculations\r\n- Data aggregations\r\n- Conditional logic\r\n\r\n**Charts and Visualizations**:\r\n- Line charts for trends\r\n- Bar charts for comparisons\r\n- Pie charts for distributions\r\n- Scatter plots for correlations\r\n\r\n## Best Practices\r\n\r\n### Workbook Structure\r\n\r\n**Recommended Approach**:\r\n- **2-3 sheets per workbook** - Works reliably and generates quickly\r\n- **Focus each sheet** on a specific purpose (e.g., P&L, metrics, charts)\r\n- **Add complexity incrementally** - Start simple, then enhance\r\n\r\n**For Complex Dashboards**:\r\n1. **Create multiple focused files** instead of one complex file\r\n   - Example: `financial_pnl.xlsx`, `balance_sheet.xlsx`, `kpi_dashboard.xlsx`\r\n2. **Use the pipeline pattern** to create and enhance files sequentially\r\n3. **Combine files programmatically** using pandas or openpyxl if needed\r\n\r\n### Performance Tips\r\n\r\n- **Simple 2-sheet dashboards**: ~1-2 minutes\r\n- **Structured data (JSON/CSV)**: More efficient than prose\r\n- **Batch operations**: Process multiple files in a single conversation\r\n- **Cache reuse**: Use container IDs to reuse loaded skills\r\n\r\n## Integration\r\n\r\n### With Artifact Publisher\r\n\r\nExcel files can be published as artifacts:\r\n- Save to `.claude/context/artifacts/`\r\n- Include in artifact manifests\r\n- Reference in workflow outputs\r\n\r\n### With Workflows\r\n\r\nExcel generation integrates with workflows:\r\n- Financial reporting workflows\r\n- Data analysis workflows\r\n- Dashboard generation workflows\r\n\r\n## Examples\r\n\r\n### Example 1: Financial Report\r\n\r\n```\r\nUser: \"Generate a Q4 financial report in Excel\"\r\n\r\nExcel Generator:\r\n1. Creates workbook with 3 sheets:\r\n   - P&L Statement\r\n   - Balance Sheet\r\n   - Cash Flow\r\n2. Includes formulas for calculations\r\n3. Adds charts for visualization\r\n4. Applies professional formatting\r\n5. Returns file_id for download\r\n```\r\n\r\n### Example 2: Data Dashboard\r\n\r\n```\r\nUser: \"Create a KPI dashboard in Excel\"\r\n\r\nExcel Generator:\r\n1. Creates workbook with 2 sheets:\r\n   - Metrics Summary\r\n   - Trend Analysis\r\n2. Includes pivot tables\r\n3. Adds charts for key metrics\r\n4. Formats for presentation\r\n```\r\n\r\n### Example 3: Budget Planning\r\n\r\n```\r\nUser: \"Generate a budget spreadsheet with formulas\"\r\n\r\nExcel Generator:\r\n1. Creates budget workbook\r\n2. Includes formulas for totals and variances\r\n3. Adds conditional formatting\r\n4. Creates summary charts\r\n```\r\n\r\n## Technical Details\r\n\r\n### API Usage\r\n\r\nUses Claude's beta Skills API:\r\n```python\r\nresponse = client.beta.messages.create(\r\n    model=\"claude-sonnet-4-5\",\r\n    container={\"type\": \"skills\", \"skills\": [{\"type\": \"anthropic\", \"skill_id\": \"xlsx\", \"version\": \"latest\"}]},\r\n    messages=[{\"role\": \"user\", \"content\": \"Create Excel workbook...\"}]\r\n)\r\n```\r\n\r\n### File Download\r\n\r\nFiles are returned as `file_id`:\r\n```python\r\nfile_id = response.content[0].file_id\r\nfile_content = client.beta.files.content(file_id)\r\n```\r\n\r\n## Related Skills\r\n\r\n- **powerpoint-generator**: Create presentations from Excel data\r\n- **pdf-generator**: Convert Excel to PDF\r\n- **artifact-publisher**: Publish Excel files as artifacts\r\n\r\n## Related Documentation\r\n\r\n- [Document Generation Guide](../docs/DOCUMENT_GENERATION.md) - Comprehensive guide\r\n- [Skills Cookbook](https://github.com/anthropics/anthropic-cookbook/tree/main/skills) - Reference implementation\r\n\r\n",
          "tokens": 1283
        }
      }
    },
    "repo-rag": {
      "name": "repo-rag",
      "one_liner": "Perform high-recall codebase retrieval using semantic search and symbol indexing. Use when you need to find specific code, understand project structure, or verify architectural patterns before editing.",
      "key_commands": [
        "/identity",
        "/capabilities",
        "/execution_process",
        "/usage_patterns",
        "/instructions"
      ],
      "token_count": {
        "minimal": 54,
        "essential": 88,
        "standard": 292,
        "full": 1314
      },
      "levels": {
        "minimal": {
          "content": "**repo-rag**: Perform high-recall codebase retrieval using semantic search and symbol indexing. Use when you need to find specific code, understand project structure, or verify architectural patterns before editing.",
          "tokens": 54
        },
        "essential": {
          "content": "## Skill: repo-rag\n\nPerform high-recall codebase retrieval using semantic search and symbol indexing. Use when you need to find specific code, understand project structure, or verify architectural patterns before editing.\n\nRepo RAG (Retrieval Augmented Generation) - Provides advanced codebase search capabilities beyond simple grep.\n\n### Key Steps:\n",
          "tokens": 88
        },
        "standard": {
          "content": "## Skill: repo-rag\n\nPerform high-recall codebase retrieval using semantic search and symbol indexing. Use when you need to find specific code, understand project structure, or verify architectural patterns before editing.\n\nRepo RAG (Retrieval Augmented Generation) - Provides advanced codebase search capabilities beyond simple grep.\n\n### Instructions:\n<execution_process>\n1. **Symbol Search First**: Use `symbols` to find classes, functions, and types. This is more accurate than text search for code structures.\n2. **Semantic Search**: Use `search` for concepts, comments, or broader patterns.\n3. **Verification**: Always verify the file path and context returned before proposing edits.\n</execution_process>\n\n<usage_patterns>\n- **Architecture Review**: Run symbol searches on key interfaces to understand the dependency graph.\n- **Plan Mode**: Use this skill to populate the \"Context\" section of a Plan Mode artifact.\n- **Refactoring**: Identify all usages of a symbol before renaming or modifying it.\n</usage_patterns>\n\n### Example:\n**Symbol Search**:\n\n```\nsymbols \"UserAuthentication\"\n```\n\n**Semantic Search**:\n\n```\nsearch \"authentication middleware logic\"\n```",
          "tokens": 292
        },
        "full": {
          "content": "---\nname: repo-rag\ndescription: Perform high-recall codebase retrieval using semantic search and symbol indexing. Use when you need to find specific code, understand project structure, or verify architectural patterns before editing.\nallowed-tools: search, symbols, codebase_search, read, grep\nversion: 2.0\nbest_practices:\n  - Use clear, specific queries (avoid vague terms)\n  - Provide context about what you're looking for\n  - Review multiple results to understand patterns\n  - Use follow-up queries to refine results\n  - Verify file paths before proposing edits\nerror_handling: graceful\nstreaming: supported\n---\n\n<identity>\nRepo RAG (Retrieval Augmented Generation) - Provides advanced codebase search capabilities beyond simple grep.\n</identity>\n\n<capabilities>\n- High-recall codebase retrieval using semantic search\n- Symbol indexing for finding classes, functions, and types\n- Understanding project structure\n- Verifying architectural patterns before editing\n</capabilities>\n\n<instructions>\n<execution_process>\n1. **Symbol Search First**: Use `symbols` to find classes, functions, and types. This is more accurate than text search for code structures.\n2. **Semantic Search**: Use `search` for concepts, comments, or broader patterns.\n3. **Verification**: Always verify the file path and context returned before proposing edits.\n</execution_process>\n\n<usage_patterns>\n- **Architecture Review**: Run symbol searches on key interfaces to understand the dependency graph.\n- **Plan Mode**: Use this skill to populate the \"Context\" section of a Plan Mode artifact.\n- **Refactoring**: Identify all usages of a symbol before renaming or modifying it.\n</usage_patterns>\n</instructions>\n\n<examples>\n<code_example>\n**Symbol Search**:\n\n```\nsymbols \"UserAuthentication\"\n```\n\n**Semantic Search**:\n\n```\nsearch \"authentication middleware logic\"\n```\n</code_example>\n</examples>\n\n## RAG Evaluation\n\n### Overview\n\nSystematic evaluation of RAG quality using retrieval and end-to-end metrics. Based on Claude Cookbooks patterns.\n\n### Evaluation Metrics\n\n**Retrieval Metrics** (from `.claude/evaluation/retrieval_metrics.py`):\n- **Precision**: Proportion of retrieved chunks that are actually relevant\n  - Formula: `Precision = True Positives / Total Retrieved`\n  - High precision (0.8-1.0): System retrieves mostly relevant items\n- **Recall**: Completeness of retrieval - how many relevant items were found\n  - Formula: `Recall = True Positives / Total Correct`\n  - High recall (0.8-1.0): System finds most relevant items\n- **F1 Score**: Harmonic mean of precision and recall\n  - Formula: `F1 = 2 × (Precision × Recall) / (Precision + Recall)`\n  - Balanced measure when both precision and recall matter\n- **MRR (Mean Reciprocal Rank)**: Measures ranking quality\n  - Formula: `MRR = 1 / rank of first correct item`\n  - High MRR (0.8-1.0): Correct items ranked first\n\n**End-to-End Metrics** (from `.claude/evaluation/end_to_end_eval.py`):\n- **Accuracy (LLM-as-Judge)**: Overall correctness using Claude evaluation\n  - Compares generated answer to correct answer\n  - Focuses on substance and meaning, not exact wording\n  - Checks for completeness and absence of contradictions\n\n### Evaluation Process\n\n1. **Create Evaluation Dataset**:\n   ```json\n   {\n     \"query\": \"How is user authentication implemented?\",\n     \"correct_chunks\": [\"src/auth/middleware.ts\", \"src/auth/types.ts\"],\n     \"correct_answer\": \"User authentication uses JWT tokens...\",\n     \"category\": \"authentication\"\n   }\n   ```\n\n2. **Run Retrieval Evaluation**:\n   ```bash\n   # Using Promptfoo\n   npx promptfoo@latest eval -c .claude/evaluation/promptfoo_configs/rag_config.yaml\n   \n   # Or using Python directly\n   from .claude.evaluation.retrieval_metrics import evaluate_retrieval\n   metrics = evaluate_retrieval(retrieved_chunks, correct_chunks)\n   print(f\"Precision: {metrics['precision']}, Recall: {metrics['recall']}, F1: {metrics['f1']}, MRR: {metrics['mrr']}\")\n   ```\n\n3. **Run End-to-End Evaluation**:\n   ```bash\n   # Using Promptfoo\n   npx promptfoo@latest eval -c .claude/evaluation/promptfoo_configs/rag_config.yaml\n   \n   # Or using Python directly\n   from .claude.evaluation.end_to_end_eval import evaluate_end_to_end\n   result = evaluate_end_to_end(query, generated_answer, correct_answer)\n   print(f\"Correct: {result['is_correct']}, Explanation: {result['explanation']}\")\n   ```\n\n### Expected Performance\n\nBased on Claude Cookbooks results:\n- **Basic RAG**: Precision 0.43, Recall 0.66, F1 0.52, MRR 0.74, Accuracy 71%\n- **With Re-ranking**: Precision 0.44, Recall 0.69, F1 0.54, MRR 0.87, Accuracy 81%\n\n### Best Practices\n\n1. **Separate Evaluation**: Evaluate retrieval and end-to-end separately\n2. **Create Comprehensive Datasets**: Cover common and edge cases\n3. **Evaluate Regularly**: Run evaluations after codebase changes\n4. **Track Metrics Over Time**: Monitor improvements\n5. **Use Both Metrics**: Precision/Recall for retrieval, Accuracy for end-to-end\n\n### References\n\n- [RAG Patterns Guide](../docs/RAG_PATTERNS.md) - Implementation patterns\n- [Retrieval Metrics](../evaluation/retrieval_metrics.py) - Metric calculations\n- [End-to-End Evaluation](../evaluation/end_to_end_eval.py) - LLM-as-judge\n- [Evaluation Guide](../docs/EVALUATION_GUIDE.md) - Comprehensive evaluation guide\n",
          "tokens": 1314
        }
      }
    },
    "dependency-analyzer": {
      "name": "dependency-analyzer",
      "one_liner": "No description",
      "key_commands": ["/requirements", "/go", "/identity", "/capabilities", "/Maven"],
      "token_count": {
        "minimal": 13,
        "essential": 458,
        "standard": 767,
        "full": 1355
      },
      "levels": {
        "minimal": {
          "content": "**dependency-analyzer**: No description available",
          "tokens": 13
        },
        "essential": {
          "content": "## Skill: dependency-analyzer\n\nDependency Analyzer Skill - Analyzes project dependencies, detects outdated packages, identifies breaking changes, and suggests safe update strategies.\n\n### Key Steps:\n: Identify Dependency Files\r\n\r\nLocate dependency files:\r\n- `package.json` (Node.js)\r\n- `requirements.txt` (Python)\r\n- `go.mod` (Go)\r\n- `Cargo.toml` (Rust)\r\n- `pom.xml` (Java/Maven)\r\n\r\n\n### Step: Analyze Dependencies\r\n\r\nExamine dependencies:\r\n- Read dependency files\r\n- Check versions\r\n- Identify outdated packages\r\n- Note version constraints\r\n\r\n\n### Step: Semantic Versioning Analysis\r\n\r\nAnalyze version numbers using semantic versioning (semver):\r\n\r\n1. **Parse version numbers**:\r\n   - Extract major.minor.patch from version strings\r\n   - Handle version ranges (^, ~, >=, etc.)\r\n   - Identify exact vs range versions\r\n\r\n2. **Detect major version bumps**:\r\n   - Compare current version with latest available\r\n   - Identify major version changes (e.g., 1.x.x -> 2.x.x)\r\n   - Flag major updates as potentially breaking\r\n\r\n3. **Check changelogs for breaking changes**:\r\n   - **For major version updates**: Trigger web search (Exa/WebFetch) to research breaking changes\r\n   - Look for \"BREAKING CHANGE\" markers in changelogs\r\n   - Check migration guides\r\n   - Review release notes for breaking changes\r\n   - Document specific breaking changes found\r\n\r\n4. **Semantic Versioning Rules**:\r\n   - **Major version (X.0.0)**: Breaking changes likely, requires code changes\r\n   - **Minor version (0.X.0)**: New features, backward compatible\r\n   - **Patch version (0.0.X)**: Bug fixes, backward compatible\r\n\r\n5. **Breaking Change Detection**:\r\n   - Parse changelog entries for breaking change indicators\r\n   - Identify deprecated APIs\r\n   - Check for removed features\r\n   - Document migration requirements\r\n   - Generate breaking change report",
          "tokens": 458
        },
        "standard": {
          "content": "## Skill: dependency-analyzer\n\nDependency Analyzer Skill - Analyzes project dependencies, detects outdated packages, identifies breaking changes, and suggests safe update strategies.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Identify Dependency Files\r\n\r\nLocate dependency files:\r\n- `package.json` (Node.js)\r\n- `requirements.txt` (Python)\r\n- `go.mod` (Go)\r\n- `Cargo.toml` (Rust)\r\n- `pom.xml` (Java/Maven)\r\n\r\n### Step 2: Analyze Dependencies\r\n\r\nExamine dependencies:\r\n- Read dependency files\r\n- Check versions\r\n- Identify outdated packages\r\n- Note version constraints\r\n\r\n### Step 3: Semantic Versioning Analysis\r\n\r\nAnalyze version numbers using semantic versioning (semver):\r\n\r\n1. **Parse version numbers**:\r\n   - Extract major.minor.patch from version strings\r\n   - Handle version ranges (^, ~, >=, etc.)\r\n   - Identify exact vs range versions\r\n\r\n2. **Detect major version bumps**:\r\n   - Compare current version with latest available\r\n   - Identify major version changes (e.g., 1.x.x -> 2.x.x)\r\n   - Flag major updates as potentially breaking\r\n\r\n3. **Check changelogs for breaking changes**:\r\n   - **For major version updates**: Trigger web search (Exa/WebFetch) to research breaking changes\r\n   - Look for \"BREAKING CHANGE\" markers in changelogs\r\n   - Check migration guides\r\n   - Review release notes for breaking changes\r\n   - Document specific breaking changes found\r\n\r\n4. **Semantic Versioning Rules**:\r\n   - **Major version (X.0.0)**: Breaking changes likely, requires code changes\r\n   - **Minor version (0.X.0)**: New features, backward compatible\r\n   - **Patch version (0.0.X)**: Bug fixes, backward compatible\r\n\r\n5. **Breaking Change Detection**:\r\n   - Parse changelog entries for breaking change indicators\r\n   - Identify deprecated APIs\r\n   - Check for removed features\r\n   - Document migration requirements\r\n   - Generate breaking change report\r\n\r\n### Step 4: Check for Updates\r\n\r\nCheck available updates:\r\n- Query package registries\r\n- Compare current vs latest versions\r\n- Identify major/minor/patch updates\r\n- Apply semantic versioning analysis\r\n- Warn about breaking changes\r\n\r\n### Step 4: Security Audit\r\n\r\nCheck for vulnerabilities:\r\n- Scan for known vulnerabilities\r\n- Check security advisories\r\n- Identify high-risk packages\r\n- Suggest security updates\r\n\r\n### Step 5: Generate Report\r\n\r\nCreate dependency report:\r\n- List outdated packages\r\n- Identify breaking changes\r\n- Suggest update strategy\r\n- Provide migration guidance\r\n</execution_process>\r\n\r\n<integration>\r\n**Integration with DevOps Agent**:\r\n- Manages dependency updates\r\n- Implements update strategies\r\n- Validates compatibility\r\n\r\n**Integration with Security Architect Agent**:\r\n- Reviews security vulnerabilities\r\n- Validates security updates\r\n- Ensures compliance\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Regular Analysis**: Analyze dependencies regularly\r\n2. **Security First**: Prioritize security updates\r\n3. **Test Updates**: Always test after updates\r\n4. **Gradual Updates**: Update incrementally\r\n5. **Document Changes**: Track update decisions\r\n</best_practices>\n",
          "tokens": 767
        },
        "full": {
          "content": "---\r\nname: dependency-analyzer\r\ndescription: Analyzes project dependencies, detects outdated packages, identifies breaking changes, and suggests safe update strategies. Helps maintain dependency health and security.\r\nallowed-tools: read, write, glob, search, codebase_search, Bash\r\nversion: 1.0\r\nbest_practices:\r\n  - Analyze package.json/requirements.txt/go.mod\r\n  - Check for security vulnerabilities\r\n  - Identify breaking changes\r\n  - Suggest update strategies\r\n  - Validate compatibility\r\nerror_handling: graceful\r\nstreaming: supported\r\ntemplates: [dependency-report, update-plan, security-audit]\r\n---\r\n\r\n<identity>\r\nDependency Analyzer Skill - Analyzes project dependencies, detects outdated packages, identifies breaking changes, and suggests safe update strategies.\r\n</identity>\r\n\r\n<capabilities>\r\n- Analyzing dependency health\r\n- Planning dependency updates\r\n- Detecting security vulnerabilities\r\n- Identifying breaking changes\r\n- Validating compatibility\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Identify Dependency Files\r\n\r\nLocate dependency files:\r\n- `package.json` (Node.js)\r\n- `requirements.txt` (Python)\r\n- `go.mod` (Go)\r\n- `Cargo.toml` (Rust)\r\n- `pom.xml` (Java/Maven)\r\n\r\n### Step 2: Analyze Dependencies\r\n\r\nExamine dependencies:\r\n- Read dependency files\r\n- Check versions\r\n- Identify outdated packages\r\n- Note version constraints\r\n\r\n### Step 3: Semantic Versioning Analysis\r\n\r\nAnalyze version numbers using semantic versioning (semver):\r\n\r\n1. **Parse version numbers**:\r\n   - Extract major.minor.patch from version strings\r\n   - Handle version ranges (^, ~, >=, etc.)\r\n   - Identify exact vs range versions\r\n\r\n2. **Detect major version bumps**:\r\n   - Compare current version with latest available\r\n   - Identify major version changes (e.g., 1.x.x -> 2.x.x)\r\n   - Flag major updates as potentially breaking\r\n\r\n3. **Check changelogs for breaking changes**:\r\n   - **For major version updates**: Trigger web search (Exa/WebFetch) to research breaking changes\r\n   - Look for \"BREAKING CHANGE\" markers in changelogs\r\n   - Check migration guides\r\n   - Review release notes for breaking changes\r\n   - Document specific breaking changes found\r\n\r\n4. **Semantic Versioning Rules**:\r\n   - **Major version (X.0.0)**: Breaking changes likely, requires code changes\r\n   - **Minor version (0.X.0)**: New features, backward compatible\r\n   - **Patch version (0.0.X)**: Bug fixes, backward compatible\r\n\r\n5. **Breaking Change Detection**:\r\n   - Parse changelog entries for breaking change indicators\r\n   - Identify deprecated APIs\r\n   - Check for removed features\r\n   - Document migration requirements\r\n   - Generate breaking change report\r\n\r\n### Step 4: Check for Updates\r\n\r\nCheck available updates:\r\n- Query package registries\r\n- Compare current vs latest versions\r\n- Identify major/minor/patch updates\r\n- Apply semantic versioning analysis\r\n- Warn about breaking changes\r\n\r\n### Step 4: Security Audit\r\n\r\nCheck for vulnerabilities:\r\n- Scan for known vulnerabilities\r\n- Check security advisories\r\n- Identify high-risk packages\r\n- Suggest security updates\r\n\r\n### Step 5: Generate Report\r\n\r\nCreate dependency report:\r\n- List outdated packages\r\n- Identify breaking changes\r\n- Suggest update strategy\r\n- Provide migration guidance\r\n</execution_process>\r\n\r\n<integration>\r\n**Integration with DevOps Agent**:\r\n- Manages dependency updates\r\n- Implements update strategies\r\n- Validates compatibility\r\n\r\n**Integration with Security Architect Agent**:\r\n- Reviews security vulnerabilities\r\n- Validates security updates\r\n- Ensures compliance\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Regular Analysis**: Analyze dependencies regularly\r\n2. **Security First**: Prioritize security updates\r\n3. **Test Updates**: Always test after updates\r\n4. **Gradual Updates**: Update incrementally\r\n5. **Document Changes**: Track update decisions\r\n</best_practices>\r\n</instructions>\r\n\r\n<examples>\r\n<formatting_example>\r\n**Dependency Health Report**\r\n\r\n```markdown\r\n# Dependency Health Report\r\n\r\n## Summary\r\n- Total Dependencies: 45\r\n- Outdated: 12\r\n- Vulnerable: 3\r\n- Up to Date: 30\r\n\r\n## Outdated Packages\r\n- react: 18.0.0 → 18.2.0 (minor update)\r\n- next: 13.4.0 → 14.0.0 (major update - breaking changes)\r\n- typescript: 5.0.0 → 5.3.0 (patch update)\r\n\r\n## Security Vulnerabilities\r\n- lodash: 4.17.20 (CVE-2021-23337) - Update to 4.17.21\r\n- axios: 0.21.1 (CVE-2021-3749) - Update to 1.6.0\r\n\r\n## Update Recommendations\r\n1. Update patch versions (safe)\r\n2. Review minor updates (low risk)\r\n3. Plan major updates (breaking changes)\r\n```\r\n</formatting_example>\r\n\r\n<formatting_example>\r\n**Update Plan**\r\n\r\n```markdown\r\n# Dependency Update Plan\r\n\r\n## Phase 1: Patch Updates (Safe)\r\n- Update lodash: 4.17.20 → 4.17.21\r\n- Update typescript: 5.0.0 → 5.3.0\r\n\r\n## Phase 2: Minor Updates (Low Risk)\r\n- Update react: 18.0.0 → 18.2.0\r\n- Update @types/node: 20.0.0 → 20.10.0\r\n\r\n## Phase 3: Major Updates (Breaking Changes)\r\n- Update next: 13.4.0 → 14.0.0\r\n  - Breaking changes: [List]\r\n  - Migration steps: [Steps]\r\n  - Testing required: [Tests]\r\n```\r\n</formatting_example>\r\n</examples>\r\n\r\n<examples>\r\n<usage_example>\r\n**Example Commands**:\r\n\r\n```\r\n# Analyze dependencies\r\nAnalyze dependencies for this project\r\n\r\n# Check for updates\r\nCheck for dependency updates\r\n\r\n# Security audit\r\nPerform security audit of dependencies\r\n\r\n# Generate update plan\r\nGenerate update plan for major version updates\r\n```\r\n</usage_example>\r\n</examples>\r\n\r\n",
          "tokens": 1355
        }
      }
    },
    "evaluator": {
      "name": "evaluator",
      "one_liner": "No description",
      "key_commands": ["/fail", "/components", "/evaluation", "/datasets", "/agent-tasks"],
      "token_count": {
        "minimal": 10,
        "essential": 5,
        "standard": 5,
        "full": 1498
      },
      "levels": {
        "minimal": {
          "content": "**evaluator**: No description available",
          "tokens": 10
        },
        "essential": {
          "content": "## Skill: evaluator\n",
          "tokens": 5
        },
        "standard": {
          "content": "## Skill: evaluator\n",
          "tokens": 5
        },
        "full": {
          "content": "---\r\nname: evaluator\r\ndescription: Evaluates agent performance, rule compliance, and workflow quality. Provides systematic evaluation using code-based, model-based, and human grading methods.\r\nallowed-tools: read, write, grep, glob, bash\r\nversion: 1.0\r\nbest_practices:\r\n  - Use code-based grading for structured outputs\r\n  - Use model-based grading for quality assessment\r\n  - Create comprehensive test datasets\r\n  - Run evaluations regularly\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# Evaluator Skill\r\n\r\n## Identity\r\n\r\nEvaluator - Provides systematic evaluation of agent performance, rule compliance, and workflow quality.\r\n\r\n## Capabilities\r\n\r\n- **Agent Performance Evaluation**: Test agents on task datasets\r\n- **Rule Compliance Testing**: Validate code against loaded rules\r\n- **Workflow Quality Assessment**: Evaluate workflow execution and outputs\r\n- **Continuous Improvement**: Track metrics over time\r\n\r\n## Evaluation Methods\r\n\r\n### 1. Code-Based Grading\r\n\r\n**Best for**: Exact matches, structured outputs, rule compliance\r\n\r\n**Examples**:\r\n- JSON schema validation\r\n- Rule violation detection\r\n- Test pass/fail counts\r\n- File creation verification\r\n\r\n**Usage**:\r\n```\r\nEvaluate agent output against expected structure\r\nCheck for required files and validation status\r\n```\r\n\r\n### 2. Model-Based Grading\r\n\r\n**Best for**: Subjective quality, complex analysis, free-form outputs\r\n\r\n**Examples**:\r\n- Code quality assessment\r\n- Architecture evaluation\r\n- Documentation quality\r\n- User experience evaluation\r\n\r\n**Usage**:\r\n```\r\nEvaluate code quality on scale of 0-1\r\nAssess architecture decisions\r\nReview documentation completeness\r\n```\r\n\r\n### 3. Human Grading\r\n\r\n**Best for**: Final validation, critical decisions, complex scenarios\r\n\r\n**Examples**:\r\n- Production readiness\r\n- Security review\r\n- Architecture approval\r\n- User acceptance\r\n\r\n**Usage**:\r\n```\r\nRequest human review for critical decisions\r\nValidate production readiness\r\nAssess security implications\r\n```\r\n\r\n## Usage Patterns\r\n\r\n### Evaluate Agent Performance\r\n\r\n**When to Use**:\r\n- After agent updates\r\n- Testing new agent capabilities\r\n- Validating agent improvements\r\n- Benchmarking performance\r\n\r\n**How to Invoke**:\r\n```\r\n\"Evaluate developer agent performance\"\r\n\"Run evaluation on architect agent\"\r\n\"Test QA agent on test dataset\"\r\n```\r\n\r\n**What It Does**:\r\n- Loads evaluation dataset\r\n- Runs agent on test tasks\r\n- Grades outputs (code-based + model-based)\r\n- Generates performance report\r\n\r\n### Evaluate Rule Compliance\r\n\r\n**When to Use**:\r\n- Before committing code\r\n- After rule updates\r\n- Validating codebase compliance\r\n- Testing new rules\r\n\r\n**How to Invoke**:\r\n```\r\n\"Evaluate rule compliance for src/components\"\r\n\"Check if code follows TECH_STACK_NEXTJS rules\"\r\n\"Audit codebase against loaded rules\"\r\n```\r\n\r\n**What It Does**:\r\n- Loads applicable rules\r\n- Scans code files for violations\r\n- Reports violations with line numbers\r\n- Calculates compliance rate\r\n\r\n### Evaluate Workflow Quality\r\n\r\n**When to Use**:\r\n- Testing workflow execution\r\n- Validating workflow outputs\r\n- Improving workflow efficiency\r\n- Benchmarking workflows\r\n\r\n**How to Invoke**:\r\n```\r\n\"Evaluate greenfield-fullstack workflow\"\r\n\"Test workflow execution quality\"\r\n\"Assess workflow outputs\"\r\n```\r\n\r\n**What It Does**:\r\n- Executes workflow on test scenarios\r\n- Validates step outputs\r\n- Checks artifact completeness\r\n- Measures workflow efficiency\r\n\r\n## Evaluation Datasets\r\n\r\n### Creating Test Datasets\r\n\r\n**Agent Tasks Dataset** (`.claude/evaluation/datasets/agent-tasks.jsonl`):\r\n```json\r\n{\r\n  \"input\": \"Implement a user authentication API\",\r\n  \"expected_output\": {\r\n    \"files_created\": [\"api/auth/route.ts\"],\r\n    \"tests_created\": [\"api/auth/route.test.ts\"],\r\n    \"validation\": \"pass\"\r\n  },\r\n  \"agent\": \"developer\",\r\n  \"category\": \"api_implementation\"\r\n}\r\n```\r\n\r\n**Rule Test Cases Dataset** (`.claude/evaluation/datasets/rule-test-cases.jsonl`):\r\n```json\r\n{\r\n  \"file\": \"src/components/Button.tsx\",\r\n  \"rule\": \"TECH_STACK_NEXTJS.md\",\r\n  \"expected_violations\": [],\r\n  \"category\": \"component_structure\"\r\n}\r\n```\r\n\r\n## Integration\r\n\r\n### With Rule Auditor\r\n\r\nThe evaluator works with the rule-auditor skill:\r\n- Rule-auditor finds violations\r\n- Evaluator measures compliance rate\r\n- Both provide actionable feedback\r\n\r\n### With Workflow Runner\r\n\r\nThe evaluator validates workflow execution:\r\n- Workflow runner executes steps\r\n- Evaluator validates outputs\r\n- Both ensure quality gates\r\n\r\n## Best Practices\r\n\r\n1. **Create Comprehensive Datasets**: Cover common and edge cases\r\n2. **Run Regularly**: Evaluate after major changes\r\n3. **Track Metrics**: Monitor performance over time\r\n4. **Iterate**: Use results to improve agents and rules\r\n5. **Automate**: Integrate into CI/CD pipeline\r\n\r\n## Examples\r\n\r\n### Example 1: Agent Performance\r\n\r\n```\r\nUser: \"Evaluate developer agent performance\"\r\n\r\nEvaluator:\r\n1. Loads agent-tasks.jsonl dataset\r\n2. Runs developer agent on each task\r\n3. Grades outputs (code-based + model-based)\r\n4. Generates performance report\r\n5. Saves to .claude/evaluation/results/developer-performance.json\r\n```\r\n\r\n### Example 2: Rule Compliance\r\n\r\n```\r\nUser: \"Evaluate rule compliance for src/components\"\r\n\r\nEvaluator:\r\n1. Loads TECH_STACK_NEXTJS.md rules\r\n2. Scans src/components/**/*.tsx files\r\n3. Detects rule violations\r\n4. Calculates compliance rate\r\n5. Reports violations with fixes\r\n```\r\n\r\n### Example 3: Workflow Quality\r\n\r\n```\r\nUser: \"Evaluate greenfield-fullstack workflow\"\r\n\r\nEvaluator:\r\n1. Executes workflow on test scenario\r\n2. Validates each step output\r\n3. Checks artifact completeness\r\n4. Measures execution time\r\n5. Generates quality report\r\n```\r\n\r\n## Related Skills\r\n\r\n- **rule-auditor**: Finds rule violations\r\n- **code-style-validator**: Validates code style\r\n- **commit-validator**: Validates commit messages\r\n\r\n## Related Documentation\r\n\r\n- [Evaluation Guide](../docs/EVALUATION_GUIDE.md) - Comprehensive evaluation guide\r\n- [Evaluation Framework](../evaluation/README.md) - Framework overview\r\n\r\n",
          "tokens": 1498
        }
      }
    },
    "classifier": {
      "name": "classifier",
      "one_liner": "No description",
      "key_commands": ["/components", "/docs", "/CLASSIFICATION_PATTERNS"],
      "token_count": {
        "minimal": 10,
        "essential": 6,
        "standard": 6,
        "full": 950
      },
      "levels": {
        "minimal": {
          "content": "**classifier**: No description available",
          "tokens": 10
        },
        "essential": {
          "content": "## Skill: classifier\n",
          "tokens": 6
        },
        "standard": {
          "content": "## Skill: classifier\n",
          "tokens": 6
        },
        "full": {
          "content": "---\r\nname: classifier\r\ndescription: Classify code, documents, and data into categories. Use for code categorization, content classification, and data organization.\r\nallowed-tools: read, write, grep, glob\r\nversion: 1.0\r\nbest_practices:\r\n  - Use clear category definitions\r\n  - Provide training examples\r\n  - Validate classifications\r\n  - Track classification accuracy\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# Classifier Skill\r\n\r\n## Identity\r\n\r\nClassifier - Categorizes code, documents, and data into predefined categories using classification patterns.\r\n\r\n## Capabilities\r\n\r\n- **Code Classification**: Categorize code files by type, purpose, or pattern\r\n- **Document Classification**: Classify documents by topic, type, or purpose\r\n- **Data Classification**: Organize data into categories\r\n- **Multi-Label Classification**: Assign multiple categories when appropriate\r\n\r\n## Usage\r\n\r\n### Code Classification\r\n\r\n**When to Use**:\r\n- Organizing codebase by functionality\r\n- Identifying code patterns\r\n- Categorizing components\r\n- Code review organization\r\n\r\n**How to Invoke**:\r\n```\r\n\"Classify all files in src/components by functionality\"\r\n\"Categorize API routes by resource type\"\r\n\"Organize code files by architectural layer\"\r\n```\r\n\r\n**What It Does**:\r\n- Analyzes code files\r\n- Assigns categories based on patterns\r\n- Returns classification results\r\n- Validates classifications\r\n\r\n### Document Classification\r\n\r\n**When to Use**:\r\n- Organizing documentation\r\n- Categorizing content\r\n- Topic classification\r\n- Content management\r\n\r\n**How to Invoke**:\r\n```\r\n\"Classify documentation files by topic\"\r\n\"Categorize markdown files by purpose\"\r\n\"Organize documents by category\"\r\n```\r\n\r\n## Classification Patterns\r\n\r\n### Code Categories\r\n\r\n- **Component Types**: React components, API routes, utilities\r\n- **Architectural Layers**: Presentation, business logic, data access\r\n- **Functionality**: Authentication, payment, reporting\r\n- **Patterns**: MVC, Repository, Factory\r\n\r\n### Document Categories\r\n\r\n- **Topics**: Technical, business, user-facing\r\n- **Types**: API docs, guides, tutorials\r\n- **Purposes**: Reference, how-to, explanation\r\n\r\n## Best Practices\r\n\r\n1. **Clear Categories**: Define categories explicitly\r\n2. **Training Examples**: Provide examples for each category\r\n3. **Validation**: Review and validate classifications\r\n4. **Accuracy Tracking**: Monitor classification accuracy\r\n5. **Iteration**: Refine categories based on results\r\n\r\n## Integration\r\n\r\n### With Database Architect\r\n\r\nClassifier can categorize database schemas:\r\n- Table types (entities, relationships, lookup)\r\n- Schema patterns (normalized, denormalized)\r\n- Data domains (user, product, order)\r\n\r\n### With Code Reviewer\r\n\r\nClassifier helps organize code reviews:\r\n- Review categories\r\n- Priority classification\r\n- Pattern identification\r\n\r\n## Examples\r\n\r\n### Example 1: Code Classification\r\n\r\n```\r\nUser: \"Classify all files in src/ by functionality\"\r\n\r\nClassifier:\r\n1. Analyzes all files in src/\r\n2. Assigns categories:\r\n   - Authentication: auth/, login/, session/\r\n   - Payment: payment/, billing/, subscription/\r\n   - Reporting: reports/, analytics/, dashboards/\r\n3. Returns classification results\r\n```\r\n\r\n### Example 2: Document Classification\r\n\r\n```\r\nUser: \"Classify documentation by topic\"\r\n\r\nClassifier:\r\n1. Analyzes documentation files\r\n2. Assigns topics:\r\n   - API: api-docs/, endpoints/\r\n   - Guides: guides/, tutorials/\r\n   - Reference: reference/, specs/\r\n3. Returns classification\r\n```\r\n\r\n## Related Skills\r\n\r\n- **text-to-sql**: Convert natural language to SQL queries\r\n- **code-reviewer**: Review classified code\r\n- **database-architect**: Use classifications for schema design\r\n\r\n## Related Documentation\r\n\r\n- [Classification Patterns](../docs/CLASSIFICATION_PATTERNS.md) - Comprehensive guide\r\n\r\n",
          "tokens": 950
        }
      }
    },
    "text-to-sql": {
      "name": "text-to-sql",
      "one_liner": "No description",
      "key_commands": [
        "/evaluation",
        "/promptfoo_configs",
        "/text_to_sql_config",
        "/docs",
        "/CLASSIFICATION_PATTERNS"
      ],
      "token_count": {
        "minimal": 11,
        "essential": 6,
        "standard": 6,
        "full": 1384
      },
      "levels": {
        "minimal": {
          "content": "**text-to-sql**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: text-to-sql\n",
          "tokens": 6
        },
        "standard": {
          "content": "## Skill: text-to-sql\n",
          "tokens": 6
        },
        "full": {
          "content": "---\r\nname: text-to-sql\r\ndescription: Convert natural language queries to SQL. Use for database queries, data analysis, and reporting.\r\nallowed-tools: read, write, grep, glob\r\nversion: 1.0\r\nbest_practices:\r\n  - Provide database schema context\r\n  - Validate SQL before execution\r\n  - Use parameterized queries\r\n  - Test queries on sample data\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# Text-to-SQL Skill\r\n\r\n## Identity\r\n\r\nText-to-SQL - Converts natural language queries to SQL using database schema context and query patterns.\r\n\r\n## Capabilities\r\n\r\n- **Query Generation**: Convert natural language to SQL\r\n- **Schema Awareness**: Uses database schema for accurate queries\r\n- **Query Optimization**: Generates optimized SQL queries\r\n- **Parameterized Queries**: Creates safe, parameterized queries\r\n\r\n## Usage\r\n\r\n### Basic SQL Generation\r\n\r\n**When to Use**:\r\n- Database queries from natural language\r\n- Data analysis requests\r\n- Reporting queries\r\n- Ad-hoc database queries\r\n\r\n**How to Invoke**:\r\n```\r\n\"Generate SQL to find all users who signed up in the last month\"\r\n\"Create a query to calculate total revenue by product\"\r\n\"Write SQL to find duplicate records\"\r\n```\r\n\r\n**What It Does**:\r\n- Analyzes natural language query\r\n- References database schema\r\n- Generates SQL query\r\n- Validates query syntax\r\n- Returns parameterized query\r\n\r\n### Advanced Features\r\n\r\n**Schema Integration**:\r\n- Loads database schema\r\n- Understands table relationships\r\n- Uses column types and constraints\r\n- Handles joins and aggregations\r\n\r\n**Query Optimization**:\r\n- Generates efficient queries\r\n- Uses appropriate indexes\r\n- Optimizes joins\r\n- Minimizes data transfer\r\n\r\n**Safety**:\r\n- Parameterized queries (prevents SQL injection)\r\n- Validates query syntax\r\n- Tests on sample data\r\n- Error handling\r\n\r\n## Best Practices\r\n\r\n1. **Schema Context**: Provide complete database schema\r\n2. **Query Validation**: Validate SQL before execution\r\n3. **Parameterization**: Always use parameterized queries\r\n4. **Testing**: Test queries on sample data\r\n5. **Optimization**: Review query performance\r\n\r\n## Integration\r\n\r\n### With Database Architect\r\n\r\nText-to-SQL uses schema from database-architect:\r\n- Table definitions\r\n- Relationships\r\n- Constraints\r\n- Indexes\r\n\r\n### With Developer\r\n\r\nText-to-SQL generates queries for developers:\r\n- Query templates\r\n- Parameterized queries\r\n- Query optimization\r\n- Error handling\r\n\r\n## Examples\r\n\r\n### Example 1: Simple Query\r\n\r\n```\r\nUser: \"Find all users who signed up in the last month\"\r\n\r\nText-to-SQL:\r\n1. Analyzes query\r\n2. References users table schema\r\n3. Generates SQL:\r\n   SELECT * FROM users \r\n   WHERE created_at >= DATE_SUB(NOW(), INTERVAL 1 MONTH)\r\n4. Returns parameterized query\r\n```\r\n\r\n### Example 2: Complex Query\r\n\r\n```\r\nUser: \"Calculate total revenue by product for Q4\"\r\n\r\nText-to-SQL:\r\n1. Analyzes query\r\n2. References orders and products tables\r\n3. Generates SQL:\r\n   SELECT p.name, SUM(o.total) as revenue\r\n   FROM orders o\r\n   JOIN products p ON o.product_id = p.id\r\n   WHERE o.created_at >= '2024-10-01' \r\n     AND o.created_at < '2025-01-01'\r\n   GROUP BY p.id, p.name\r\n4. Returns optimized query\r\n```\r\n\r\n## Evaluation\r\n\r\n### Evaluation Framework\r\n\r\nBased on Claude Cookbooks patterns, text-to-SQL evaluation includes:\r\n\r\n**Syntax Validation**:\r\n- SQL syntax correctness\r\n- Schema compliance\r\n- Query structure validation\r\n\r\n**Functional Testing**:\r\n- Query execution on test database\r\n- Result correctness\r\n- Performance validation\r\n\r\n**Promptfoo Integration**:\r\n- Multiple prompt variants (basic, few-shot, chain-of-thought, RAG)\r\n- Temperature sweeps\r\n- Model comparisons (Haiku vs Sonnet)\r\n\r\n**Evaluation Configuration**:\r\nSee `.claude/evaluation/promptfoo_configs/text_to_sql_config.yaml` for complete evaluation setup.\r\n\r\n### Running Evaluations\r\n\r\n```bash\r\n# Run text-to-SQL evaluation\r\nnpx promptfoo@latest eval -c .claude/evaluation/promptfoo_configs/text_to_sql_config.yaml\r\n```\r\n\r\n### Evaluation Metrics\r\n\r\n- **Syntax Accuracy**: Percentage of queries with valid SQL syntax\r\n- **Functional Correctness**: Percentage of queries returning correct results\r\n- **Schema Compliance**: Percentage of queries using correct schema\r\n- **Performance**: Query execution time and optimization\r\n\r\n## Best Practices from Cookbooks\r\n\r\n### 1. Provide Schema Context\r\n\r\nAlways include complete database schema:\r\n- Table definitions with column types\r\n- Relationships and foreign keys\r\n- Constraints and indexes\r\n- Sample data patterns\r\n\r\n### 2. Use Few-Shot Examples\r\n\r\nProvide examples of similar queries:\r\n- Simple queries\r\n- Complex queries with joins\r\n- Aggregation queries\r\n- Subquery patterns\r\n\r\n### 3. Chain-of-Thought for Complex Queries\r\n\r\nFor complex queries, use chain-of-thought reasoning:\r\n- Break down query into steps\r\n- Identify required tables\r\n- Plan joins and aggregations\r\n- Generate SQL step by step\r\n\r\n### 4. RAG for Schema Understanding\r\n\r\nUse RAG to retrieve relevant schema information:\r\n- Find relevant tables for query\r\n- Understand relationships\r\n- Get column details\r\n- Retrieve query patterns\r\n\r\n## Related Skills\r\n\r\n- **classifier**: Classify database queries\r\n- **database-architect**: Use for schema design\r\n- **developer**: Generate query code\r\n\r\n## Related Documentation\r\n\r\n- [Classification Patterns](../docs/CLASSIFICATION_PATTERNS.md) - Classification guide\r\n- [Evaluation Guide](../docs/EVALUATION_GUIDE.md) - Comprehensive evaluation\r\n- [Claude Cookbooks - Text-to-SQL](https://github.com/anthropics/anthropic-cookbook/tree/main/capabilities/text_to_sql)\r\n\r\n",
          "tokens": 1384
        }
      }
    },
    "test-generator": {
      "name": "test-generator",
      "one_liner": "No description",
      "key_commands": ["/identity", "/capabilities", "/function", "/API", "/methods"],
      "token_count": {
        "minimal": 11,
        "essential": 191,
        "standard": 761,
        "full": 1705
      },
      "levels": {
        "minimal": {
          "content": "**test-generator**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: test-generator\n\nTest Generator Skill - Generates test code from specifications, components, and API endpoints following project testing patterns and conventions.\n\n### Key Steps:\n: Identify Test Type\r\n\r\nDetermine what type of test is needed:\r\n- **Unit Test**: Component/function testing\r\n- **Integration Test**: Service/API integration\r\n- **E2E Test**: Full user flow testing\r\n- **API Test**: Endpoint testing\r\n\r\n\n### Step: Analyze Target Code\r\n\r\nExamine code to test:\r\n- Read component/function code\r\n- Identify test cases\r\n- Understand dependencies\r\n- Note edge cases\r\n\r\n\n### Step: Analyze Test Patterns\r\n\r\nReview existing tests:\r\n- Read similar test files\r\n- Identify testing patterns\r\n- Note testing framework usage\r\n- Understand mocking strategies",
          "tokens": 191
        },
        "standard": {
          "content": "## Skill: test-generator\n\nTest Generator Skill - Generates test code from specifications, components, and API endpoints following project testing patterns and conventions.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Identify Test Type\r\n\r\nDetermine what type of test is needed:\r\n- **Unit Test**: Component/function testing\r\n- **Integration Test**: Service/API integration\r\n- **E2E Test**: Full user flow testing\r\n- **API Test**: Endpoint testing\r\n\r\n### Step 2: Analyze Target Code\r\n\r\nExamine code to test:\r\n- Read component/function code\r\n- Identify test cases\r\n- Understand dependencies\r\n- Note edge cases\r\n\r\n### Step 3: Analyze Test Patterns\r\n\r\nReview existing tests:\r\n- Read similar test files\r\n- Identify testing patterns\r\n- Note testing framework usage\r\n- Understand mocking strategies\r\n\r\n### Step 4: Generate Test Code\r\n\r\nCreate test following patterns:\r\n- Use appropriate testing framework\r\n- Follow project conventions\r\n- Include comprehensive coverage\r\n- Add edge cases and error scenarios\r\n\r\n### Step 5: Coverage Analysis\r\n\r\nAfter generating tests, analyze coverage:\r\n\r\n1. **Check that generated tests cover all requirements**:\r\n   - Verify all functions/methods are tested\r\n   - Check all branches are covered (if/else, switch, etc.)\r\n   - Ensure all edge cases are tested\r\n   - Validate error scenarios are covered\r\n\r\n2. **Validate tests are runnable**:\r\n   - Check test syntax is valid\r\n   - Verify imports are correct\r\n   - Ensure test framework is properly configured\r\n   - Validate test setup/teardown is correct\r\n\r\n3. **Report coverage percentage**:\r\n   - Calculate line coverage (if possible)\r\n   - Calculate branch coverage (if possible)\r\n   - Report uncovered code paths\r\n   - Suggest additional tests for uncovered areas\r\n\r\n4. **Coverage Validation Checklist**:\r\n   - [ ] All public functions/methods have tests\r\n   - [ ] All error paths are tested\r\n   - [ ] All edge cases are covered\r\n   - [ ] Tests are syntactically valid\r\n   - [ ] Tests can be executed successfully\r\n   - [ ] Coverage meets project thresholds (if defined)\r\n</execution_process>\n\n### Example:\n**Unit Test (React Component)**\r\n\r\n```typescript\r\nimport { render, screen, waitFor } from '@testing-library/react'\r\nimport { describe, it, expect, vi } from 'vitest'\r\nimport { UserProfile } from './user-profile'\r\n\r\ndescribe('UserProfile', () => {\r\n  it('renders user information', async () => {\r\n    const mockUser = { id: '1', name: 'John', email: 'john@example.com' }\r\n    \r\n    render(<UserProfile user={mockUser} />)\r\n    \r\n    await waitFor(() => {\r\n      expect(screen.getByText('John')).toBeInTheDocument()\r\n      expect(screen.getByText('john@example.com')).toBeInTheDocument()\r\n    })\r\n  })\r\n  \r\n  it('handles loading state', () => {\r\n    render(<UserProfile user={null} loading />)\r\n    expect(screen.getByTestId('loading')).toBeInTheDocument()\r\n  })\r\n  \r\n  it('handles error state', () => {\r\n    render(<UserProfile user={null} error=\"Failed to load\" />)\r\n    expect(screen.getByText('Failed to load')).toBeInTheDocument()\r\n  })\r\n})\r\n```",
          "tokens": 761
        },
        "full": {
          "content": "---\r\nname: test-generator\r\ndescription: Generates test code from specifications, components, and API endpoints. Creates unit tests, integration tests, and E2E tests following project testing patterns and conventions.\r\nallowed-tools: read, write, glob, search, codebase_search\r\nversion: 1.0\r\nbest_practices:\r\n  - Analyze existing test patterns\r\n  - Follow project testing conventions\r\n  - Generate comprehensive test coverage\r\n  - Include edge cases and error scenarios\r\n  - Use appropriate testing framework\r\nerror_handling: graceful\r\nstreaming: supported\r\ntemplates: [unit-test, integration-test, e2e-test, api-test]\r\n---\r\n\r\n<identity>\r\nTest Generator Skill - Generates test code from specifications, components, and API endpoints following project testing patterns and conventions.\r\n</identity>\r\n\r\n<capabilities>\r\n- Generating tests for new components\r\n- Creating tests for API endpoints\r\n- Generating E2E tests for user flows\r\n- Creating integration tests\r\n- Adding test coverage for existing code\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Identify Test Type\r\n\r\nDetermine what type of test is needed:\r\n- **Unit Test**: Component/function testing\r\n- **Integration Test**: Service/API integration\r\n- **E2E Test**: Full user flow testing\r\n- **API Test**: Endpoint testing\r\n\r\n### Step 2: Analyze Target Code\r\n\r\nExamine code to test:\r\n- Read component/function code\r\n- Identify test cases\r\n- Understand dependencies\r\n- Note edge cases\r\n\r\n### Step 3: Analyze Test Patterns\r\n\r\nReview existing tests:\r\n- Read similar test files\r\n- Identify testing patterns\r\n- Note testing framework usage\r\n- Understand mocking strategies\r\n\r\n### Step 4: Generate Test Code\r\n\r\nCreate test following patterns:\r\n- Use appropriate testing framework\r\n- Follow project conventions\r\n- Include comprehensive coverage\r\n- Add edge cases and error scenarios\r\n\r\n### Step 5: Coverage Analysis\r\n\r\nAfter generating tests, analyze coverage:\r\n\r\n1. **Check that generated tests cover all requirements**:\r\n   - Verify all functions/methods are tested\r\n   - Check all branches are covered (if/else, switch, etc.)\r\n   - Ensure all edge cases are tested\r\n   - Validate error scenarios are covered\r\n\r\n2. **Validate tests are runnable**:\r\n   - Check test syntax is valid\r\n   - Verify imports are correct\r\n   - Ensure test framework is properly configured\r\n   - Validate test setup/teardown is correct\r\n\r\n3. **Report coverage percentage**:\r\n   - Calculate line coverage (if possible)\r\n   - Calculate branch coverage (if possible)\r\n   - Report uncovered code paths\r\n   - Suggest additional tests for uncovered areas\r\n\r\n4. **Coverage Validation Checklist**:\r\n   - [ ] All public functions/methods have tests\r\n   - [ ] All error paths are tested\r\n   - [ ] All edge cases are covered\r\n   - [ ] Tests are syntactically valid\r\n   - [ ] Tests can be executed successfully\r\n   - [ ] Coverage meets project thresholds (if defined)\r\n</execution_process>\r\n</instructions>\r\n\r\n<examples>\r\n<code_example>\r\n**Unit Test (React Component)**\r\n\r\n```typescript\r\nimport { render, screen, waitFor } from '@testing-library/react'\r\nimport { describe, it, expect, vi } from 'vitest'\r\nimport { UserProfile } from './user-profile'\r\n\r\ndescribe('UserProfile', () => {\r\n  it('renders user information', async () => {\r\n    const mockUser = { id: '1', name: 'John', email: 'john@example.com' }\r\n    \r\n    render(<UserProfile user={mockUser} />)\r\n    \r\n    await waitFor(() => {\r\n      expect(screen.getByText('John')).toBeInTheDocument()\r\n      expect(screen.getByText('john@example.com')).toBeInTheDocument()\r\n    })\r\n  })\r\n  \r\n  it('handles loading state', () => {\r\n    render(<UserProfile user={null} loading />)\r\n    expect(screen.getByTestId('loading')).toBeInTheDocument()\r\n  })\r\n  \r\n  it('handles error state', () => {\r\n    render(<UserProfile user={null} error=\"Failed to load\" />)\r\n    expect(screen.getByText('Failed to load')).toBeInTheDocument()\r\n  })\r\n})\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Integration Test (API)**\r\n\r\n```typescript\r\nimport { describe, it, expect, beforeAll, afterAll } from 'vitest'\r\nimport { createTestClient } from './test-client'\r\n\r\ndescribe('Users API', () => {\r\n  let client: TestClient\r\n  \r\n  beforeAll(() => {\r\n    client = createTestClient()\r\n  })\r\n  \r\n  afterAll(async () => {\r\n    await client.cleanup()\r\n  })\r\n  \r\n  it('creates a user', async () => {\r\n    const response = await client.post('/api/users', {\r\n      email: 'test@example.com',\r\n      name: 'Test User'\r\n    })\r\n    \r\n    expect(response.status).toBe(201)\r\n    expect(response.data).toHaveProperty('id')\r\n    expect(response.data.email).toBe('test@example.com')\r\n  })\r\n  \r\n  it('validates required fields', async () => {\r\n    const response = await client.post('/api/users', {})\r\n    \r\n    expect(response.status).toBe(400)\r\n    expect(response.data).toHaveProperty('errors')\r\n  })\r\n})\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**E2E Test (Cypress)**\r\n\r\n```typescript\r\ndescribe('User Authentication Flow', () => {\r\n  beforeEach(() => {\r\n    cy.visit('/login')\r\n  })\r\n  \r\n  it('allows user to login', () => {\r\n    cy.get('[data-testid=\"email-input\"]').type('user@example.com')\r\n    cy.get('[data-testid=\"password-input\"]').type('password123')\r\n    cy.get('[data-testid=\"login-button\"]').click()\r\n    \r\n    cy.url().should('include', '/dashboard')\r\n    cy.get('[data-testid=\"user-menu\"]').should('be.visible')\r\n  })\r\n  \r\n  it('shows error for invalid credentials', () => {\r\n    cy.get('[data-testid=\"email-input\"]').type('invalid@example.com')\r\n    cy.get('[data-testid=\"password-input\"]').type('wrong')\r\n    cy.get('[data-testid=\"login-button\"]').click()\r\n    \r\n    cy.get('[data-testid=\"error-message\"]')\r\n      .should('be.visible')\r\n      .and('contain', 'Invalid credentials')\r\n  })\r\n})\r\n```\r\n</code_example>\r\n</examples>\r\n\r\n<instructions>\r\n<integration>\r\n**Integration with Developer Agent**:\r\n- Generates tests during development\r\n- Ensures test coverage\r\n- Validates implementation\r\n\r\n**Integration with QA Agent**:\r\n- Creates comprehensive test suites\r\n- Generates test plans\r\n- Validates test quality\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Follow Patterns**: Match existing test structure\r\n2. **Comprehensive Coverage**: Test happy paths and edge cases\r\n3. **Clear Test Names**: Descriptive test descriptions\r\n4. **Isolate Tests**: Each test should be independent\r\n5. **Mock Dependencies**: Use appropriate mocking strategies\r\n</best_practices>\r\n</instructions>\r\n\r\n<examples>\r\n<usage_example>\r\n**Example Commands**:\r\n\r\n```\r\n# Generate unit tests\r\nGenerate unit tests for components/user-profile\r\n\r\n# Generate API tests\r\nGenerate API tests for app/api/users\r\n\r\n# Generate E2E tests\r\nGenerate E2E tests for user authentication flow\r\n\r\n# Generate integration tests\r\nGenerate integration tests for user service\r\n```\r\n</usage_example>\r\n</examples>\r\n\r\n",
          "tokens": 1705
        }
      }
    },
    "chrome-devtools": {
      "name": "chrome-devtools",
      "one_liner": "No description",
      "key_commands": ["/network", "/example", "/path", "/to", "/file"],
      "token_count": {
        "minimal": 12,
        "essential": 7,
        "standard": 7,
        "full": 3179
      },
      "levels": {
        "minimal": {
          "content": "**chrome-devtools**: No description available",
          "tokens": 12
        },
        "essential": {
          "content": "## Skill: chrome-devtools\n",
          "tokens": 7
        },
        "standard": {
          "content": "## Skill: chrome-devtools\n",
          "tokens": 7
        },
        "full": {
          "content": "---\r\nname: chrome-devtools\r\ndescription: Chrome DevTools for AI agents. Control and inspect live Chrome browsers with performance tracing, network inspection, DOM snapshots, and automated interactions. Use for web debugging, performance analysis, and browser automation.\r\nallowed-tools: read, write, bash\r\nversion: 1.0\r\nbest_practices:\r\n  - Start with navigate_page before other operations\r\n  - Use take_screenshot to verify page state\r\n  - Check console messages for errors\r\n  - Use performance tracing for optimization tasks\r\n  - Handle dialogs before they block automation\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# Chrome DevTools Skill\r\n\r\n## Overview\r\n\r\nThis skill gives AI agents access to Chrome DevTools for controlling and inspecting live Chrome browsers. It provides 26 tools for browser automation, performance analysis, network inspection, and debugging.\r\n\r\n**Context Savings**: ~93% reduction\r\n- **MCP Mode**: ~25,000 tokens always loaded\r\n- **Skill Mode**: ~600 tokens metadata + on-demand loading\r\n\r\n## When to Use\r\n\r\n- Debugging web applications in real browsers\r\n- Performance profiling and optimization\r\n- Network request inspection and analysis\r\n- Automated browser testing\r\n- Taking screenshots and DOM snapshots\r\n- Form filling and interaction automation\r\n- Device/network emulation testing\r\n\r\n## Quick Reference\r\n\r\n```bash\r\n# List available tools\r\npython executor.py --list\r\n\r\n# Navigate to a page\r\npython executor.py --tool navigate_page --args '{\"url\": \"https://example.com\"}'\r\n\r\n# Take a screenshot\r\npython executor.py --tool take_screenshot --args '{}'\r\n\r\n# Start performance trace\r\npython executor.py --tool performance_start_trace --args '{}'\r\n```\r\n\r\n## Tools\r\n\r\n### Input Automation (8 tools)\r\n\r\n#### click\r\n\r\nInteract with page elements by clicking.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `selector` | string | CSS selector or element reference |\r\n| `options` | object | Click options (button, clickCount, etc.) |\r\n\r\n```bash\r\npython executor.py --tool click --args '{\"selector\": \"#submit-button\"}'\r\n```\r\n\r\n#### drag\r\n\r\nPerform drag operations on elements.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `source` | string | Source element selector |\r\n| `target` | string | Target element selector or coordinates |\r\n\r\n```bash\r\npython executor.py --tool drag --args '{\"source\": \"#draggable\", \"target\": \"#dropzone\"}'\r\n```\r\n\r\n#### fill\r\n\r\nInput text into form fields.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `selector` | string | Input field selector |\r\n| `value` | string | Text to enter |\r\n\r\n```bash\r\npython executor.py --tool fill --args '{\"selector\": \"#email\", \"value\": \"user@example.com\"}'\r\n```\r\n\r\n#### fill_form\r\n\r\nComplete multiple form fields at once.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `fields` | object | Map of selectors to values |\r\n\r\n```bash\r\npython executor.py --tool fill_form --args '{\"fields\": {\"#name\": \"John\", \"#email\": \"john@example.com\"}}'\r\n```\r\n\r\n#### handle_dialog\r\n\r\nRespond to browser dialogs (alerts, confirms, prompts).\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `accept` | boolean | Whether to accept or dismiss |\r\n| `promptText` | string | Text for prompt dialogs |\r\n\r\n```bash\r\npython executor.py --tool handle_dialog --args '{\"accept\": true}'\r\n```\r\n\r\n#### hover\r\n\r\nMove cursor over elements to trigger hover states.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `selector` | string | Element selector to hover |\r\n\r\n```bash\r\npython executor.py --tool hover --args '{\"selector\": \".dropdown-trigger\"}'\r\n```\r\n\r\n#### press_key\r\n\r\nSimulate keyboard input.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `key` | string | Key to press (e.g., \"Enter\", \"Tab\", \"Escape\") |\r\n| `modifiers` | array | Modifier keys (e.g., [\"Control\", \"Shift\"]) |\r\n\r\n```bash\r\npython executor.py --tool press_key --args '{\"key\": \"Enter\"}'\r\n```\r\n\r\n#### upload_file\r\n\r\nSubmit files through file input controls.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `selector` | string | File input selector |\r\n| `filePaths` | array | Paths to files to upload |\r\n\r\n```bash\r\npython executor.py --tool upload_file --args '{\"selector\": \"#file-input\", \"filePaths\": [\"/path/to/file.pdf\"]}'\r\n```\r\n\r\n### Navigation Automation (6 tools)\r\n\r\n#### navigate_page\r\n\r\nDirect the browser to specific URLs.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `url` | string | URL to navigate to |\r\n| `waitUntil` | string | Wait condition (load, domcontentloaded, networkidle) |\r\n\r\n```bash\r\npython executor.py --tool navigate_page --args '{\"url\": \"https://example.com\", \"waitUntil\": \"networkidle\"}'\r\n```\r\n\r\n#### new_page\r\n\r\nCreate additional browser tabs.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `url` | string | Optional URL for new page |\r\n\r\n```bash\r\npython executor.py --tool new_page --args '{\"url\": \"https://example.com\"}'\r\n```\r\n\r\n#### close_page\r\n\r\nShut down individual browser tabs/windows.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `pageId` | string | ID of page to close (optional, closes current) |\r\n\r\n```bash\r\npython executor.py --tool close_page --args '{}'\r\n```\r\n\r\n#### list_pages\r\n\r\nRetrieve all open browser pages.\r\n\r\n```bash\r\npython executor.py --tool list_pages --args '{}'\r\n```\r\n\r\n#### select_page\r\n\r\nSwitch between active pages.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `pageId` | string | ID of page to select |\r\n\r\n```bash\r\npython executor.py --tool select_page --args '{\"pageId\": \"page-123\"}'\r\n```\r\n\r\n#### wait_for\r\n\r\nPause execution until conditions are met.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `selector` | string | Element to wait for |\r\n| `state` | string | State to wait for (visible, hidden, attached, detached) |\r\n| `timeout` | number | Maximum wait time in ms |\r\n\r\n```bash\r\npython executor.py --tool wait_for --args '{\"selector\": \"#loading\", \"state\": \"hidden\"}'\r\n```\r\n\r\n### Emulation (2 tools)\r\n\r\n#### emulate\r\n\r\nSimulate different device types and configurations.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `device` | string | Device name (e.g., \"iPhone 12\", \"Pixel 5\") |\r\n| `userAgent` | string | Custom user agent |\r\n| `viewport` | object | Custom viewport dimensions |\r\n\r\n```bash\r\npython executor.py --tool emulate --args '{\"device\": \"iPhone 12\"}'\r\n```\r\n\r\n#### resize_page\r\n\r\nAdjust viewport dimensions.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `width` | number | Viewport width in pixels |\r\n| `height` | number | Viewport height in pixels |\r\n\r\n```bash\r\npython executor.py --tool resize_page --args '{\"width\": 1920, \"height\": 1080}'\r\n```\r\n\r\n### Performance Analysis (3 tools)\r\n\r\n#### performance_start_trace\r\n\r\nBegin recording performance data.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `categories` | array | Trace categories to capture |\r\n\r\n```bash\r\npython executor.py --tool performance_start_trace --args '{}'\r\n```\r\n\r\n#### performance_stop_trace\r\n\r\nComplete performance recording session.\r\n\r\n```bash\r\npython executor.py --tool performance_stop_trace --args '{}'\r\n```\r\n\r\n#### performance_analyze_insight\r\n\r\nExtract actionable performance metrics.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `traceData` | object | Trace data from stopped trace |\r\n\r\n```bash\r\npython executor.py --tool performance_analyze_insight --args '{}'\r\n```\r\n\r\n### Network Inspection (2 tools)\r\n\r\n#### list_network_requests\r\n\r\nView all intercepted network activity.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `filter` | object | Filter by URL pattern, status, type |\r\n\r\n```bash\r\npython executor.py --tool list_network_requests --args '{}'\r\n```\r\n\r\n#### get_network_request\r\n\r\nRetrieve specific network request details.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `requestId` | string | ID of the request |\r\n\r\n```bash\r\npython executor.py --tool get_network_request --args '{\"requestId\": \"req-123\"}'\r\n```\r\n\r\n### Debugging & Inspection (5 tools)\r\n\r\n#### take_screenshot\r\n\r\nCapture visual page state.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `fullPage` | boolean | Capture full scrollable page |\r\n| `selector` | string | Specific element to capture |\r\n| `format` | string | Image format (png, jpeg, webp) |\r\n\r\n```bash\r\npython executor.py --tool take_screenshot --args '{\"fullPage\": true}'\r\n```\r\n\r\n#### take_snapshot\r\n\r\nRecord DOM structure snapshots.\r\n\r\n```bash\r\npython executor.py --tool take_snapshot --args '{}'\r\n```\r\n\r\n#### evaluate_script\r\n\r\nExecute JavaScript within page context.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `expression` | string | JavaScript code to execute |\r\n\r\n```bash\r\npython executor.py --tool evaluate_script --args '{\"expression\": \"document.title\"}'\r\n```\r\n\r\n#### list_console_messages\r\n\r\nAccess all logged console messages.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `level` | string | Filter by level (log, warn, error, info) |\r\n\r\n```bash\r\npython executor.py --tool list_console_messages --args '{\"level\": \"error\"}'\r\n```\r\n\r\n#### get_console_message\r\n\r\nRetrieve specific console output.\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `messageId` | string | ID of the console message |\r\n\r\n```bash\r\npython executor.py --tool get_console_message --args '{\"messageId\": \"msg-123\"}'\r\n```\r\n\r\n## Common Workflows\r\n\r\n### Debug a Web Page\r\n\r\n```bash\r\n# 1. Navigate to page\r\npython executor.py --tool navigate_page --args '{\"url\": \"https://myapp.com\"}'\r\n\r\n# 2. Check for console errors\r\npython executor.py --tool list_console_messages --args '{\"level\": \"error\"}'\r\n\r\n# 3. Take screenshot of current state\r\npython executor.py --tool take_screenshot --args '{}'\r\n\r\n# 4. Inspect network requests\r\npython executor.py --tool list_network_requests --args '{}'\r\n```\r\n\r\n### Performance Analysis\r\n\r\n```bash\r\n# 1. Start trace\r\npython executor.py --tool performance_start_trace --args '{}'\r\n\r\n# 2. Navigate/interact with page\r\npython executor.py --tool navigate_page --args '{\"url\": \"https://myapp.com\"}'\r\n\r\n# 3. Stop trace and analyze\r\npython executor.py --tool performance_stop_trace --args '{}'\r\npython executor.py --tool performance_analyze_insight --args '{}'\r\n```\r\n\r\n### Form Automation\r\n\r\n```bash\r\n# 1. Navigate to form\r\npython executor.py --tool navigate_page --args '{\"url\": \"https://myapp.com/login\"}'\r\n\r\n# 2. Fill form fields\r\npython executor.py --tool fill_form --args '{\"fields\": {\"#username\": \"user\", \"#password\": \"pass\"}}'\r\n\r\n# 3. Submit\r\npython executor.py --tool click --args '{\"selector\": \"#submit\"}'\r\n\r\n# 4. Wait for navigation\r\npython executor.py --tool wait_for --args '{\"selector\": \"#dashboard\", \"state\": \"visible\"}'\r\n```\r\n\r\n### Mobile Testing\r\n\r\n```bash\r\n# 1. Emulate mobile device\r\npython executor.py --tool emulate --args '{\"device\": \"iPhone 12\"}'\r\n\r\n# 2. Navigate and test\r\npython executor.py --tool navigate_page --args '{\"url\": \"https://myapp.com\"}'\r\n\r\n# 3. Take mobile screenshot\r\npython executor.py --tool take_screenshot --args '{\"fullPage\": true}'\r\n```\r\n\r\n## Configuration\r\n\r\nMCP server configuration stored in `config.json`:\r\n- **Command**: `npx chrome-devtools-mcp@latest`\r\n- **Flags**: `--headless`, `--channel`, `--browser-url`, `--isolated`\r\n\r\n### Headless Mode\r\n\r\n```json\r\n{\r\n  \"args\": [\"chrome-devtools-mcp@latest\", \"--headless\"]\r\n}\r\n```\r\n\r\n### Connect to Existing Chrome\r\n\r\n```json\r\n{\r\n  \"args\": [\"chrome-devtools-mcp@latest\", \"--browser-url\", \"http://localhost:9222\"]\r\n}\r\n```\r\n\r\n## Error Handling\r\n\r\n**Common Issues:**\r\n- Chrome not installed: Install Chrome or use `--channel` flag\r\n- Element not found: Verify selector, use `wait_for` first\r\n- Dialog blocking: Handle dialogs before continuing\r\n- Timeout errors: Increase timeout or check page load\r\n\r\n**Recovery:**\r\n- Take screenshot to verify page state\r\n- Check console for JavaScript errors\r\n- List pages to ensure correct page is active\r\n- Use evaluate_script for custom debugging\r\n\r\n## Related\r\n\r\n- Original MCP: `chrome-devtools-mcp@latest`\r\n- Puppeteer Skill: `.claude/skills/puppeteer/`\r\n- MCP Converter: `.claude/skills/mcp-converter/`\r\n\r\n## Sources\r\n\r\n- [Chrome DevTools MCP - npm](https://www.npmjs.com/package/chrome-devtools-mcp)\r\n- [Chrome DevTools MCP - GitHub](https://github.com/ChromeDevTools/chrome-devtools-mcp)\r\n- [Chrome DevTools MCP Blog](https://developer.chrome.com/blog/chrome-devtools-mcp)\r\n",
          "tokens": 3179
        }
      }
    },
    "computer-use": {
      "name": "computer-use",
      "one_liner": "No description",
      "key_commands": ["/example", "/google", "/true", "/yes", "/skills"],
      "token_count": {
        "minimal": 11,
        "essential": 6,
        "standard": 6,
        "full": 2336
      },
      "levels": {
        "minimal": {
          "content": "**computer-use**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: computer-use\n",
          "tokens": 6
        },
        "standard": {
          "content": "## Skill: computer-use\n",
          "tokens": 6
        },
        "full": {
          "content": "---\r\nname: computer-use\r\ndescription: Browser automation with Playwright for computer use. Click, type, scroll, screenshot, and execute JavaScript. Use for web testing, automation, and visual verification tasks.\r\nallowed-tools: read, write, bash\r\n---\r\n\r\n# Computer Use Skill\r\n\r\n## Overview\r\n\r\nThis skill provides Playwright-powered browser automation capabilities via MCP, enabling programmatic interaction with web pages including clicking, typing, scrolling, and screenshot capture.\r\n\r\n**Context Savings**: ~90% reduction\r\n- **MCP Mode**: ~12,000 tokens always loaded (6 tools + cursor overlay)\r\n- **Skill Mode**: ~300 tokens metadata + on-demand loading\r\n\r\n## Requirements\r\n\r\n- Python 3.10+ installed\r\n- Playwright (auto-installed by executor)\r\n- Chromium browser (auto-installed via `playwright install chromium`)\r\n\r\n## Tools\r\n\r\nThe server provides 6 tools for browser automation:\r\n\r\n### Lifecycle Tools\r\n\r\n| Tool | Description |\r\n|------|-------------|\r\n| `initialize_browser` | Launch Chromium browser with URL, viewport size, headless mode |\r\n| `close_browser` | Close browser and release all resources |\r\n\r\n### Interaction Tools\r\n\r\n| Tool | Description |\r\n|------|-------------|\r\n| `execute_action` | Execute actions: click_at, type_text_at, scroll_to_percent, press_key, execute_javascript |\r\n| `click_selector` | Click element by CSS selector |\r\n| `fill_selector` | Fill form field by CSS selector |\r\n\r\n### State Capture Tools\r\n\r\n| Tool | Description |\r\n|------|-------------|\r\n| `capture_state` | Take screenshot and return path + current URL |\r\n\r\n## Quick Reference\r\n\r\n```bash\r\n# List available tools\r\npython executor.py --list\r\n\r\n# Initialize browser (headless)\r\npython executor.py --tool initialize_browser --args '{\"url\": \"https://example.com\", \"width\": 1440, \"height\": 900}'\r\n\r\n# Initialize browser (visible)\r\nCU_HEADFUL=1 python executor.py --tool initialize_browser --args '{\"url\": \"https://google.com\"}'\r\n\r\n# Click at coordinates (0-1000 scale)\r\npython executor.py --tool execute_action --args '{\"action_name\": \"click_at\", \"args\": {\"x\": 500, \"y\": 300}}'\r\n\r\n# Type text at coordinates\r\npython executor.py --tool execute_action --args '{\"action_name\": \"type_text_at\", \"args\": {\"x\": 500, \"y\": 300, \"text\": \"Hello World\", \"press_enter\": true}}'\r\n\r\n# Scroll to 50% of page\r\npython executor.py --tool execute_action --args '{\"action_name\": \"scroll_to_percent\", \"args\": {\"y\": 500}}'\r\n\r\n# Click by CSS selector\r\npython executor.py --tool click_selector --args '{\"selector\": \"button.submit\", \"nth\": 0}'\r\n\r\n# Fill form field\r\npython executor.py --tool fill_selector --args '{\"selector\": \"input[name=search]\", \"text\": \"Claude AI\", \"press_enter\": true}'\r\n\r\n# Take screenshot\r\npython executor.py --tool capture_state --args '{\"action_name\": \"after_click\"}'\r\n\r\n# Execute JavaScript\r\npython executor.py --tool execute_action --args '{\"action_name\": \"execute_javascript\", \"args\": {\"code\": \"document.title\"}}'\r\n\r\n# Close browser\r\npython executor.py --tool close_browser\r\n```\r\n\r\n## Configuration\r\n\r\n### Environment Variables\r\n\r\n| Variable | Description | Default |\r\n|----------|-------------|---------|\r\n| `CU_HEADFUL` | Show browser window (1/true/yes) | `false` (headless) |\r\n| `CU_SLOW_MO` | Delay between actions (ms) | `250` |\r\n| `CU_SHOW_CURSOR` | Show cursor overlay (1/true/yes) | `false` |\r\n| `CU_NO_SANDBOX` | Disable Chromium sandbox | `false` |\r\n| `CU_DEVICE_SCALE` | Device scale factor | `2` |\r\n\r\n### Setup\r\n\r\n1. **First run** (auto-installs dependencies):\r\n   ```bash\r\n   python .claude/skills/computer-use/executor.py --list\r\n   ```\r\n\r\n2. **For visible browser automation**:\r\n   ```bash\r\n   export CU_HEADFUL=1\r\n   export CU_SLOW_MO=500\r\n   ```\r\n\r\n## Coordinate System\r\n\r\nThe system uses a **0-1000 normalized scale** for viewport-independent automation:\r\n\r\n- `x=0` = left edge, `x=1000` = right edge\r\n- `y=0` = top edge, `y=1000` = bottom edge\r\n\r\nThis allows the same coordinates to work across different screen sizes.\r\n\r\n**Example**: To click the center of the viewport:\r\n```json\r\n{\"action_name\": \"click_at\", \"args\": {\"x\": 500, \"y\": 500}}\r\n```\r\n\r\n## Tool Details\r\n\r\n### initialize_browser\r\n\r\nLaunch Playwright Chromium browser with specified configuration.\r\n\r\n**Parameters**:\r\n- `url` (string, required): Initial URL to navigate to\r\n- `width` (number, optional): Viewport width in pixels (default: 1440)\r\n- `height` (number, optional): Viewport height in pixels (default: 900)\r\n- `headless` (boolean, optional): Run headless (overrides `CU_HEADFUL` env var)\r\n\r\n**Returns**:\r\n```json\r\n{\r\n  \"ok\": true,\r\n  \"url\": \"https://example.com\",\r\n  \"width\": 1440,\r\n  \"height\": 900,\r\n  \"headless\": true,\r\n  \"slow_mo_ms\": 250\r\n}\r\n```\r\n\r\n### execute_action\r\n\r\nExecute a single browser automation action.\r\n\r\n**Parameters**:\r\n- `action_name` (string, required): One of:\r\n  - `open_web_browser` - Navigate to URL\r\n  - `click_at` - Click at coordinates\r\n  - `type_text_at` - Type text at coordinates\r\n  - `scroll_to_percent` - Scroll to position\r\n  - `press_key` - Press keyboard key\r\n  - `execute_javascript` - Run JS code\r\n- `args` (object, required): Action-specific arguments\r\n\r\n**Action Arguments**:\r\n\r\n| Action | Required Args | Optional Args |\r\n|--------|---------------|---------------|\r\n| `open_web_browser` | `url` | - |\r\n| `click_at` | `x`, `y` (0-1000) | - |\r\n| `type_text_at` | `x`, `y`, `text` | `press_enter` |\r\n| `scroll_to_percent` | `y` (0-1000) | - |\r\n| `press_key` | `key` (e.g., \"Enter\", \"Meta+L\") | - |\r\n| `execute_javascript` | `code` | - |\r\n\r\n### capture_state\r\n\r\nTake a screenshot of the current browser state.\r\n\r\n**Parameters**:\r\n- `action_name` (string, required): Label for the screenshot file\r\n- `result_ok` (boolean, optional): Whether previous action succeeded\r\n- `error_msg` (string, optional): Error message if action failed\r\n\r\n**Returns**:\r\n```json\r\n{\r\n  \"ok\": true,\r\n  \"path\": \"/tmp/gemini_computer_use/1234567890_action.png\",\r\n  \"mime_type\": \"image/png\",\r\n  \"url\": \"https://example.com\"\r\n}\r\n```\r\n\r\n### click_selector\r\n\r\nClick an element by CSS selector.\r\n\r\n**Parameters**:\r\n- `selector` (string, required): CSS selector for the element\r\n- `nth` (number, optional): Index if multiple matches (default: 0)\r\n\r\n### fill_selector\r\n\r\nFill a form field by CSS selector.\r\n\r\n**Parameters**:\r\n- `selector` (string, required): CSS selector for the input field\r\n- `text` (string, required): Text to enter\r\n- `press_enter` (boolean, optional): Press Enter after typing\r\n- `clear` (boolean, optional): Clear field before typing (default: true)\r\n\r\n### close_browser\r\n\r\nClose the browser and release all Playwright resources.\r\n\r\n**Parameters**: None\r\n\r\n## Usage Examples\r\n\r\n### Web Search Automation\r\n\r\n```bash\r\n# Initialize browser\r\npython executor.py --tool initialize_browser --args '{\"url\": \"https://google.com\"}'\r\n\r\n# Click search box (approximate center)\r\npython executor.py --tool execute_action --args '{\"action_name\": \"click_at\", \"args\": {\"x\": 500, \"y\": 400}}'\r\n\r\n# Type search query\r\npython executor.py --tool execute_action --args '{\"action_name\": \"type_text_at\", \"args\": {\"x\": 500, \"y\": 400, \"text\": \"Claude AI\", \"press_enter\": true}}'\r\n\r\n# Capture results\r\npython executor.py --tool capture_state --args '{\"action_name\": \"search_results\"}'\r\n\r\n# Close browser\r\npython executor.py --tool close_browser\r\n```\r\n\r\n### Form Filling with Selectors\r\n\r\n```bash\r\n# Initialize\r\npython executor.py --tool initialize_browser --args '{\"url\": \"https://example.com/form\"}'\r\n\r\n# Fill fields by selector\r\npython executor.py --tool fill_selector --args '{\"selector\": \"#name\", \"text\": \"John Doe\"}'\r\npython executor.py --tool fill_selector --args '{\"selector\": \"#email\", \"text\": \"john@example.com\"}'\r\n\r\n# Click submit button\r\npython executor.py --tool click_selector --args '{\"selector\": \"button[type=submit]\"}'\r\n\r\n# Capture result\r\npython executor.py --tool capture_state --args '{\"action_name\": \"form_submitted\"}'\r\n```\r\n\r\n### JavaScript Extraction\r\n\r\n```bash\r\n# Get all links on page\r\npython executor.py --tool execute_action --args '{\"action_name\": \"execute_javascript\", \"args\": {\"code\": \"Array.from(document.querySelectorAll(\\\"a\\\")).map(a => ({text: a.textContent, href: a.href}))\"}}'\r\n\r\n# Get page title\r\npython executor.py --tool execute_action --args '{\"action_name\": \"execute_javascript\", \"args\": {\"code\": \"document.title\"}}'\r\n```\r\n\r\n## Integration with Agents\r\n\r\nThis skill integrates with the following agents:\r\n- **qa**: For automated browser testing and visual verification\r\n- **developer**: For debugging web applications\r\n- **devops**: For deployment verification and smoke tests\r\n\r\n## Troubleshooting\r\n\r\n| Error | Cause | Fix |\r\n|-------|-------|-----|\r\n| \"Browser not initialized\" | Tool called before `initialize_browser` | Call `initialize_browser` first |\r\n| \"Playwright not found\" | Dependencies not installed | Run `pip install playwright && playwright install chromium` |\r\n| \"click_at requires x and y\" | Missing coordinates | Provide both `x` and `y` in 0-1000 range |\r\n| \"Page load wait timed out\" | Slow page load | Increase timeout or wait for specific element |\r\n| \"No editable element at click point\" | Wrong coordinates | Use `fill_selector` instead for form fields |\r\n\r\n## Security Notes\r\n\r\n- Browser automation executes locally via Playwright\r\n- No remote code execution by default\r\n- Screenshots saved to `/tmp/gemini_computer_use/` (or system temp)\r\n- Clear screenshots after sensitive operations\r\n",
          "tokens": 2336
        }
      }
    },
    "recovery": {
      "name": "recovery",
      "one_liner": "No description",
      "key_commands": ["/context", "/history", "/gates", "/reasoning", "/artifacts"],
      "token_count": {
        "minimal": 10,
        "essential": 5,
        "standard": 5,
        "full": 974
      },
      "levels": {
        "minimal": {
          "content": "**recovery**: No description available",
          "tokens": 10
        },
        "essential": {
          "content": "## Skill: recovery\n",
          "tokens": 5
        },
        "standard": {
          "content": "## Skill: recovery\n",
          "tokens": 5
        },
        "full": {
          "content": "---\r\nname: recovery\r\ndescription: Workflow recovery protocol for resuming workflows after context loss, session interruption, or errors. Handles state reconstruction, artifact recovery, and seamless workflow continuation.\r\nallowed-tools: read, grep, glob, search\r\n---\r\n\r\n# Recovery Skill\r\n\r\nWorkflow recovery protocol for resuming workflows after context loss, session interruption, or errors.\r\n\r\n## When to Use\r\n\r\n- Context window exhausted mid-workflow\r\n- Session interrupted or lost\r\n- Need to resume from last completed step\r\n- Workflow state needs reconstruction\r\n\r\n## Instructions\r\n\r\n### Step 1: Identify Last Completed Step\r\n\r\n1. **Check gate files** for last successful validation:\r\n   - Location: `.claude/context/history/gates/{workflow_id}/`\r\n   - Find highest step number with validation_status: \"pass\"\r\n   - This is the last successfully completed step\r\n\r\n2. **Review reasoning files** for progress:\r\n   - Location: `.claude/context/history/reasoning/{workflow_id}/`\r\n   - Read reasoning files up to last completed step\r\n   - Extract context and decisions made\r\n\r\n3. **Identify artifacts created**:\r\n   - Check artifact registry: `.claude/context/artifacts/registry-{workflow_id}.json`\r\n   - List all artifacts created up to last step\r\n   - Verify artifact files exist\r\n\r\n### Step 2: Load Plan Documents\r\n\r\n1. **Read plan document** (stateless):\r\n   - Load `plan-{workflow_id}.json` from artifact registry\r\n   - Extract current workflow state\r\n   - Identify completed vs pending tasks\r\n\r\n2. **Load relevant phase plan** (if multi-phase):\r\n   - Check if project is multi-phase (exceeds phase_size_max_lines threshold)\r\n   - Load active phase plan: `plan-{workflow_id}-phase-{n}.json`\r\n   - Understand phase boundaries and dependencies\r\n\r\n3. **Understand current state**:\r\n   - Map completed tasks to plan\r\n   - Identify next steps\r\n   - Check for dependencies\r\n\r\n### Step 3: Context Recovery\r\n\r\n1. **Load artifacts from last completed step**:\r\n   - Read artifact registry\r\n   - Load all artifacts with validation_status: \"pass\"\r\n   - Verify artifact integrity\r\n\r\n2. **Read reasoning files for context**:\r\n   - Load reasoning files from completed steps\r\n   - Extract key decisions and context\r\n   - Understand workflow progression\r\n\r\n3. **Reconstruct workflow state**:\r\n   - Combine plan, artifacts, and reasoning\r\n   - Create recovery state document\r\n   - Validate state consistency\r\n\r\n### Step 4: Resume Execution\r\n\r\n1. **Continue from next step**:\r\n   - Identify next step after last completed\r\n   - Load step requirements from plan\r\n   - Prepare inputs for next step\r\n\r\n2. **Planner updates plan status** (stateless):\r\n   - Update plan-{workflow_id}.json with current status\r\n   - Mark completed steps\r\n   - Update progress tracking\r\n\r\n3. **Orchestrator coordinates next agents**:\r\n   - Pass recovered artifacts to next step\r\n   - Resume workflow execution\r\n   - Monitor for additional interruptions\r\n\r\n## Recovery Validation Checklist\r\n\r\n- [ ] Last completed step identified correctly\r\n- [ ] Plan document loaded and validated\r\n- [ ] All artifacts from completed steps available\r\n- [ ] Reasoning files reviewed for context\r\n- [ ] Workflow state reconstructed accurately\r\n- [ ] No duplicate work will be performed\r\n- [ ] Next step inputs prepared\r\n- [ ] Recovery logged in reasoning file\r\n\r\n## Error Handling\r\n\r\n- **Missing plan document**: Request planner to recreate plan from requirements\r\n- **Missing artifacts**: Request artifact recreation from source agent\r\n- **Corrupted artifacts**: Request artifact recreation with validation\r\n- **Incomplete reasoning**: Use artifact registry and gate files to reconstruct state\r\n\r\n## Related Documentation\r\n\r\n- [Planner Agent](../../agents/planner.md) - Stateless Behavior Rule\r\n- [Orchestrator Agent](../../agents/orchestrator.md) - Context Recovery\r\n- [CUJ-027](../../docs/cujs/CUJ-027.md) - Workflow Recovery After Context Loss\r\n\r\n",
          "tokens": 974
        }
      }
    },
    "response-rater": {
      "name": "response-rater",
      "one_liner": "Run headless AI CLIs (Claude Code, Gemini, OpenAI Codex, Cursor Agent, GitHub Copilot) to rate an assistant response against a rubric and return actionable feedback plus a rewritten improved response; use for response quality audits, prompt/docs reviews, and \"have another AI critique this answer\" workflows.",
      "key_commands": ["/docs", "/skills", "/response-rater", "/scripts", "/rate"],
      "token_count": {
        "minimal": 82,
        "essential": 84,
        "standard": 84,
        "full": 1869
      },
      "levels": {
        "minimal": {
          "content": "**response-rater**: Run headless AI CLIs (Claude Code, Gemini, OpenAI Codex, Cursor Agent, GitHub Copilot) to rate an assistant response against a rubric and return actionable feedback plus a rewritten improved response; use for response quality audits, prompt/docs reviews, and \"have another AI critique this answer\" workflows.",
          "tokens": 82
        },
        "essential": {
          "content": "## Skill: response-rater\n\nRun headless AI CLIs (Claude Code, Gemini, OpenAI Codex, Cursor Agent, GitHub Copilot) to rate an assistant response against a rubric and return actionable feedback plus a rewritten improved response; use for response quality audits, prompt/docs reviews, and \"have another AI critique this answer\" workflows.\n",
          "tokens": 84
        },
        "standard": {
          "content": "## Skill: response-rater\n\nRun headless AI CLIs (Claude Code, Gemini, OpenAI Codex, Cursor Agent, GitHub Copilot) to rate an assistant response against a rubric and return actionable feedback plus a rewritten improved response; use for response quality audits, prompt/docs reviews, and \"have another AI critique this answer\" workflows.\n",
          "tokens": 84
        },
        "full": {
          "content": "---\nname: response-rater\ndescription: Run headless AI CLIs (Claude Code, Gemini, OpenAI Codex, Cursor Agent, GitHub Copilot) to rate an assistant response against a rubric and return actionable feedback plus a rewritten improved response; use for response quality audits, prompt/docs reviews, and \"have another AI critique this answer\" workflows.\n---\n\n# Response Rater\n\nUse this skill to get *independent* critiques of an assistant response by calling external AI CLIs in headless mode and aggregating the results.\n\n## Supported Providers\n\n| Provider | CLI Command | Auth | Default Model |\n|----------|-------------|------|---------------|\n| **Claude Code** | `claude` | Session or `ANTHROPIC_API_KEY` | (CLI default) |\n| **Gemini CLI** | `gemini` | Session or `GEMINI_API_KEY`/`GOOGLE_API_KEY` | gemini-3-pro-preview |\n| **OpenAI Codex** | `codex` | `OPENAI_API_KEY` or `CODEX_API_KEY` | gpt-5.1-codex-max |\n| **Cursor Agent** | `cursor-agent` (via WSL on Windows) | Session or `CURSOR_API_KEY` | auto |\n| **GitHub Copilot** | `copilot` | GitHub auth (`gh auth login`) | claude-sonnet-4.5 |\n\n## Quick Start\n\n1) Save the response you want reviewed to a file (or pipe it via stdin).\n\n2) Ensure you have at least one provider authenticated (see table above).\n\n3) Run:\n\n```bash\nnode .claude/skills/response-rater/scripts/rate.cjs --response-file <path> --providers claude,gemini\n```\n\nOr via stdin (PowerShell):\n\n```powershell\nGet-Content response.txt | node .claude/skills/response-rater/scripts/rate.cjs --providers claude,gemini\n```\n\nOr via stdin (Bash):\n\n```bash\ncat response.txt | node .claude/skills/response-rater/scripts/rate.cjs --providers claude,gemini\n```\n\n## All Providers Example\n\n```bash\nnode .claude/skills/response-rater/scripts/rate.cjs \\\n  --response-file response.txt \\\n  --providers claude,gemini,codex,cursor,copilot\n```\n\n## Model Selection\n\nEach provider has a configurable model:\n\n```bash\n# Use specific models for each provider\nnode .claude/skills/response-rater/scripts/rate.cjs \\\n  --response-file response.txt \\\n  --providers gemini,codex,copilot \\\n  --gemini-model gemini-2.5-pro \\\n  --codex-model gpt-5.1-codex \\\n  --copilot-model gpt-5\n```\n\n### Available Models by Provider\n\n**Gemini CLI:**\n- `gemini-3-pro-preview` (default, latest flagship)\n- `gemini-3-flash-preview` (fast, latest)\n- `gemini-2.5-pro` (stable pro)\n- `gemini-2.5-flash` (stable fast)\n- `gemini-2.5-flash-lite` (lightweight)\n\n**OpenAI Codex:**\n- `gpt-5.1-codex-max` (default, flagship)\n- `gpt-5.1-codex` (standard)\n- `gpt-5.1-codex-mini` (faster/cheaper)\n\n**Cursor Agent:**\n- `auto` (default, smart selection)\n- `gpt-5.1-high`, `gpt-5.1-codex-high`\n- `opus-4.5`, `sonnet-4.5`\n- `gemini-3-pro`\n\n**GitHub Copilot:**\n- `claude-sonnet-4.5` (default)\n- `claude-opus-4.5`, `claude-haiku-4.5`, `claude-sonnet-4`\n- `gpt-5.1-codex-max`, `gpt-5.1-codex`, `gpt-5.1-codex-mini`\n- `gpt-5.2`, `gpt-5.1`, `gpt-5`, `gpt-5-mini`, `gpt-4.1`\n- `gemini-3-pro-preview`\n\n## Templates\n\n```bash\n# Response review (default) - critique against rubric\n--template response-review\n\n# Vocabulary review - security audit for LLM vocabulary files\n--template vocab-review\n```\n\n### Vocabulary Review Example\n\n```powershell\nGet-Content vocabulary.json | node .claude/skills/response-rater/scripts/rate.cjs \\\n  --providers claude,gemini \\\n  --template vocab-review\n```\n\n## Auth Behavior\n\nBy default the runner uses `--auth-mode session-first`:\n\n1. Try the CLI using your existing logged-in session/subscription\n2. If that fails and env keys exist, retry using env keys\n\nTo flip the order:\n\n```bash\nnode .claude/skills/response-rater/scripts/rate.cjs \\\n  --response-file response.txt \\\n  --auth-mode env-first \\\n  --providers claude,gemini\n```\n\n## Direct Headless Commands (No Script)\n\n**Claude Code:**\n```powershell\nGet-Content response.txt | claude -p --output-format json --permission-mode bypassPermissions\n```\n\n**Gemini CLI:**\n```powershell\nGet-Content response.txt | gemini --output-format json --model gemini-3-pro-preview\n```\n\n**OpenAI Codex:**\n```bash\ncodex exec --json --color never --model gpt-5.1-codex-max --skip-git-repo-check \"Your prompt\"\n```\n\n**Cursor Agent (via WSL on Windows):**\n```bash\nwsl bash -lc \"cursor-agent -p 'Your prompt' --output-format json --model auto\"\n```\n\n**GitHub Copilot:**\n```bash\ncopilot -p --silent --no-color --model claude-sonnet-4.5 \"Your prompt\"\n```\n\n## Output Format\n\nJSON to stdout with:\n\n- `promptVersion`: Schema version\n- `template`: Template used\n- `authMode`: Auth mode used\n- `providers`: Object with per-provider results:\n  - `ok`: Boolean success\n  - `authUsed`: Which auth method worked\n  - `raw`: Truncated raw output\n  - `parsed`: Extracted JSON with `scores`, `summary`, `improvements`, `rewrite`\n  - `attempts`: Auth attempt history\n\n### Sample Output\n\n```json\n{\n  \"promptVersion\": 3,\n  \"template\": \"response-review\",\n  \"authMode\": \"session-first\",\n  \"providers\": {\n    \"claude\": {\n      \"ok\": true,\n      \"authUsed\": \"session\",\n      \"parsed\": {\n        \"scores\": {\n          \"correctness\": 8,\n          \"completeness\": 7,\n          \"clarity\": 9,\n          \"actionability\": 8,\n          \"risk_management\": 6,\n          \"constraint_alignment\": 8,\n          \"brevity\": 7\n        },\n        \"summary\": \"The response is well-structured...\",\n        \"improvements\": [\"Add error handling for...\", \"...\"],\n        \"rewrite\": \"Improved version...\"\n      }\n    },\n    \"gemini\": { \"ok\": true, \"...\" },\n    \"codex\": { \"ok\": true, \"...\" }\n  }\n}\n```\n\n## Notes / Constraints\n\n- This skill **requires network access** to contact the providers.\n- If a provider is missing credentials, it will be skipped with a clear error.\n- Keep the reviewed response reasonably sized; start with the exact section you want critiqued.\n- Timeout is 180 seconds per provider (3 minutes).\n\n## Installation Requirements\n\nInstall the CLIs you want to use:\n\n```bash\n# Claude Code (via npm)\nnpm install -g @anthropic-ai/claude-code\n\n# Gemini CLI (via npm)\nnpm install -g @anthropic-ai/gemini\n\n# OpenAI Codex (via npm)\nnpm install -g @openai/codex\n\n# Cursor Agent (via curl, inside WSL on Windows)\nwsl bash -lc \"curl https://cursor.com/install -fsS | bash\"\n\n# GitHub Copilot (via npm)\nnpm install -g @github/copilot\n```\n\n## Skill Invocation\n\n**Natural language** (recommended):\n```\n\"Rate this response against the rubric\"\n\"Have another AI critique this answer\"\n\"Review the vocabulary file for security issues\"\n\"Get feedback from Claude, Gemini, and Codex on this response\"\n```\n\n**Direct CLI**:\n```bash\nnode .claude/skills/response-rater/scripts/rate.cjs --response-file response.txt --providers claude,gemini,codex,cursor,copilot\n```\n\n## CLI Reference\n\n```\nUsage:\n  node .claude/skills/response-rater/scripts/rate.cjs --response-file <path> [options]\n  cat response.txt | node .claude/skills/response-rater/scripts/rate.cjs [options]\n\nOptions:\n  --response-file <path>   # file containing the response to review\n  --question-file <path>   # optional; original question/request for context\n  --providers <list>       # comma-separated: claude,gemini,codex,cursor,copilot\n\nModels:\n  --gemini-model <model>   # default: gemini-3-pro-preview\n  --codex-model <model>    # default: gpt-5.1-codex-max\n  --cursor-model <model>   # default: auto\n  --copilot-model <model>  # default: claude-sonnet-4.5\n\nTemplates:\n  --template response-review   # default\n  --template vocab-review      # security audit\n\nAuth:\n  --auth-mode session-first   # default\n  --auth-mode env-first       # try env keys first\n```\n",
          "tokens": 1869
        }
      }
    },
    "artifact-publisher": {
      "name": "artifact-publisher",
      "one_liner": "Publish and share Claude Artifacts with Projects, Cursor, and downstream agents. Use when a user wants to \"save\", \"share\", or \"finalize\" a generated artifact.",
      "key_commands": ["/identity", "/capabilities", "/tools", "/run-manager", "/false"],
      "token_count": {
        "minimal": 46,
        "essential": 125,
        "standard": 2330,
        "full": 2900
      },
      "levels": {
        "minimal": {
          "content": "**artifact-publisher**: Publish and share Claude Artifacts with Projects, Cursor, and downstream agents. Use when a user wants to \"save\", \"share\", or \"finalize\" a generated artifact.",
          "tokens": 46
        },
        "essential": {
          "content": "## Skill: artifact-publisher\n\nPublish and share Claude Artifacts with Projects, Cursor, and downstream agents. Use when a user wants to \"save\", \"share\", or \"finalize\" a generated artifact.\n\nArtifact Publisher - Handles the lifecycle of Claude Artifacts, ensuring they are properly versioned and distributed.\n\n**Platform Support**: This skill works across all platforms (Claude, Cursor, Factory, OpenCode) with platform-specific invocation methods but consistent metadata structure.\n\n### Key Steps:\n",
          "tokens": 125
        },
        "standard": {
          "content": "## Skill: artifact-publisher\n\nPublish and share Claude Artifacts with Projects, Cursor, and downstream agents. Use when a user wants to \"save\", \"share\", or \"finalize\" a generated artifact.\n\nArtifact Publisher - Handles the lifecycle of Claude Artifacts, ensuring they are properly versioned and distributed.\n\n**Platform Support**: This skill works across all platforms (Claude, Cursor, Factory, OpenCode) with platform-specific invocation methods but consistent metadata structure.\n\n### Instructions:\n<execution_process>\n1. **Check Registry**: If artifact is registered, check registry metadata for:\n   - Use `readArtifactRegistry(runId)` from `.claude/tools/run-manager.mjs` to load registry\n   - Check `publishable: true` - Should this artifact be published?\n   - Check `publish_targets` - Where to publish (e.g., `[\"project_feed\", \"cursor\"]`)\n   - Extract `workflow_id` and `step_number` from registry metadata\n   \n2. **Creation**: Use `create_artifact` to finalize a code block or document into a persistent artifact.\n   - Include metadata: `workflow_id`, `step_number`, `dependencies` from registry\n   - Add validation status from gate file if available\n   \n3. **Distribution**: Use `share_artifact` to push the artifact to the Claude Project feed or external integrations.\n   - Publish to targets specified in registry metadata or default to `[\"project_feed\"]`\n   \n4. **Publishing**: Use `publish_artifact` to formally publish an artifact, updating its `published` status and `published_at` timestamp in the artifact registry.\n   - This is the formal publishing step that marks an artifact as published\n   - Updates registry metadata with publishing status\n   \n5. **Update Registry**: After publishing (success or failure):\n   - Use `updateArtifactPublishingStatus(runId, artifactName, status)` from `.claude/tools/run-manager.mjs`\n   - Update `published: true/false` in registry metadata\n   - Set `published_at` timestamp on success\n   - Update `publish_status`: 'success' or 'failed'\n   - Record `publish_error` if publication failed\n   - Add to `publish_attempts` array for retry tracking\n   - Example call:\n     ```javascript\n     await updateArtifactPublishingStatus(runId, artifactName, {\n       published: true,\n       published_at: new Date().toISOString(),\n       publish_status: 'success',\n       attempt: {\n         timestamp: new Date().toISOString(),\n         status: 'success',\n         target: 'project_feed'\n       }\n     });\n     ```\n   \n6. **Error Handling & Retry**:\n   - **Retry Logic**: If publication fails, retry up to `max_attempts` (default: 3) with exponential backoff\n   - **Backoff Strategy**: Use delays from `retry_config`: initial_delay_ms (1000ms), then 2x, 4x, up to max_delay_ms (8000ms)\n   - **Status Tracking**: Track each attempt in `publish_attempts` array with timestamp and error using `updateArtifactPublishingStatus()`\n   - **Validation Check**: Only publish artifacts with `validation_status: 'pass'` unless `validation_required: false` override\n   - **Notifications**: Log publishing success/failure; include in gate file if available\n   - **Fallback**: If all retries fail, mark as `publish_status: 'failed'` and log error for manual intervention\n   - **Retry Implementation**:\n     ```javascript\n     async function publishWithRetry(artifact, runId, maxRetries = 3) {\n       const delays = [1000, 2000, 4000]; // From retry_config\n       for (let attempt = 0; attempt < maxRetries; attempt++) {\n         try {\n           await publishArtifact(artifact);\n           await updateArtifactPublishingStatus(runId, artifact.name, {\n             status: 'success',\n             published: true,\n             published_at: new Date().toISOString(),\n             attempt: { timestamp: new Date().toISOString(), status: 'success' }\n           });\n           return;\n         } catch (error) {\n           await updateArtifactPublishingStatus(runId, artifact.name, {\n             status: attempt === maxRetries - 1 ? 'failed' : 'pending',\n             publish_error: error.message,\n             attempt: { timestamp: new Date().toISOString(), status: 'failed', error: error.message }\n           });\n           if (attempt < maxRetries - 1) {\n             await new Promise(resolve => setTimeout(resolve, delays[attempt]));\n           }\n         }\n       }\n       throw new Error(`Publishing failed after ${maxRetries} attempts`);\n     }\n     ```\n</execution_process>\n\n<error_handling>\n**Publishing Failures**:\n\n1. **Transient Errors** (network, rate limits):\n   - Retry with exponential backoff: 1s, 2s, 4s\n   - Maximum 3 retries\n   - Log each attempt in registry metadata\n\n2. **Permanent Errors** (invalid artifact, permission denied):\n   - Fail immediately (no retry)\n   - Log error in registry: `publish_error`\n   - Set `publish_status: 'failed'`\n   - Include error details in gate file if available\n\n3. **Status Tracking**:\n   ```javascript\n   metadata: {\n     publish_attempts: [\n       { timestamp: \"2025-11-29T10:00:00Z\", status: \"failed\", error: \"Network timeout\" },\n       { timestamp: \"2025-11-29T10:00:01Z\", status: \"success\" }\n     ],\n     publish_status: \"success\" | \"failed\" | \"pending\",\n     publish_error: null | \"Error message\"\n   }\n   ```\n\n4. **Notifications**:\n   - Log success: \"✅ Artifact published successfully to project_feed\"\n   - Log failure: \"❌ Artifact publishing failed after 3 retries: [error]\"\n   - Include in gate file validation results if available\n</error_handling>\n\n<workflow_integration>\n- **Post-Tool Trigger**: This skill is often invoked automatically after a `PostToolUse` hook to snapshot the results of a tool execution.\n- **Factory Droid**: Published artifacts are the primary way Factory Droids consume instructions from Claude.\n- **Publishing Policy**: The `publish_policy` in the frontmatter dictates when artifacts are automatically published:\n  - `manual`: Requires explicit `publish_artifact` call.\n  - `auto-on-pass`: Automatically publishes if the artifact's validation status is 'pass'.\n  - `auto-on-complete`: Automatically publishes upon workflow completion.\n- **Artifact Registry Integration**: \n  - Use `readArtifactRegistry(runId)` from `.claude/tools/run-manager.mjs` to check registry\n  - Check artifact registry for `publishable: true` metadata to auto-publish\n  - Use `updateArtifactPublishingStatus(runId, artifactName, status)` to update registry after publication\n  - Read `workflow_id` and `step_number` from registry metadata\n  - Track publishing attempts and errors in registry via `publish_attempts` array\n  - **Migration Note**: Prefer run-manager.mjs over artifact-registry.mjs (deprecated)\n\n**Publishing Policy Examples**:\n\n1. **Manual Publishing** (`publish_policy: manual`):\n   ```yaml\n   # In workflow YAML or skill frontmatter\n   publish_policy: manual\n   ```\n   - Artifacts are only published when explicitly requested\n   - Use: \"Publish this artifact\" or `publish_artifact` tool call\n   - Example: User reviews artifact, then explicitly publishes it\n\n2. **Auto-on-Pass** (`publish_policy: auto-on-pass`):\n   ```yaml\n   # In workflow YAML or skill frontmatter\n   publish_policy: auto-on-pass\n   ```\n   - Artifacts are automatically published when validation status is 'pass'\n   - Use: When you want to publish all validated artifacts automatically\n   - Example: After gate file validation passes, artifact is automatically published\n   - Implementation:\n   ```javascript\n   // After gate validation passes\n   if (artifact.validationStatus === 'pass' && publishPolicy === 'auto-on-pass') {\n     await publishArtifact(artifact);\n     await updateArtifactPublishingStatus(runId, artifact.name, {\n       published: true,\n       published_at: new Date().toISOString(),\n       publish_status: 'success'\n     });\n   }\n   ```\n\n3. **Auto-on-Complete** (`publish_policy: auto-on-complete`):\n   ```yaml\n   # In workflow YAML or skill frontmatter\n   publish_policy: auto-on-complete\n   ```\n   - Artifacts are automatically published when workflow completes\n   - Use: When you want to publish all artifacts at workflow end\n   - Example: At workflow completion, all artifacts with `publishable: true` are published\n   - Implementation:\n   ```javascript\n   // At workflow completion\n   if (workflowStatus === 'completed' && publishPolicy === 'auto-on-complete') {\n     const registry = await readArtifactRegistry(runId);\n     for (const [name, artifact] of Object.entries(registry.artifacts)) {\n       if (artifact.publishable && !artifact.published) {\n         await publishArtifact(artifact);\n         await updateArtifactPublishingStatus(runId, name, {\n           published: true,\n           published_at: new Date().toISOString(),\n           publish_status: 'success'\n         });\n       }\n     }\n   }\n   ```\n\n**Configuring Publish Targets Per Artifact**:\n```javascript\n// When registering artifact\nawait registerArtifact(runId, {\n  name: 'plan-123.json',\n  step: 0,\n  agent: 'planner',\n  publishable: true,\n  publish_targets: ['project_feed', 'cursor'], // Multiple targets\n  // ... other fields\n});\n```\n\n**Handling Publishing Failures in Workflows**:\n- If publishing fails, workflow continues (non-blocking)\n- Publishing errors are logged in registry: `publish_error`\n- Failed artifacts can be retried manually or in next workflow run\n- Gate files include publishing status for visibility\n</workflow_integration>\n",
          "tokens": 2330
        },
        "full": {
          "content": "---\nname: artifact-publisher\ndescription: Publish and share Claude Artifacts with Projects, Cursor, and downstream agents. Use when a user wants to \"save\", \"share\", or \"finalize\" a generated artifact.\nallowed-tools: create_artifact, share_artifact, publish_artifact\npublish_policy: manual # Options: manual, auto-on-pass, auto-on-complete\nretry_config:\n  max_attempts: 3\n  backoff_strategy: exponential\n  initial_delay_ms: 1000\n  max_delay_ms: 8000\nvalidation_required: true # Only publish artifacts with validation_status: 'pass' unless override\n---\n\n<identity>\nArtifact Publisher - Handles the lifecycle of Claude Artifacts, ensuring they are properly versioned and distributed.\n\n**Platform Support**: This skill works across all platforms (Claude, Cursor, Factory, OpenCode) with platform-specific invocation methods but consistent metadata structure.\n</identity>\n\n<capabilities>\n- Publishing and sharing Claude Artifacts with Projects, Cursor, and downstream agents\n- Saving, sharing, or finalizing generated artifacts\n- Versioning artifacts\n- Distributing artifacts to external integrations\n</capabilities>\n\n<instructions>\n<execution_process>\n1. **Check Registry**: If artifact is registered, check registry metadata for:\n   - Use `readArtifactRegistry(runId)` from `.claude/tools/run-manager.mjs` to load registry\n   - Check `publishable: true` - Should this artifact be published?\n   - Check `publish_targets` - Where to publish (e.g., `[\"project_feed\", \"cursor\"]`)\n   - Extract `workflow_id` and `step_number` from registry metadata\n   \n2. **Creation**: Use `create_artifact` to finalize a code block or document into a persistent artifact.\n   - Include metadata: `workflow_id`, `step_number`, `dependencies` from registry\n   - Add validation status from gate file if available\n   \n3. **Distribution**: Use `share_artifact` to push the artifact to the Claude Project feed or external integrations.\n   - Publish to targets specified in registry metadata or default to `[\"project_feed\"]`\n   \n4. **Publishing**: Use `publish_artifact` to formally publish an artifact, updating its `published` status and `published_at` timestamp in the artifact registry.\n   - This is the formal publishing step that marks an artifact as published\n   - Updates registry metadata with publishing status\n   \n5. **Update Registry**: After publishing (success or failure):\n   - Use `updateArtifactPublishingStatus(runId, artifactName, status)` from `.claude/tools/run-manager.mjs`\n   - Update `published: true/false` in registry metadata\n   - Set `published_at` timestamp on success\n   - Update `publish_status`: 'success' or 'failed'\n   - Record `publish_error` if publication failed\n   - Add to `publish_attempts` array for retry tracking\n   - Example call:\n     ```javascript\n     await updateArtifactPublishingStatus(runId, artifactName, {\n       published: true,\n       published_at: new Date().toISOString(),\n       publish_status: 'success',\n       attempt: {\n         timestamp: new Date().toISOString(),\n         status: 'success',\n         target: 'project_feed'\n       }\n     });\n     ```\n   \n6. **Error Handling & Retry**:\n   - **Retry Logic**: If publication fails, retry up to `max_attempts` (default: 3) with exponential backoff\n   - **Backoff Strategy**: Use delays from `retry_config`: initial_delay_ms (1000ms), then 2x, 4x, up to max_delay_ms (8000ms)\n   - **Status Tracking**: Track each attempt in `publish_attempts` array with timestamp and error using `updateArtifactPublishingStatus()`\n   - **Validation Check**: Only publish artifacts with `validation_status: 'pass'` unless `validation_required: false` override\n   - **Notifications**: Log publishing success/failure; include in gate file if available\n   - **Fallback**: If all retries fail, mark as `publish_status: 'failed'` and log error for manual intervention\n   - **Retry Implementation**:\n     ```javascript\n     async function publishWithRetry(artifact, runId, maxRetries = 3) {\n       const delays = [1000, 2000, 4000]; // From retry_config\n       for (let attempt = 0; attempt < maxRetries; attempt++) {\n         try {\n           await publishArtifact(artifact);\n           await updateArtifactPublishingStatus(runId, artifact.name, {\n             status: 'success',\n             published: true,\n             published_at: new Date().toISOString(),\n             attempt: { timestamp: new Date().toISOString(), status: 'success' }\n           });\n           return;\n         } catch (error) {\n           await updateArtifactPublishingStatus(runId, artifact.name, {\n             status: attempt === maxRetries - 1 ? 'failed' : 'pending',\n             publish_error: error.message,\n             attempt: { timestamp: new Date().toISOString(), status: 'failed', error: error.message }\n           });\n           if (attempt < maxRetries - 1) {\n             await new Promise(resolve => setTimeout(resolve, delays[attempt]));\n           }\n         }\n       }\n       throw new Error(`Publishing failed after ${maxRetries} attempts`);\n     }\n     ```\n</execution_process>\n\n<error_handling>\n**Publishing Failures**:\n\n1. **Transient Errors** (network, rate limits):\n   - Retry with exponential backoff: 1s, 2s, 4s\n   - Maximum 3 retries\n   - Log each attempt in registry metadata\n\n2. **Permanent Errors** (invalid artifact, permission denied):\n   - Fail immediately (no retry)\n   - Log error in registry: `publish_error`\n   - Set `publish_status: 'failed'`\n   - Include error details in gate file if available\n\n3. **Status Tracking**:\n   ```javascript\n   metadata: {\n     publish_attempts: [\n       { timestamp: \"2025-11-29T10:00:00Z\", status: \"failed\", error: \"Network timeout\" },\n       { timestamp: \"2025-11-29T10:00:01Z\", status: \"success\" }\n     ],\n     publish_status: \"success\" | \"failed\" | \"pending\",\n     publish_error: null | \"Error message\"\n   }\n   ```\n\n4. **Notifications**:\n   - Log success: \"✅ Artifact published successfully to project_feed\"\n   - Log failure: \"❌ Artifact publishing failed after 3 retries: [error]\"\n   - Include in gate file validation results if available\n</error_handling>\n\n<workflow_integration>\n- **Post-Tool Trigger**: This skill is often invoked automatically after a `PostToolUse` hook to snapshot the results of a tool execution.\n- **Factory Droid**: Published artifacts are the primary way Factory Droids consume instructions from Claude.\n- **Publishing Policy**: The `publish_policy` in the frontmatter dictates when artifacts are automatically published:\n  - `manual`: Requires explicit `publish_artifact` call.\n  - `auto-on-pass`: Automatically publishes if the artifact's validation status is 'pass'.\n  - `auto-on-complete`: Automatically publishes upon workflow completion.\n- **Artifact Registry Integration**: \n  - Use `readArtifactRegistry(runId)` from `.claude/tools/run-manager.mjs` to check registry\n  - Check artifact registry for `publishable: true` metadata to auto-publish\n  - Use `updateArtifactPublishingStatus(runId, artifactName, status)` to update registry after publication\n  - Read `workflow_id` and `step_number` from registry metadata\n  - Track publishing attempts and errors in registry via `publish_attempts` array\n  - **Migration Note**: Prefer run-manager.mjs over artifact-registry.mjs (deprecated)\n\n**Publishing Policy Examples**:\n\n1. **Manual Publishing** (`publish_policy: manual`):\n   ```yaml\n   # In workflow YAML or skill frontmatter\n   publish_policy: manual\n   ```\n   - Artifacts are only published when explicitly requested\n   - Use: \"Publish this artifact\" or `publish_artifact` tool call\n   - Example: User reviews artifact, then explicitly publishes it\n\n2. **Auto-on-Pass** (`publish_policy: auto-on-pass`):\n   ```yaml\n   # In workflow YAML or skill frontmatter\n   publish_policy: auto-on-pass\n   ```\n   - Artifacts are automatically published when validation status is 'pass'\n   - Use: When you want to publish all validated artifacts automatically\n   - Example: After gate file validation passes, artifact is automatically published\n   - Implementation:\n   ```javascript\n   // After gate validation passes\n   if (artifact.validationStatus === 'pass' && publishPolicy === 'auto-on-pass') {\n     await publishArtifact(artifact);\n     await updateArtifactPublishingStatus(runId, artifact.name, {\n       published: true,\n       published_at: new Date().toISOString(),\n       publish_status: 'success'\n     });\n   }\n   ```\n\n3. **Auto-on-Complete** (`publish_policy: auto-on-complete`):\n   ```yaml\n   # In workflow YAML or skill frontmatter\n   publish_policy: auto-on-complete\n   ```\n   - Artifacts are automatically published when workflow completes\n   - Use: When you want to publish all artifacts at workflow end\n   - Example: At workflow completion, all artifacts with `publishable: true` are published\n   - Implementation:\n   ```javascript\n   // At workflow completion\n   if (workflowStatus === 'completed' && publishPolicy === 'auto-on-complete') {\n     const registry = await readArtifactRegistry(runId);\n     for (const [name, artifact] of Object.entries(registry.artifacts)) {\n       if (artifact.publishable && !artifact.published) {\n         await publishArtifact(artifact);\n         await updateArtifactPublishingStatus(runId, name, {\n           published: true,\n           published_at: new Date().toISOString(),\n           publish_status: 'success'\n         });\n       }\n     }\n   }\n   ```\n\n**Configuring Publish Targets Per Artifact**:\n```javascript\n// When registering artifact\nawait registerArtifact(runId, {\n  name: 'plan-123.json',\n  step: 0,\n  agent: 'planner',\n  publishable: true,\n  publish_targets: ['project_feed', 'cursor'], // Multiple targets\n  // ... other fields\n});\n```\n\n**Handling Publishing Failures in Workflows**:\n- If publishing fails, workflow continues (non-blocking)\n- Publishing errors are logged in registry: `publish_error`\n- Failed artifacts can be retried manually or in next workflow run\n- Gate files include publishing status for visibility\n</workflow_integration>\n</instructions>\n\n<platform_invocation>\n**Claude (this platform)**:\n- Use `create_artifact` and `share_artifact` tools directly\n- Invoke: \"Use artifact-publisher skill to publish this artifact\"\n\n**Cursor**:\n- Use `@artifact-publisher` mention\n- Invoke: \"Use @artifact-publisher to publish this plan\"\n\n**Factory**:\n- Use Task tool with skill\n- Invoke: \"Run Task tool with skill artifact-publisher to publish this spec\"\n\n**OpenCode**:\n- Use file system operations\n- Invoke: \"Publish artifact to .opencode/context/artifacts/published/\"\n\n**Cross-Platform Metadata**:\nAll platforms should use consistent metadata structure:\n```json\n{\n  \"id\": \"artifact-{timestamp}-{sequence}\",\n  \"type\": \"plan|architecture|specification|implementation|test-results\",\n  \"title\": \"Artifact Title\",\n  \"created\": \"ISO 8601 timestamp\",\n  \"workflow_id\": \"workflow-id\",\n  \"step_number\": 0,\n  \"agent\": \"agent-name\",\n  \"dependencies\": [\"artifact1.json\", \"artifact2.json\"],\n  \"validation_status\": \"pass|fail|pending\",\n  \"tags\": [\"tag1\", \"tag2\"],\n  \"publish_targets\": [\"project_feed\", \"cursor\"],\n  \"published\": true,\n  \"published_at\": \"ISO 8601 timestamp\"\n}\n```\n</platform_invocation>\n\n<examples>\n<usage_example>\n**Publishing a Design Doc (Claude)**:\n\n```\ncreate_artifact --title \"System Architecture\" --type \"markdown\" --content \"...\"\nshare_artifact --id <artifact_id> --target \"project_feed\"\n```\n</usage_example>\n\n<usage_example>\n**Publishing a Plan (Cursor)**:\n```\nUse @artifact-publisher to publish this plan\n```\n</usage_example>\n\n<usage_example>\n**Publishing a Spec (Factory)**:\n```\nRun Task tool with skill artifact-publisher to publish this spec\n```\n</usage_example>\n</examples>\n",
          "tokens": 2900
        }
      }
    },
    "context-bridge": {
      "name": "context-bridge",
      "one_liner": "Synchronize task state and metadata across Claude, Cursor, and Factory Droid sessions. Use when handing off tasks between platforms, sharing plans, or updating external trackers like Linear or Jira.",
      "key_commands": ["/identity", "/capabilities", "/context", "/state", "/runs"],
      "token_count": {
        "minimal": 55,
        "essential": 109,
        "standard": 560,
        "full": 652
      },
      "levels": {
        "minimal": {
          "content": "**context-bridge**: Synchronize task state and metadata across Claude, Cursor, and Factory Droid sessions. Use when handing off tasks between platforms, sharing plans, or updating external trackers like Linear or Jira.",
          "tokens": 55
        },
        "essential": {
          "content": "## Skill: context-bridge\n\nSynchronize task state and metadata across Claude, Cursor, and Factory Droid sessions. Use when handing off tasks between platforms, sharing plans, or updating external trackers like Linear or Jira.\n\nContext Bridge - Synchronizes task state and metadata across Claude, Cursor, and Factory Droid sessions. Ensures \"memory\" is preserved when switching between different AI agents or platforms.\n\n### Key Steps:\n",
          "tokens": 109
        },
        "standard": {
          "content": "## Skill: context-bridge\n\nSynchronize task state and metadata across Claude, Cursor, and Factory Droid sessions. Use when handing off tasks between platforms, sharing plans, or updating external trackers like Linear or Jira.\n\nContext Bridge - Synchronizes task state and metadata across Claude, Cursor, and Factory Droid sessions. Ensures \"memory\" is preserved when switching between different AI agents or platforms.\n\n### Instructions:\n<execution_process>\n1. **Identify Handoff**: When a user indicates they are switching platforms (e.g., \"I'll finish this in Cursor\"), invoke this skill.\n2. **Persist State**: Save the current plan, active artifacts, and next steps to `.claude/context/state.json`.\n3. **Sync Publishing Metadata**: \n   - Read artifact registry from source platform (e.g., `.claude/context/runs/<run_id>/artifact-registry.json`)\n   - Extract publishing metadata (published, published_at, publish_status, publish_targets, publish_attempts)\n   - Validate metadata against `.claude/schemas/artifact-metadata.schema.json`\n   - Sync to target platform (e.g., `.cursor/plans/artifacts/` or `.factory/context/artifacts/`)\n   - Handle conflicts: prefer most recent `published_at` timestamp\n   - Update `last_synced` timestamp in metadata\n4. **Update Trackers**: If a ticket ID is present, update the external status (Linear/GitHub).\n5. **Notify**: Send a summary to the appropriate channel if requested.\n</execution_process>\n\n<integrations>\n- **Linear**: Read/Write issues.\n- **GitHub**: Read repo context, update PRs/Issues.\n- **Slack**: Send notifications to team channels.\n</integrations>\n\n<best_practices>\n- **Always** update the central state file before sending notifications.\n- **Never** overwrite existing state without reading it first to preserve history.\n- **Publishing Metadata Sync**: When syncing artifacts across platforms:\n  - Validate metadata against `.claude/schemas/artifact-metadata.schema.json` before syncing\n  - Handle publishing status conflicts by preferring most recent `published_at` timestamp\n  - Preserve `publish_attempts` history for retry tracking\n  - Update `last_synced` timestamp to track sync freshness\n  - If metadata conflicts, log conflict resolution in reasoning file\n</best_practices>\n",
          "tokens": 560
        },
        "full": {
          "content": "---\nname: context-bridge\ndescription: Synchronize task state and metadata across Claude, Cursor, and Factory Droid sessions. Use when handing off tasks between platforms, sharing plans, or updating external trackers like Linear or Jira.\nallowed-tools: linear_read, linear_write, github_read, github_write, slack_write\n---\n\n<identity>\nContext Bridge - Synchronizes task state and metadata across Claude, Cursor, and Factory Droid sessions. Ensures \"memory\" is preserved when switching between different AI agents or platforms.\n</identity>\n\n<capabilities>\n- Synchronizing task state and metadata across platforms\n- Handing off tasks between platforms\n- Sharing plans and updating external trackers (Linear, Jira)\n- Preserving context when switching AI agents\n</capabilities>\n\n<instructions>\n<execution_process>\n1. **Identify Handoff**: When a user indicates they are switching platforms (e.g., \"I'll finish this in Cursor\"), invoke this skill.\n2. **Persist State**: Save the current plan, active artifacts, and next steps to `.claude/context/state.json`.\n3. **Sync Publishing Metadata**: \n   - Read artifact registry from source platform (e.g., `.claude/context/runs/<run_id>/artifact-registry.json`)\n   - Extract publishing metadata (published, published_at, publish_status, publish_targets, publish_attempts)\n   - Validate metadata against `.claude/schemas/artifact-metadata.schema.json`\n   - Sync to target platform (e.g., `.cursor/plans/artifacts/` or `.factory/context/artifacts/`)\n   - Handle conflicts: prefer most recent `published_at` timestamp\n   - Update `last_synced` timestamp in metadata\n4. **Update Trackers**: If a ticket ID is present, update the external status (Linear/GitHub).\n5. **Notify**: Send a summary to the appropriate channel if requested.\n</execution_process>\n\n<integrations>\n- **Linear**: Read/Write issues.\n- **GitHub**: Read repo context, update PRs/Issues.\n- **Slack**: Send notifications to team channels.\n</integrations>\n\n<best_practices>\n- **Always** update the central state file before sending notifications.\n- **Never** overwrite existing state without reading it first to preserve history.\n- **Publishing Metadata Sync**: When syncing artifacts across platforms:\n  - Validate metadata against `.claude/schemas/artifact-metadata.schema.json` before syncing\n  - Handle publishing status conflicts by preferring most recent `published_at` timestamp\n  - Preserve `publish_attempts` history for retry tracking\n  - Update `last_synced` timestamp to track sync freshness\n  - If metadata conflicts, log conflict resolution in reasoning file\n</best_practices>\n</instructions>\n",
          "tokens": 652
        }
      }
    },
    "conflict-resolution": {
      "name": "conflict-resolution",
      "one_liner": "No description",
      "key_commands": ["/sec", "/agents", "/planner", "/orchestrator", "/docs"],
      "token_count": {
        "minimal": 13,
        "essential": 8,
        "standard": 8,
        "full": 3425
      },
      "levels": {
        "minimal": {
          "content": "**conflict-resolution**: No description available",
          "tokens": 13
        },
        "essential": {
          "content": "## Skill: conflict-resolution\n",
          "tokens": 8
        },
        "standard": {
          "content": "## Skill: conflict-resolution\n",
          "tokens": 8
        },
        "full": {
          "content": "---\r\nname: conflict-resolution\r\ndescription: Multi-agent conflict resolution protocol for detecting and resolving conflicts when multiple agents produce conflicting outputs or requirements. Handles technical, requirements, design, and data conflicts.\r\nallowed-tools: read, grep, search\r\n---\r\n\r\n# Conflict Resolution Skill\r\n\r\nMulti-agent conflict resolution protocol for detecting and resolving conflicts when multiple agents produce conflicting outputs or requirements.\r\n\r\n## When to Use\r\n\r\n**Trigger Conditions**:\r\n- Multiple agents provide conflicting recommendations on the same component\r\n- Requirements from different agents are incompatible (e.g., PM wants feature X, Security says block it)\r\n- Technical decisions conflict between agents (e.g., Architect chooses REST, Developer implements GraphQL)\r\n- Design choices conflict between agents (e.g., UX wants modal, Architect wants separate page)\r\n- Data requirements conflict between agents (e.g., PM wants user emails, DBA says normalize to user_id FK)\r\n- Workflow execution blocked due to contradictory agent outputs\r\n\r\n**When NOT to Use**:\r\n- Agents provide different but compatible approaches (that's healthy diversity)\r\n- Minor style preferences (use code-style-validator instead)\r\n- Performance trade-offs without clear winner (use performance-engineer for analysis)\r\n\r\n**Real-World Triggers**:\r\n1. Planner detects contradictory requirements in workflow step outputs\r\n2. Developer receives conflicting specifications from Architect and UX Expert\r\n3. Two agents update the same artifact with incompatible changes\r\n4. Validation gate fails due to conflicting schema requirements\r\n5. Orchestrator receives conflicting routing decisions from multiple agents\r\n\r\n## Instructions\r\n\r\n### Step 1: Conflict Detection\r\n\r\n1. **Compare agent outputs**:\r\n   - Identify which agents provided input\r\n   - Extract key decisions from each agent\r\n   - Compare outputs for contradictions\r\n\r\n2. **Detect conflict types**:\r\n   - **Technical Conflicts**: Architect vs Developer on implementation approach\r\n   - **Requirements Conflicts**: PM vs Analyst on feature priorities\r\n   - **Design Conflicts**: UX Expert vs Architect on interface design\r\n   - **Data Conflicts**: Database Architect vs Analyst on data requirements\r\n\r\n3. **Assess conflict severity**:\r\n   - **Critical**: Blocks workflow execution, requires immediate resolution\r\n   - **High**: Significant impact, should be resolved before proceeding\r\n   - **Medium**: Moderate impact, can be resolved during execution\r\n   - **Low**: Minor inconsistency, can be noted and resolved later\r\n\r\n### Step 2: Conflict Resolution Process\r\n\r\n1. **Set timeout**:\r\n   - Use `config.workflow_thresholds.conflict_resolution_timeout_seconds` (default: 30 seconds)\r\n   - Start timer for resolution attempts\r\n\r\n2. **Document conflict**:\r\n   - Record conflict details in reasoning file\r\n   - Document which agents are in conflict\r\n   - Record conflict type and severity\r\n   - Log impact on workflow\r\n\r\n3. **Escalate to appropriate resolution agent** (within timeout):\r\n   - **Technical Conflicts**: Escalate to Architect (has final authority on technical decisions)\r\n   - **Requirements Conflicts**: Escalate to PM (has final authority on product decisions)\r\n   - **Design Conflicts**: Escalate to UX Expert (has final authority on design decisions)\r\n   - **Data Conflicts**: Escalate to Database Architect (has final authority on data decisions)\r\n   - **Multi-Domain Conflicts**: Escalate to AI Council for consensus building\r\n\r\n4. **Timeout handling**:\r\n   - If timeout exceeded: Log timeout in reasoning file\r\n   - Escalate to AI Council for final resolution\r\n   - Document timeout and escalation in plan\r\n\r\n5. **Document resolution**:\r\n   - Record resolution decision in reasoning file\r\n   - Update plan to reflect resolution\r\n   - Communicate resolution to affected agents\r\n\r\n### Step 3: Resolution Methods\r\n\r\n1. **Authority-based resolution**:\r\n   - Escalate to agent with final authority for conflict type\r\n   - Accept authoritative decision\r\n   - Update plan accordingly\r\n\r\n2. **Consensus building**:\r\n   - Facilitate discussion between conflicting agents\r\n   - Find common ground\r\n   - Build consensus solution\r\n\r\n3. **AI Council resolution**:\r\n   - Escalate complex multi-domain conflicts\r\n   - Use extended thinking for analysis\r\n   - Generate comprehensive resolution\r\n\r\n## Conflict Resolution Matrix\r\n\r\n| Conflict Type | Resolution Agent | Timeout | Escalation |\r\n|--------------|------------------|---------|------------|\r\n| Technical | Architect | 30s | AI Council |\r\n| Requirements | PM | 30s | AI Council |\r\n| Design | UX Expert | 30s | AI Council |\r\n| Data | Database Architect | 30s | AI Council |\r\n| Multi-Domain | AI Council | 60s | Human Review |\r\n\r\n## Usage Patterns\r\n\r\n### Detect and Resolve Conflicts\r\n\r\n**When to Use**:\r\n- Workflow step outputs contradict each other\r\n- Multiple agents provide incompatible recommendations\r\n- Agent outputs fail validation due to conflicts\r\n\r\n**How to Invoke**:\r\n```\r\n\"Detect conflicts between architect and developer outputs\"\r\n\"Resolve conflict in authentication implementation\"\r\n\"Check for conflicts in workflow artifacts\"\r\n```\r\n\r\n**What It Does**:\r\n- Loads agent outputs from workflow artifacts\r\n- Compares outputs for contradictions\r\n- Detects conflict type and severity\r\n- Escalates to appropriate resolution agent\r\n- Documents resolution in reasoning file\r\n\r\n## Examples\r\n\r\n### Example 1: Technical Conflict (Architect vs Developer)\r\n\r\n**Scenario**: Architect specifies REST API, Developer implements GraphQL\r\n\r\n**Conflict Detection**:\r\n```json\r\n{\r\n  \"conflict_type\": \"technical\",\r\n  \"severity\": \"high\",\r\n  \"agents_in_conflict\": [\"architect\", \"developer\"],\r\n  \"conflict_details\": {\r\n    \"architect_output\": {\r\n      \"artifact\": \"architecture-workflow-123.json\",\r\n      \"decision\": \"Use REST API with JSON responses\",\r\n      \"rationale\": \"Team familiarity, industry standard, simple caching\"\r\n    },\r\n    \"developer_output\": {\r\n      \"artifact\": \"dev-manifest-workflow-123.json\",\r\n      \"implementation\": \"GraphQL API with Apollo Server\",\r\n      \"rationale\": \"Better developer experience, type safety, efficient queries\"\r\n    },\r\n    \"impact\": \"Workflow blocked - cannot proceed without resolution\"\r\n  }\r\n}\r\n```\r\n\r\n**Resolution Process**:\r\n1. **Timeout Start**: 30 seconds for resolution\r\n2. **Escalation**: Escalate to Architect (has final authority on technical decisions)\r\n3. **Architect Decision**: \"Use REST for v1, evaluate GraphQL for v2 after metrics\"\r\n4. **Resolution Documented**:\r\n   ```json\r\n   {\r\n     \"resolution\": \"Use REST API as specified in architecture\",\r\n     \"resolution_agent\": \"architect\",\r\n     \"resolution_time\": \"15s\",\r\n     \"updated_plan\": {\r\n       \"developer_task\": \"Implement REST API with Express.js\",\r\n       \"future_consideration\": \"Evaluate GraphQL for v2 based on v1 metrics\"\r\n     }\r\n   }\r\n   ```\r\n\r\n**Before State**:\r\n- Architect: REST API specified\r\n- Developer: GraphQL implemented\r\n- Status: Conflicting implementations\r\n\r\n**After State**:\r\n- Architect: REST API confirmed (authority decision)\r\n- Developer: REST API implementation started\r\n- Status: Conflict resolved, workflow proceeding\r\n\r\n### Example 2: Requirements Conflict (PM vs Security)\r\n\r\n**Scenario**: PM wants public user profiles, Security Architect flags privacy risk\r\n\r\n**Conflict Detection**:\r\n```json\r\n{\r\n  \"conflict_type\": \"requirements\",\r\n  \"severity\": \"critical\",\r\n  \"agents_in_conflict\": [\"pm\", \"security-architect\"],\r\n  \"conflict_details\": {\r\n    \"pm_output\": {\r\n      \"artifact\": \"prd-workflow-456.json\",\r\n      \"requirement\": \"Public user profiles with full name, email, location visible to all users\",\r\n      \"business_value\": \"Networking feature, user discovery, community building\"\r\n    },\r\n    \"security_output\": {\r\n      \"artifact\": \"security-review-workflow-456.json\",\r\n      \"violation\": \"PII exposure risk - email addresses publicly visible\",\r\n      \"severity\": \"critical\",\r\n      \"recommendation\": \"Block feature or implement privacy controls\"\r\n    },\r\n    \"impact\": \"Feature cannot ship without addressing security concerns\"\r\n  }\r\n}\r\n```\r\n\r\n**Resolution Process**:\r\n1. **Timeout Start**: 30 seconds for resolution\r\n2. **Escalation**: Escalate to PM (has final authority on requirements)\r\n3. **PM Decision**: \"Implement privacy controls - make email optional, add visibility toggles\"\r\n4. **Resolution Documented**:\r\n   ```json\r\n   {\r\n     \"resolution\": \"Add privacy controls to meet both requirements\",\r\n     \"resolution_agent\": \"pm\",\r\n     \"resolution_time\": \"22s\",\r\n     \"updated_requirements\": {\r\n       \"public_profile_fields\": [\"username\", \"bio\", \"profile_image\"],\r\n       \"optional_fields\": [\"full_name\", \"location\"],\r\n       \"private_by_default\": [\"email\"],\r\n       \"user_controls\": [\"visibility_toggle_per_field\", \"profile_privacy_level\"]\r\n     }\r\n   }\r\n   ```\r\n\r\n**Before State**:\r\n- PM: Public profiles with all fields visible\r\n- Security: Block feature due to PII exposure\r\n- Status: Critical conflict blocking feature\r\n\r\n**After State**:\r\n- PM: Updated requirements with privacy controls\r\n- Security: Approved with privacy controls\r\n- Status: Conflict resolved, feature can proceed\r\n\r\n### Example 3: Design Conflict (UX vs Architect)\r\n\r\n**Scenario**: UX wants modal for file upload, Architect wants dedicated page for scalability\r\n\r\n**Conflict Detection**:\r\n```json\r\n{\r\n  \"conflict_type\": \"design\",\r\n  \"severity\": \"medium\",\r\n  \"agents_in_conflict\": [\"ux-expert\", \"architect\"],\r\n  \"conflict_details\": {\r\n    \"ux_output\": {\r\n      \"artifact\": \"ui-spec-workflow-789.json\",\r\n      \"design\": \"Modal dialog for file upload - keeps user in context\",\r\n      \"user_flow\": \"Click upload → modal opens → select file → upload → modal closes\"\r\n    },\r\n    \"architect_output\": {\r\n      \"artifact\": \"architecture-workflow-789.json\",\r\n      \"concern\": \"Modal limits functionality - need dedicated page for batch uploads, progress tracking, file management\",\r\n      \"recommendation\": \"Use dedicated upload page with full functionality\"\r\n    },\r\n    \"impact\": \"Cannot finalize UI spec without resolving approach\"\r\n  }\r\n}\r\n```\r\n\r\n**Resolution Process**:\r\n1. **Timeout Start**: 30 seconds for resolution\r\n2. **Escalation**: Escalate to UX Expert (has final authority on design)\r\n3. **UX Decision**: \"Use modal for single file, dedicated page for batch - best of both\"\r\n4. **Resolution Documented**:\r\n   ```json\r\n   {\r\n     \"resolution\": \"Hybrid approach - modal for simple upload, page for advanced\",\r\n     \"resolution_agent\": \"ux-expert\",\r\n     \"resolution_time\": \"18s\",\r\n     \"updated_design\": {\r\n       \"simple_upload\": {\r\n         \"component\": \"UploadModal\",\r\n         \"trigger\": \"Quick upload button\",\r\n         \"use_case\": \"Single file upload in-context\"\r\n       },\r\n       \"advanced_upload\": {\r\n         \"component\": \"UploadPage\",\r\n         \"trigger\": \"Upload center link\",\r\n         \"use_case\": \"Batch uploads, file management, progress tracking\"\r\n       }\r\n     }\r\n   }\r\n   ```\r\n\r\n**Before State**:\r\n- UX: Modal for all uploads\r\n- Architect: Dedicated page for all uploads\r\n- Status: Design conflict blocking implementation\r\n\r\n**After State**:\r\n- UX: Hybrid approach approved\r\n- Architect: Scalability concerns addressed\r\n- Status: Conflict resolved, implementation can proceed\r\n\r\n### Example 4: Multi-Domain Conflict (Timeout → AI Council)\r\n\r\n**Scenario**: Complex conflict involving Architect, Security, and Performance Engineer\r\n\r\n**Conflict Detection**:\r\n```json\r\n{\r\n  \"conflict_type\": \"multi-domain\",\r\n  \"severity\": \"high\",\r\n  \"agents_in_conflict\": [\"architect\", \"security-architect\", \"performance-engineer\"],\r\n  \"conflict_details\": {\r\n    \"architect\": \"Use microservices for scalability\",\r\n    \"security\": \"Monolith easier to secure, fewer network boundaries\",\r\n    \"performance\": \"Microservices add latency, monolith faster for current scale\"\r\n  },\r\n  \"timeout_exceeded\": true,\r\n  \"escalation\": \"AI Council\"\r\n}\r\n```\r\n\r\n**AI Council Resolution**:\r\n```json\r\n{\r\n  \"resolution\": \"Start with modular monolith, extract services as needed\",\r\n  \"consensus_approach\": \"Incremental migration based on metrics\",\r\n  \"phase_1\": {\r\n    \"architecture\": \"Modular monolith with clear service boundaries\",\r\n    \"security\": \"Simplified security perimeter, easier to audit\",\r\n    \"performance\": \"Optimal for current scale\"\r\n  },\r\n  \"phase_2_triggers\": {\r\n    \"extract_to_microservice_if\": [\r\n      \"Service load > 10k req/sec\",\r\n      \"Team size > 8 developers\",\r\n      \"Independent scaling needed\"\r\n    ]\r\n  },\r\n  \"all_agents_approve\": true\r\n}\r\n```\r\n\r\n## Invocation Commands\r\n\r\n**Natural Language**:\r\n```\r\n\"Detect conflicts in workflow artifacts\"\r\n\"Resolve conflict between architect and developer\"\r\n\"Check for requirements conflicts in PRD\"\r\n\"Escalate authentication design conflict to architect\"\r\n```\r\n\r\n**Skill Tool**:\r\n```\r\nSkill: conflict-resolution\r\nParameters: {\r\n  \"workflow_id\": \"workflow-123\",\r\n  \"artifacts\": [\"architecture.json\", \"dev-manifest.json\"],\r\n  \"conflict_type\": \"technical\"\r\n}\r\n```\r\n\r\n**Via Orchestrator**:\r\n```\r\nWhen orchestrator detects conflicting outputs:\r\n1. Pause workflow execution\r\n2. Invoke conflict-resolution skill\r\n3. Wait for resolution\r\n4. Update workflow plan with resolution\r\n5. Resume workflow execution\r\n```\r\n\r\n## Related Skills\r\n\r\n- **evaluator**: Evaluates agent performance to prevent conflicts\r\n- **plan-generator**: Creates conflict-free plans\r\n- **rule-auditor**: Validates compliance to prevent conflicts\r\n\r\n## Related Documentation\r\n\r\n- [Planner Agent](../../agents/planner.md) - Specialist Coordination with Timeout\r\n- [Orchestrator Agent](../../agents/orchestrator.md) - Conflict Detection and Resolution Protocol\r\n- [CUJ-047](../../docs/cujs/CUJ-047.md) - Multi-Agent Conflict Resolution\r\n\r\n",
          "tokens": 3425
        }
      }
    },
    "optional-artifact-handler": {
      "name": "optional-artifact-handler",
      "one_liner": "No description",
      "key_commands": [
        "/context",
        "/artifacts",
        "/registry-",
        "/infrastructure-config-workflow-123",
        "/registry-workflow-123"
      ],
      "token_count": {
        "minimal": 14,
        "essential": 9,
        "standard": 9,
        "full": 4049
      },
      "levels": {
        "minimal": {
          "content": "**optional-artifact-handler**: No description available",
          "tokens": 14
        },
        "essential": {
          "content": "## Skill: optional-artifact-handler\n",
          "tokens": 9
        },
        "standard": {
          "content": "## Skill: optional-artifact-handler\n",
          "tokens": 9
        },
        "full": {
          "content": "---\r\nname: optional-artifact-handler\r\ndescription: Handles optional artifact inputs in workflows. Manages workflows that can proceed with or without optional artifacts, provides defaults when artifacts are missing, and documents optional artifact handling.\r\nallowed-tools: read, grep, glob\r\n---\r\n\r\n# Optional Artifact Handler Skill\r\n\r\nHandles optional artifact inputs in workflows, allowing workflows to proceed with or without optional artifacts.\r\n\r\n## When to Use\r\n\r\nUse this skill when:\r\n- **Executing workflow steps** with inputs marked as `(optional)` in YAML\r\n- **Building adaptive workflows** that gracefully degrade without certain inputs\r\n- **Implementing fallback logic** for missing documentation artifacts\r\n- **Documenting decision rationale** about optional artifact handling\r\n- **Recovering from incomplete previous steps** without blocking progress\r\n\r\n**Trigger Phrases**:\r\n- \"Check for optional artifact X\"\r\n- \"Handle missing optional input\"\r\n- \"Provide defaults for optional artifact\"\r\n- \"Process step with optional artifacts\"\r\n\r\n## Invocation Examples\r\n\r\n### Natural Language (Recommended)\r\n```\r\n\"Check if infrastructure-config.json is available as an optional input\"\r\n\"Handle the optional UX spec artifact for code review\"\r\n\"Provide defaults for missing test-plan from Step 5\"\r\n```\r\n\r\n### Skill Tool (Programmatic)\r\n```javascript\r\n// In agent workflow execution\r\nSkill: optional-artifact-handler\r\n\r\n// With specific context\r\nawait skillManager.invoke('optional-artifact-handler', {\r\n  artifactName: 'infrastructure-config.json',\r\n  workflowId: 'workflow-123',\r\n  step: 7\r\n});\r\n```\r\n\r\n## Instructions\r\n\r\n### Step 1: Detect Optional Artifacts\r\n\r\n1. **Check workflow step definition**:\r\n   - Review step inputs in workflow YAML\r\n   - Identify which inputs are marked as optional\r\n   - Check artifact registry for availability\r\n\r\n2. **Check artifact registry**:\r\n   - Location: `.claude/context/artifacts/registry-{workflow_id}.json`\r\n   - Check if optional artifact exists\r\n   - Verify artifact validation status if present\r\n\r\n**Example Registry Check**:\r\n```json\r\n{\r\n  \"artifacts\": [\r\n    {\r\n      \"name\": \"infrastructure-config.json\",\r\n      \"path\": \".claude/context/artifacts/infrastructure-config-workflow-123.json\",\r\n      \"step\": 4.5,\r\n      \"agent\": \"devops\",\r\n      \"validated\": true,\r\n      \"created_at\": \"2025-01-03T10:30:00Z\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n### Step 2: Handle Missing Optional Artifacts\r\n\r\n1. **If artifact missing**:\r\n   - Log in reasoning file: \"Optional artifact {name} not found, using default\"\r\n   - Use default value or behavior\r\n   - Continue workflow execution\r\n\r\n2. **If artifact present**:\r\n   - Load artifact from registry\r\n   - Verify validation status\r\n   - Use artifact value\r\n\r\n**Example Handling Logic**:\r\n```javascript\r\n// Check registry\r\nconst registry = await readFile('.claude/context/artifacts/registry-workflow-123.json');\r\nconst artifact = registry.artifacts.find(a => a.name === 'infrastructure-config.json');\r\n\r\nif (!artifact) {\r\n  // Missing optional artifact - use defaults\r\n  console.log('[optional-artifact-handler] infrastructure-config.json not found, using empty config');\r\n  const config = { resources: [], environment_variables: {} };\r\n\r\n  // Log decision\r\n  await appendToReasoningFile({\r\n    optional_artifact_handling: {\r\n      artifact: 'infrastructure-config.json',\r\n      status: 'missing',\r\n      default_used: 'empty config object',\r\n      impact: 'Cloud service integration stubs will use placeholder values'\r\n    }\r\n  });\r\n\r\n  return config;\r\n} else {\r\n  // Artifact available - load it\r\n  console.log('[optional-artifact-handler] infrastructure-config.json found, loading from registry');\r\n  const config = await readFile(artifact.path);\r\n\r\n  // Log decision\r\n  await appendToReasoningFile({\r\n    optional_artifact_handling: {\r\n      artifact: 'infrastructure-config.json',\r\n      status: 'available',\r\n      source: artifact.path,\r\n      impact: 'Cloud service integration will use actual resource names'\r\n    }\r\n  });\r\n\r\n  return config;\r\n}\r\n```\r\n\r\n### Step 3: Provide Defaults\r\n\r\n1. **Default values**:\r\n   - Use sensible defaults based on workflow context\r\n   - Document default choice in reasoning file\r\n   - Ensure defaults don't break workflow\r\n\r\n2. **Default behaviors**:\r\n   - Skip optional step if artifact missing\r\n   - Use fallback logic when artifact unavailable\r\n   - Continue with reduced functionality\r\n\r\n**Example Default Strategies**:\r\n\r\n| Optional Artifact | Default Value | Rationale |\r\n|-------------------|---------------|-----------|\r\n| `infrastructure-config.json` | `{ resources: [], environment_variables: {} }` | Empty config allows code generation to proceed with stubs |\r\n| `ui-spec.json` | `null` | Code reviewer skips UI compliance checks |\r\n| `test-plan.json` | `{ test_cases: [] }` | Developer proceeds without test guidance |\r\n| `prd.json` | `null` | Architect designs without product requirements (technical debt) |\r\n\r\n### Step 4: Document Handling\r\n\r\n1. **Log in reasoning file**:\r\n   - Document which optional artifacts were used\r\n   - Document which defaults were applied\r\n   - Record decision rationale\r\n\r\n2. **Update plan**:\r\n   - Note optional artifact handling in plan\r\n   - Document impact on workflow execution\r\n   - Track optional artifact usage\r\n\r\n**Example Reasoning File Output**:\r\n```json\r\n{\r\n  \"step\": 7,\r\n  \"agent\": \"developer\",\r\n  \"optional_artifact_handling\": {\r\n    \"timestamp\": \"2025-01-03T10:45:00Z\",\r\n    \"artifacts_checked\": [\r\n      {\r\n        \"name\": \"infrastructure-config.json\",\r\n        \"required\": false,\r\n        \"found\": false,\r\n        \"default_applied\": \"empty config object\",\r\n        \"impact\": \"Cloud integration stubs will use placeholder resource names\"\r\n      },\r\n      {\r\n        \"name\": \"ui-spec.json\",\r\n        \"required\": false,\r\n        \"found\": true,\r\n        \"source\": \".claude/context/artifacts/ui-spec-workflow-123.json\",\r\n        \"impact\": \"UI components will follow specified design system\"\r\n      }\r\n    ],\r\n    \"workflow_impact\": \"Proceeded with partial context - cloud integration requires manual configuration\",\r\n    \"recommendations\": [\r\n      \"Run DevOps step (4.5) to generate infrastructure-config.json\",\r\n      \"Update cloud service stubs with actual resource names after infrastructure provisioning\"\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\n## Complete Workflow Example\r\n\r\n### Scenario: Developer Step with Optional Infrastructure Config\r\n\r\n**Workflow YAML** (Step 7):\r\n```yaml\r\n- step: 7\r\n  agent: developer\r\n  prompt: Implement API endpoints and cloud integration\r\n  inputs:\r\n    - plan.json (from step 3)\r\n    - architecture.json (from step 4)\r\n    - infrastructure-config.json (from step 4.5, optional)\r\n  outputs:\r\n    - dev-manifest.json\r\n  validation:\r\n    schema: .claude/schemas/dev_manifest.schema.json\r\n```\r\n\r\n**Step 1: Check Registry**\r\n```bash\r\n# Agent reads artifact registry\r\ncat .claude/context/artifacts/registry-workflow-123.json\r\n\r\n# Output:\r\n# {\r\n#   \"artifacts\": [\r\n#     {\r\n#       \"name\": \"plan.json\",\r\n#       \"path\": \".claude/context/artifacts/plan-workflow-123.json\",\r\n#       \"step\": 3,\r\n#       \"validated\": true\r\n#     },\r\n#     {\r\n#       \"name\": \"architecture.json\",\r\n#       \"path\": \".claude/context/artifacts/architecture-workflow-123.json\",\r\n#       \"step\": 4,\r\n#       \"validated\": true\r\n#     }\r\n#     // Note: infrastructure-config.json is MISSING\r\n#   ]\r\n# }\r\n```\r\n\r\n**Step 2: Detect Missing Optional Artifact**\r\n```javascript\r\n// Developer agent logic\r\nconst requiredArtifacts = ['plan.json', 'architecture.json'];\r\nconst optionalArtifacts = ['infrastructure-config.json'];\r\n\r\n// Check required artifacts (must exist)\r\nfor (const artifact of requiredArtifacts) {\r\n  const found = registry.artifacts.find(a => a.name === artifact);\r\n  if (!found) {\r\n    throw new Error(`Required artifact ${artifact} not found`);\r\n  }\r\n}\r\n\r\n// Check optional artifacts (graceful degradation)\r\nconst infraConfig = registry.artifacts.find(a => a.name === 'infrastructure-config.json');\r\nif (!infraConfig) {\r\n  console.log('[optional-artifact-handler] infrastructure-config.json missing - using defaults');\r\n}\r\n```\r\n\r\n**Step 3: Apply Defaults**\r\n```javascript\r\n// Use default empty infrastructure config\r\nconst infrastructureConfig = infraConfig\r\n  ? await readFile(infraConfig.path)\r\n  : {\r\n      cloud_provider: 'gcp',\r\n      resources: [],\r\n      environment_variables: {},\r\n      service_accounts: []\r\n    };\r\n\r\n// Generate code with placeholders\r\nconst storageClient = `\r\n// TODO: Update with actual bucket name from infrastructure-config.json\r\nconst bucketName = process.env.STORAGE_BUCKET || 'placeholder-bucket';\r\nconst storage = new Storage({ projectId: process.env.GCP_PROJECT_ID });\r\n`;\r\n```\r\n\r\n**Step 4: Document in Reasoning File**\r\n```json\r\n{\r\n  \"step\": 7,\r\n  \"agent\": \"developer\",\r\n  \"optional_artifact_handling\": {\r\n    \"timestamp\": \"2025-01-03T10:45:00Z\",\r\n    \"missing_optional_artifacts\": [\"infrastructure-config.json\"],\r\n    \"defaults_applied\": {\r\n      \"infrastructure-config.json\": {\r\n        \"default_value\": \"empty config with placeholder resource names\",\r\n        \"rationale\": \"DevOps step (4.5) was skipped - proceeding with stubs\",\r\n        \"workaround\": \"Using environment variables and placeholder names\",\r\n        \"follow_up_required\": true,\r\n        \"follow_up_action\": \"Run DevOps step to generate actual infrastructure config\"\r\n      }\r\n    },\r\n    \"code_generation_impact\": [\r\n      \"Cloud storage client uses placeholder bucket name\",\r\n      \"Database connection uses placeholder credentials\",\r\n      \"Message queue client uses default topic names\"\r\n    ],\r\n    \"runtime_requirements\": [\r\n      \"Set STORAGE_BUCKET environment variable before deployment\",\r\n      \"Set DATABASE_URL environment variable before deployment\",\r\n      \"Configure GCP_PROJECT_ID environment variable\"\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\n**Step 5: Continue Execution**\r\n```javascript\r\n// Developer continues with implementation\r\nconst manifest = {\r\n  files_created: [\r\n    'src/services/storage.ts',  // Uses placeholder bucket name\r\n    'src/services/database.ts', // Uses placeholder connection string\r\n    'src/api/upload.ts'         // API endpoint implementation\r\n  ],\r\n  files_modified: [],\r\n  dependencies_added: ['@google-cloud/storage', 'pg'],\r\n  tests_created: ['tests/api/upload.test.ts'],\r\n  notes: [\r\n    'infrastructure-config.json was not available',\r\n    'Cloud service clients use placeholder resource names',\r\n    'Run DevOps step (4.5) and update service configurations'\r\n  ]\r\n};\r\n\r\n// Save manifest\r\nawait writeFile('.claude/context/artifacts/dev-manifest-workflow-123.json', manifest);\r\n```\r\n\r\n## Optional Artifact Patterns\r\n\r\n### Pattern 1: Optional Documentation\r\n\r\n**Use Case**: Code review can proceed without PRD or UX spec\r\n\r\n```yaml\r\n- step: 8\r\n  agent: code-reviewer\r\n  inputs:\r\n    - dev-manifest.json (from step 7)\r\n    - prd.json (from step 2, optional)\r\n    - ui-spec.json (from step 4.1, optional)\r\n```\r\n\r\n**Handling Logic**:\r\n```javascript\r\nconst prd = await loadOptionalArtifact('prd.json');\r\nconst uiSpec = await loadOptionalArtifact('ui-spec.json');\r\n\r\nconst reviewChecks = {\r\n  code_quality: true,           // Always check\r\n  architecture_compliance: true, // Always check\r\n  prd_alignment: !!prd,         // Only if PRD available\r\n  ui_compliance: !!uiSpec       // Only if UI spec available\r\n};\r\n\r\nif (!prd) {\r\n  console.log('[code-reviewer] PRD not available - skipping requirements alignment check');\r\n}\r\n\r\nif (!uiSpec) {\r\n  console.log('[code-reviewer] UI spec not available - skipping design system compliance');\r\n}\r\n```\r\n\r\n### Pattern 2: Optional Previous Artifacts\r\n\r\n**Use Case**: Architect can design without existing legacy system analysis\r\n\r\n```yaml\r\n- step: 4\r\n  agent: architect\r\n  inputs:\r\n    - prd.json (from step 2)\r\n    - legacy-analysis.json (from step 3.5, optional)\r\n```\r\n\r\n**Handling Logic**:\r\n```javascript\r\nconst legacyAnalysis = await loadOptionalArtifact('legacy-analysis.json');\r\n\r\nconst architectureConstraints = legacyAnalysis\r\n  ? {\r\n      legacy_integrations: legacyAnalysis.integration_points,\r\n      migration_requirements: legacyAnalysis.migration_strategy,\r\n      compatibility_constraints: legacyAnalysis.constraints\r\n    }\r\n  : {\r\n      legacy_integrations: [],\r\n      migration_requirements: 'greenfield',\r\n      compatibility_constraints: []\r\n    };\r\n```\r\n\r\n### Pattern 3: Optional Validation Artifacts\r\n\r\n**Use Case**: QA can test without performance benchmarks\r\n\r\n```yaml\r\n- step: 9\r\n  agent: qa\r\n  inputs:\r\n    - dev-manifest.json (from step 7)\r\n    - performance-baseline.json (from step 8.5, optional)\r\n```\r\n\r\n**Handling Logic**:\r\n```javascript\r\nconst performanceBaseline = await loadOptionalArtifact('performance-baseline.json');\r\n\r\nconst testSuite = {\r\n  unit_tests: true,              // Always run\r\n  integration_tests: true,        // Always run\r\n  e2e_tests: true,               // Always run\r\n  performance_tests: !!performanceBaseline  // Only if baseline available\r\n};\r\n\r\nif (!performanceBaseline) {\r\n  console.log('[qa] Performance baseline not available - skipping performance regression tests');\r\n  console.log('[qa] Will establish new baseline instead of comparing against existing');\r\n}\r\n```\r\n\r\n## Example Output/Logging Format\r\n\r\n### Console Logging Pattern\r\n```\r\n[optional-artifact-handler] Checking for optional artifact: infrastructure-config.json\r\n[optional-artifact-handler] Registry path: .claude/context/artifacts/registry-workflow-123.json\r\n[optional-artifact-handler] ✗ infrastructure-config.json NOT FOUND (optional)\r\n[optional-artifact-handler] ✓ Applying default: empty config object\r\n[optional-artifact-handler] Impact: Cloud integration stubs will use placeholder values\r\n[optional-artifact-handler] Recommendation: Run DevOps step (4.5) to generate infrastructure config\r\n[optional-artifact-handler] Documenting decision in reasoning file\r\n```\r\n\r\n### Reasoning File Entry\r\n```json\r\n{\r\n  \"optional_artifact_handling\": {\r\n    \"timestamp\": \"2025-01-03T10:45:00Z\",\r\n    \"workflow_id\": \"workflow-123\",\r\n    \"step\": 7,\r\n    \"agent\": \"developer\",\r\n    \"artifacts_checked\": [\r\n      {\r\n        \"name\": \"infrastructure-config.json\",\r\n        \"required\": false,\r\n        \"found\": false,\r\n        \"registry_path\": \".claude/context/artifacts/registry-workflow-123.json\",\r\n        \"default_strategy\": \"empty_config\",\r\n        \"default_value\": {\r\n          \"cloud_provider\": \"gcp\",\r\n          \"resources\": [],\r\n          \"environment_variables\": {},\r\n          \"service_accounts\": []\r\n        },\r\n        \"impact_assessment\": {\r\n          \"severity\": \"medium\",\r\n          \"areas_affected\": [\"cloud_integration\", \"deployment\"],\r\n          \"workarounds_applied\": [\"environment_variables\", \"placeholder_names\"],\r\n          \"follow_up_required\": true,\r\n          \"follow_up_steps\": [\"Run step 4.5 (DevOps)\", \"Update service configurations\"]\r\n        }\r\n      }\r\n    ],\r\n    \"workflow_continuity\": \"proceeded_with_defaults\",\r\n    \"quality_impact\": \"technical_debt_introduced\",\r\n    \"recommendations\": [\r\n      \"Run DevOps workflow step (4.5) to generate infrastructure-config.json\",\r\n      \"Update cloud service clients with actual resource names after infrastructure provisioning\",\r\n      \"Set required environment variables before deployment\"\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\n### Artifact Registry Update\r\n```json\r\n{\r\n  \"artifacts\": [\r\n    {\r\n      \"name\": \"dev-manifest.json\",\r\n      \"path\": \".claude/context/artifacts/dev-manifest-workflow-123.json\",\r\n      \"step\": 7,\r\n      \"agent\": \"developer\",\r\n      \"validated\": true,\r\n      \"created_at\": \"2025-01-03T10:50:00Z\",\r\n      \"metadata\": {\r\n        \"optional_artifacts_used\": [],\r\n        \"optional_artifacts_missing\": [\"infrastructure-config.json\"],\r\n        \"defaults_applied\": [\"infrastructure-config.json\"],\r\n        \"quality_notes\": \"Cloud integration uses placeholder values - requires manual configuration\"\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n## Related Documentation\r\n\r\n- [Orchestrator Agent](../../agents/orchestrator.md) - Optional Input Handling\r\n- [Developer Agent](../../agents/developer.md) - Cloud Integration Patterns\r\n- [Workflow Guide](../../workflows/WORKFLOW-GUIDE.md) - Optional Inputs Section\r\n- [CUJ-038](../../docs/cujs/CUJ-038.md) - Optional Artifact Handling\r\n",
          "tokens": 4049
        }
      }
    },
    "plan-generator": {
      "name": "plan-generator",
      "one_liner": "No description",
      "key_commands": ["/identity", "/capabilities", "/templates", "/plan-template", "/context"],
      "token_count": {
        "minimal": 11,
        "essential": 239,
        "standard": 719,
        "full": 1270
      },
      "levels": {
        "minimal": {
          "content": "**plan-generator**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: plan-generator\n\nPlan Generator Skill - Creates structured, validated plans from requirements by coordinating with specialist agents and generating comprehensive planning artifacts.\n\n### Key Steps:\n: Analyze Requirements\r\n\r\nParse user requirements:\r\n- Extract explicit requirements\r\n- Identify implicit requirements\r\n- Determine planning scope\r\n- Assess complexity\r\n\r\n\n### Step: Coordinate Specialists\r\n\r\nRequest planning input from relevant agents:\r\n- **Analyst**: Business requirements and market context\r\n- **PM**: Product requirements and user stories\r\n- **Architect**: Technical architecture and design\r\n- **Database Architect**: Data requirements\r\n- **UX Expert**: Interface requirements\r\n\r\n\n### Step: Generate Plan Structure\r\n\r\nCreate plan following template:\r\n- Load template from `.claude/templates/plan-template.md`\r\n- Define objectives\r\n- Break down into steps (≤7 steps per section)\r\n- Identify dependencies\r\n- Assign agents to steps",
          "tokens": 239
        },
        "standard": {
          "content": "## Skill: plan-generator\n\nPlan Generator Skill - Creates structured, validated plans from requirements by coordinating with specialist agents and generating comprehensive planning artifacts.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Analyze Requirements\r\n\r\nParse user requirements:\r\n- Extract explicit requirements\r\n- Identify implicit requirements\r\n- Determine planning scope\r\n- Assess complexity\r\n\r\n### Step 2: Coordinate Specialists\r\n\r\nRequest planning input from relevant agents:\r\n- **Analyst**: Business requirements and market context\r\n- **PM**: Product requirements and user stories\r\n- **Architect**: Technical architecture and design\r\n- **Database Architect**: Data requirements\r\n- **UX Expert**: Interface requirements\r\n\r\n### Step 3: Generate Plan Structure\r\n\r\nCreate plan following template:\r\n- Load template from `.claude/templates/plan-template.md`\r\n- Define objectives\r\n- Break down into steps (≤7 steps per section)\r\n- Identify dependencies\r\n- Assign agents to steps\r\n\r\n### Step 4: Assess Risks\r\n\r\nIdentify risks and mitigation:\r\n- Technical risks\r\n- Resource risks\r\n- Timeline risks\r\n- Dependency risks\r\n- Mitigation strategies\r\n\r\n### Step 5: Validate Plan\r\n\r\nValidate plan completeness:\r\n- All requirements addressed\r\n- Dependencies mapped\r\n- Success criteria defined\r\n- Risks identified\r\n- Plan is feasible\r\n\r\n### Step 6: Generate Artifacts\r\n\r\nCreate plan artifacts:\r\n- Plan markdown: `.claude/context/artifacts/plan-<id>.md`\r\n- Plan JSON: `.claude/context/artifacts/plan-<id>.json`\r\n- Plan summary\r\n</execution_process>\r\n\r\n<plan_types>\r\n**Feature Development Plan**:\r\n- Objectives: Feature goals\r\n- Steps: Analysis → Design → Implementation → Testing\r\n- Agents: Analyst → PM → Architect → Developer → QA\r\n\r\n**Refactoring Plan**:\r\n- Objectives: Code quality goals\r\n- Steps: Analysis → Planning → Implementation → Validation\r\n- Agents: Code Reviewer → Refactoring Specialist → Developer → QA\r\n\r\n**Migration Plan**:\r\n- Objectives: Migration goals\r\n- Steps: Analysis → Planning → Execution → Validation\r\n- Agents: Architect → Legacy Modernizer → Developer → QA\r\n\r\n**Architecture Plan**:\r\n- Objectives: Architecture goals\r\n- Steps: Analysis → Design → Validation → Documentation\r\n- Agents: Architect → Database Architect → Security Architect → Technical Writer\r\n</plan_types>\r\n\r\n<integration>\r\n**Integration with Planner Agent**:\r\nPlanner agent uses this skill to:\r\n- Generate plans from requirements\r\n- Coordinate specialist input\r\n- Validate plan completeness\r\n- Track plan execution\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Coordinate Early**: Get specialist input before finalizing plan\r\n2. **Keep Steps Focused**: ≤7 steps per plan section\r\n3. **Map Dependencies**: Clearly identify prerequisites\r\n4. **Assess Risks**: Identify and mitigate risks proactively\r\n5. **Validate Thoroughly**: Ensure plan is complete and feasible\r\n</best_practices>\n",
          "tokens": 719
        },
        "full": {
          "content": "---\r\nname: plan-generator\r\ndescription: Creates structured plans from requirements. Generates comprehensive plans with steps, dependencies, risks, and success criteria. Coordinates with specialist agents for planning input and validates plan completeness.\r\nallowed-tools: read, write, glob, search, codebase_search, Task\r\nversion: 1.0\r\nbest_practices:\r\n  - Coordinate with Analyst, PM, Architect for planning input\r\n  - Break down requirements into actionable steps (≤7 per section)\r\n  - Identify dependencies and sequencing\r\n  - Assess risks with mitigation strategies\r\n  - Validate plan completeness and feasibility\r\nerror_handling: graceful\r\nstreaming: supported\r\ntemplates: [feature-plan, refactoring-plan, migration-plan, architecture-plan]\r\n---\r\n\r\n<identity>\r\nPlan Generator Skill - Creates structured, validated plans from requirements by coordinating with specialist agents and generating comprehensive planning artifacts.\r\n</identity>\r\n\r\n<capabilities>\r\n- Creating plans for new features\r\n- Planning refactoring efforts\r\n- Planning system migrations\r\n- Planning architecture changes\r\n- Breaking down complex requirements\r\n- Validating existing plans\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Analyze Requirements\r\n\r\nParse user requirements:\r\n- Extract explicit requirements\r\n- Identify implicit requirements\r\n- Determine planning scope\r\n- Assess complexity\r\n\r\n### Step 2: Coordinate Specialists\r\n\r\nRequest planning input from relevant agents:\r\n- **Analyst**: Business requirements and market context\r\n- **PM**: Product requirements and user stories\r\n- **Architect**: Technical architecture and design\r\n- **Database Architect**: Data requirements\r\n- **UX Expert**: Interface requirements\r\n\r\n### Step 3: Generate Plan Structure\r\n\r\nCreate plan following template:\r\n- Load template from `.claude/templates/plan-template.md`\r\n- Define objectives\r\n- Break down into steps (≤7 steps per section)\r\n- Identify dependencies\r\n- Assign agents to steps\r\n\r\n### Step 4: Assess Risks\r\n\r\nIdentify risks and mitigation:\r\n- Technical risks\r\n- Resource risks\r\n- Timeline risks\r\n- Dependency risks\r\n- Mitigation strategies\r\n\r\n### Step 5: Validate Plan\r\n\r\nValidate plan completeness:\r\n- All requirements addressed\r\n- Dependencies mapped\r\n- Success criteria defined\r\n- Risks identified\r\n- Plan is feasible\r\n\r\n### Step 6: Generate Artifacts\r\n\r\nCreate plan artifacts:\r\n- Plan markdown: `.claude/context/artifacts/plan-<id>.md`\r\n- Plan JSON: `.claude/context/artifacts/plan-<id>.json`\r\n- Plan summary\r\n</execution_process>\r\n\r\n<plan_types>\r\n**Feature Development Plan**:\r\n- Objectives: Feature goals\r\n- Steps: Analysis → Design → Implementation → Testing\r\n- Agents: Analyst → PM → Architect → Developer → QA\r\n\r\n**Refactoring Plan**:\r\n- Objectives: Code quality goals\r\n- Steps: Analysis → Planning → Implementation → Validation\r\n- Agents: Code Reviewer → Refactoring Specialist → Developer → QA\r\n\r\n**Migration Plan**:\r\n- Objectives: Migration goals\r\n- Steps: Analysis → Planning → Execution → Validation\r\n- Agents: Architect → Legacy Modernizer → Developer → QA\r\n\r\n**Architecture Plan**:\r\n- Objectives: Architecture goals\r\n- Steps: Analysis → Design → Validation → Documentation\r\n- Agents: Architect → Database Architect → Security Architect → Technical Writer\r\n</plan_types>\r\n\r\n<integration>\r\n**Integration with Planner Agent**:\r\nPlanner agent uses this skill to:\r\n- Generate plans from requirements\r\n- Coordinate specialist input\r\n- Validate plan completeness\r\n- Track plan execution\r\n</integration>\r\n\r\n<best_practices>\r\n1. **Coordinate Early**: Get specialist input before finalizing plan\r\n2. **Keep Steps Focused**: ≤7 steps per plan section\r\n3. **Map Dependencies**: Clearly identify prerequisites\r\n4. **Assess Risks**: Identify and mitigate risks proactively\r\n5. **Validate Thoroughly**: Ensure plan is complete and feasible\r\n</best_practices>\r\n</instructions>\r\n\r\n<examples>\r\n<formatting_example>\r\n**Example Plan Output**\r\n\r\n**Command**: \"Generate plan for user authentication feature\"\r\n\r\n**Generated Plan**:\r\n\r\n```markdown\r\n# Plan: User Authentication Feature\r\n\r\n## Objectives\r\n- Implement JWT-based authentication\r\n- Support login, logout, and session management\r\n- Provide secure password handling\r\n\r\n## Steps\r\n\r\n### Step 1: Requirements Analysis\r\n- **Agent**: analyst\r\n- **Dependencies**: none\r\n- **Tasks**: Analyze auth requirements, research best practices\r\n- **Success Criteria**: Requirements document complete\r\n\r\n### Step 2: Architecture Design\r\n- **Agent**: architect\r\n- **Dependencies**: Step 1\r\n- **Tasks**: Design auth architecture, select technologies\r\n- **Success Criteria**: Architecture document complete\r\n\r\n### Step 3: Implementation\r\n- **Agent**: developer\r\n- **Dependencies**: Step 2\r\n- **Tasks**: Implement auth endpoints, JWT handling, password hashing\r\n- **Success Criteria**: All tests passing, code reviewed\r\n\r\n### Step 4: Testing\r\n- **Agent**: qa\r\n- **Dependencies**: Step 3\r\n- **Tasks**: Write tests, perform security testing\r\n- **Success Criteria**: Test coverage >80%, security validated\r\n```\r\n</formatting_example>\r\n</examples>\r\n\r\n",
          "tokens": 1270
        }
      }
    },
    "sequential-thinking": {
      "name": "sequential-thinking",
      "one_liner": "Sequential thinking and structured problem solving. Break down complex problems into steps with revision and branching capabilities. Use for multi-step analysis, planning, and hypothesis verification.",
      "key_commands": [
        "/revise",
        "/server-sequential-thinking",
        "/skills",
        "/mcp-converter",
        "/skill-manager"
      ],
      "token_count": {
        "minimal": 57,
        "essential": 58,
        "standard": 58,
        "full": 823
      },
      "levels": {
        "minimal": {
          "content": "**sequential-thinking**: Sequential thinking and structured problem solving. Break down complex problems into steps with revision and branching capabilities. Use for multi-step analysis, planning, and hypothesis verification.",
          "tokens": 57
        },
        "essential": {
          "content": "## Skill: sequential-thinking\n\nSequential thinking and structured problem solving. Break down complex problems into steps with revision and branching capabilities. Use for multi-step analysis, planning, and hypothesis verification.\n",
          "tokens": 58
        },
        "standard": {
          "content": "## Skill: sequential-thinking\n\nSequential thinking and structured problem solving. Break down complex problems into steps with revision and branching capabilities. Use for multi-step analysis, planning, and hypothesis verification.\n",
          "tokens": 58
        },
        "full": {
          "content": "---\nname: sequential-thinking\ndescription: Sequential thinking and structured problem solving. Break down complex problems into steps with revision and branching capabilities. Use for multi-step analysis, planning, and hypothesis verification.\nallowed-tools: read, write, bash\n---\n\n# Sequential Thinking Skill\n\n## Overview\n\nThis skill provides structured problem-solving through a flexible thinking process that can adapt and evolve. Each thought can build on, question, or revise previous insights.\n\n**Context Savings**: ~97% reduction\n- **MCP Mode**: ~15,000 tokens always loaded\n- **Skill Mode**: ~500 tokens metadata + on-demand loading\n\n## When to Use\n\n- Breaking down complex problems into steps\n- Planning and design with room for revision\n- Analysis that might need course correction\n- Problems where the full scope isn't clear initially\n- Multi-step solutions requiring maintained context\n- Filtering irrelevant information\n- Hypothesis generation and verification\n\n## Quick Reference\n\n```bash\n# Use the sequential thinking tool\npython executor.py --tool sequentialthinking --args '{\n  \"thought\": \"First, let me analyze the problem...\",\n  \"thoughtNumber\": 1,\n  \"totalThoughts\": 5,\n  \"nextThoughtNeeded\": true\n}'\n```\n\n## Tool: sequentialthinking\n\nA detailed tool for dynamic and reflective problem-solving through thoughts.\n\n### Parameters\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `thought` | string | Your current thinking step |\n| `thoughtNumber` | integer | Current thought number (1, 2, 3...) |\n| `totalThoughts` | integer | Estimated total thoughts needed |\n| `nextThoughtNeeded` | boolean | Whether another thought step is needed |\n| `isRevision` | boolean | If this thought revises previous thinking |\n| `revisesThought` | integer | Which thought number is being reconsidered |\n| `branchFromThought` | integer | Branching point thought number |\n| `branchId` | string | Identifier for current branch |\n| `needsMoreThoughts` | boolean | If more thoughts needed at the \"end\" |\n\n### Key Features\n\n- Adjust `totalThoughts` up or down as you progress\n- Question or revise previous thoughts\n- Add more thoughts even after reaching what seemed like the end\n- Express uncertainty and explore alternatives\n- Branch or backtrack (non-linear thinking)\n- Generate and verify solution hypotheses\n\n### Process\n\n1. Start with initial estimate of needed thoughts\n2. Feel free to question/revise previous thoughts\n3. Add more thoughts if needed, even at the \"end\"\n4. Mark thoughts that revise or branch\n5. Generate solution hypothesis when appropriate\n6. Verify hypothesis based on Chain of Thought\n7. Repeat until satisfied\n8. Set `nextThoughtNeeded: false` only when truly done\n\n## Tool Execution\n\n```bash\n# List available tools\npython executor.py --list\n\n# Execute a thinking step\npython executor.py --tool sequentialthinking --args '{\"thought\": \"...\", \"thoughtNumber\": 1, \"totalThoughts\": 5, \"nextThoughtNeeded\": true}'\n```\n\n## Configuration\n\nMCP server configuration stored in `config.json`:\n- **Command**: `npx -y @modelcontextprotocol/server-sequential-thinking`\n\n## Related\n\n- Original MCP server: `@modelcontextprotocol/server-sequential-thinking`\n- MCP Converter Skill: `.claude/skills/mcp-converter/`\n- Skill Manager: `.claude/skills/skill-manager/`\n",
          "tokens": 823
        }
      }
    },
    "rule-selector": {
      "name": "rule-selector",
      "one_liner": "No description",
      "key_commands": ["/JavaScript", "/context", "/rule-index", "/generate-rule-index", "/n"],
      "token_count": {
        "minimal": 11,
        "essential": 6,
        "standard": 6,
        "full": 5754
      },
      "levels": {
        "minimal": {
          "content": "**rule-selector**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: rule-selector\n",
          "tokens": 6
        },
        "standard": {
          "content": "## Skill: rule-selector\n",
          "tokens": 6
        },
        "full": {
          "content": "---\r\nname: rule-selector\r\ndescription: Analyzes project tech stack and recommends optimal rule configuration. Detects frameworks from package.json, requirements.txt, go.mod, and other config files. Generates custom manifest.yaml profiles for your specific stack.\r\nallowed-tools: read, glob, grep, search\r\nmin_required_version: 1.0.0\r\ncompatible_versions: \"^1.0.0\"\r\n---\r\n\r\n# Rule Selector\r\n\r\nIntelligently detects your tech stack and configures optimal coding rules.\r\n\r\n## When to Use\r\n\r\n- Setting up rules for a new project\r\n- Onboarding to an existing codebase\r\n- Updating rules after adding new dependencies\r\n- Auditing rule configuration for optimization\r\n- Generating team-specific rule profiles\r\n\r\n## Instructions\r\n\r\n### Step 1: Detect Project Type\r\n\r\nScan for configuration files to identify the tech stack:\r\n\r\n```bash\r\n# Check for package managers and configs\r\nls -la package.json requirements.txt go.mod Cargo.toml pom.xml build.gradle composer.json Gemfile\r\n\r\n# Check for framework-specific files\r\nls -la next.config.* nuxt.config.* angular.json svelte.config.* astro.config.*\r\n```\r\n\r\n### Step 2: Parse Dependencies\r\n\r\nExtract framework and library information:\r\n\r\n**Node.js/JavaScript Projects:**\r\n```bash\r\n# Parse package.json for key dependencies\r\ncat package.json | jq '.dependencies + .devDependencies | keys[]' | grep -E \"react|next|vue|angular|svelte\"\r\n```\r\n\r\n**Python Projects:**\r\n```bash\r\n# Parse requirements.txt or pyproject.toml\r\ncat requirements.txt | grep -E \"fastapi|django|flask|pytorch|tensorflow\"\r\n```\r\n\r\n**Go Projects:**\r\n```bash\r\n# Parse go.mod\r\ncat go.mod | grep -E \"gin|echo|fiber|chi\"\r\n```\r\n\r\n### Step 3: Load Rule Index\r\n\r\nLoad the rule index to discover all available rules dynamically:\r\n- @.claude/context/rule-index.json\r\n\r\nThe index contains metadata for all 1,081+ rules with technology mappings.\r\n\r\n**Version Compatibility Check** (CRITICAL):\r\n\r\nBefore using the rule index, verify version compatibility:\r\n\r\n```javascript\r\n// Load and validate index version\r\nconst ruleIndex = JSON.parse(await fs.readFile('.claude/context/rule-index.json', 'utf-8'));\r\nconst indexVersion = ruleIndex.version || '0.0.0';\r\nconst minRequired = '1.0.0'; // From skill frontmatter\r\n\r\nif (!isVersionCompatible(indexVersion, minRequired)) {\r\n  console.warn(`\r\n⚠️  RULE INDEX VERSION MISMATCH\r\n   Current index version: ${indexVersion}\r\n   Required version: ${minRequired}+\r\n\r\n   The rule index may be outdated. Please regenerate it:\r\n\r\n   Command: pnpm index-rules\r\n   Or:      node scripts/generate-rule-index.mjs\r\n\r\n   This ensures all rules are discoverable by the skill.\r\n  `);\r\n\r\n  // Offer to regenerate automatically\r\n  const shouldRegenerate = await promptUser('Regenerate rule index now? (y/n)');\r\n  if (shouldRegenerate) {\r\n    await execAsync('pnpm index-rules');\r\n    // Reload index after regeneration\r\n    ruleIndex = JSON.parse(await fs.readFile('.claude/context/rule-index.json', 'utf-8'));\r\n  }\r\n}\r\n\r\n// Helper function for semantic version comparison\r\nfunction isVersionCompatible(current, required) {\r\n  const [cMajor, cMinor, cPatch] = current.split('.').map(Number);\r\n  const [rMajor, rMinor, rPatch] = required.split('.').map(Number);\r\n\r\n  // Major version must match (breaking changes)\r\n  if (cMajor !== rMajor) return false;\r\n\r\n  // Minor version must be >= required (new features are backward compatible)\r\n  if (cMinor < rMinor) return false;\r\n\r\n  // Patch version doesn't matter for compatibility\r\n  return true;\r\n}\r\n```\r\n\r\n**When to Increment Index Version**:\r\n\r\nUpdate the version in `scripts/generate-rule-index.mjs` when:\r\n\r\n| Change Type | Version Bump | Example |\r\n|------------|--------------|---------|\r\n| **Major (X.0.0)** | Breaking schema changes | Renamed `technology_map` to `tech_index`, removed `rules` array |\r\n| **Minor (1.X.0)** | New rules added | Added 50 new rules, new technology categories |\r\n| **Minor (1.X.0)** | Rule paths changed | Moved rules from `.claude/archive/` to `.claude/rules-library/` |\r\n| **Minor (1.X.0)** | New metadata fields | Added `templates` or `validation_blocks` to rule metadata |\r\n| **Patch (1.0.X)** | Bug fixes only | Fixed technology detection, corrected metadata parsing |\r\n| **Patch (1.0.X)** | Re-indexing | Re-ran index generation without content changes |\r\n\r\n**Version History**:\r\n\r\n- **1.1.0**: Added versioning metadata, schema_version, and increment guide\r\n- **1.0.0**: Initial release with master rules and library rules support\r\n\r\n**Fallback Strategy (CRITICAL for drop-in reliability):**\r\n\r\nIf `.claude/context/rule-index.json` is missing or cannot be loaded:\r\n\r\n1. **Attempt to load pre-built index** (should exist in repo):\r\n   - Check if file exists at `.claude/context/rule-index.json`\r\n   - If exists, load it (pre-built index includes common stacks)\r\n\r\n2. **If pre-built index missing, fall back to direct directory scan**:\r\n   - Scan `.claude/rules-master/` directory directly\r\n   - Scan `.claude/rules-library/` (formerly archive) directory directly\r\n   - Build temporary index in memory from discovered rules\r\n   - Continue with rule selection using temporary index\r\n   - Log fallback in reasoning: \"Used directory scan fallback - rule-index.json not found\"\r\n\r\n3. **Never fail** - Always provide rule recommendations even if index is missing\r\n\r\n**Empty Directory Handling:**\r\n\r\nIf no configuration files are detected (package.json, requirements.txt, go.mod, etc.):\r\n\r\n1. **Detect empty state**:\r\n   - Check for common config files: `package.json`, `requirements.txt`, `go.mod`, `Cargo.toml`, `pom.xml`, `build.gradle`, `composer.json`, `Gemfile`\r\n   - Check for framework configs: `next.config.*`, `nuxt.config.*`, `angular.json`, `svelte.config.*`, `astro.config.*`\r\n   - If none found: Empty directory detected\r\n\r\n2. **Prompt user with Quick Pick list for common stacks**:\r\n   ```\r\n   \"No configuration files detected. Please select your intended stack:\r\n   \r\n   **Quick Pick (Common Stacks):**\r\n   1. Next.js - Full-stack React framework with App Router\r\n   2. Python API - FastAPI/Django REST API service\r\n   3. Go Service - Go microservice or API\r\n   4. React SPA - React single-page application\r\n   5. TypeScript App - TypeScript application\r\n   6. Vue.js App - Vue.js application\r\n   7. Other - Describe your stack using keywords\r\n   \r\n   Or describe your stack using one of these keywords:\r\n   \r\n   **Supported Stack Keywords:**\r\n   - `nextjs-app` - Next.js application\r\n   - `react-spa` - React single-page application\r\n   - `fastapi-backend` - FastAPI backend service\r\n   - `django-backend` - Django backend service\r\n   - `go-microservice` - Go microservice\r\n   - `python-api` - Python API service\r\n   - `typescript-app` - TypeScript application\r\n   - `vue-app` - Vue.js application\r\n   - `angular-app` - Angular application\r\n   - `nodejs-api` - Node.js API service\r\n   - `mobile-react-native` - React Native mobile app\r\n   - `mobile-flutter` - Flutter mobile app\r\n   \r\n   **Or describe your stack in natural language:**\r\n   - Example: 'React with Python backend'\r\n   - Example: 'Next.js TypeScript with PostgreSQL'\r\n   - Example: 'Go microservices'\r\n   - Example: 'Python FastAPI with MongoDB'\r\n   \"\r\n   ```\r\n\r\n3. **Parse user description**:\r\n   - Extract technologies from user input\r\n   - Map to rule categories using technology keywords\r\n   - Generate profile based on parsed technologies\r\n   - **If user uses a Stack Keyword**: Map directly to corresponding rules (e.g., `nextjs-app` → Next.js + TypeScript + React rules)\r\n\r\n4. **Generate manifest.yaml**:\r\n   - Use parsed technologies to select rules\r\n   - Create stack profile with selected rules\r\n   - Document that profile was generated from user description\r\n\r\n## Supported Stack Keywords\r\n\r\nWhen prompting users in empty directory scenarios, suggest these keywords for better rule mapping:\r\n\r\n| Keyword | Description | Maps To Rules |\r\n|---------|-------------|---------------|\r\n| `nextjs-app` | Next.js application | Next.js, React, TypeScript, Tailwind |\r\n| `react-spa` | React single-page application | React, TypeScript, JavaScript |\r\n| `fastapi-backend` | FastAPI backend service | FastAPI, Python, Pydantic |\r\n| `django-backend` | Django backend service | Django, Python |\r\n| `go-microservice` | Go microservice | Go, Golang |\r\n| `python-api` | Python API service | Python, FastAPI/Django |\r\n| `typescript-app` | TypeScript application | TypeScript, JavaScript |\r\n| `vue-app` | Vue.js application | Vue, TypeScript, JavaScript |\r\n| `angular-app` | Angular application | Angular, TypeScript |\r\n| `nodejs-api` | Node.js API service | Node.js, Express, TypeScript |\r\n| `mobile-react-native` | React Native mobile app | React Native, TypeScript |\r\n| `mobile-flutter` | Flutter mobile app | Flutter, Dart |\r\n\r\n**Usage**: When user provides a keyword, map directly to corresponding technology rules. For natural language descriptions, extract technologies and map to rules.\r\n\r\n### Step 4: Map Technologies to Rules\r\n\r\nFor each detected technology, query the index's `technology_map`:\r\n\r\n```javascript\r\n// Pseudocode\r\nconst detectedTech = ['nextjs', 'react', 'typescript', 'tailwind'];\r\nconst recommendedRules = [];\r\n\r\ndetectedTech.forEach(tech => {\r\n  const rules = index.technology_map[tech] || [];\r\n  recommendedRules.push(...rules);\r\n});\r\n\r\n// Prioritize master rules over library rules\r\nconst masterRules = recommendedRules.filter(r => r.type === 'master');\r\nconst libraryRules = recommendedRules.filter(r => r.type === 'library');\r\n```\r\n\r\n**Technology Mapping**:\r\n- Detected technologies from Step 2 → Query `index.technology_map[tech]`\r\n- Get all rules for each technology\r\n- Prioritize master rules (from `.claude/rules-master/`)\r\n- Supplement with library rules (from `.claude/rules-library/`, formerly archive)\r\n\r\n### Step 5: Generate Stack Profile\r\n\r\nCreate a custom profile in manifest.yaml using rules from the index:\r\n\r\n```yaml\r\n# Generated stack profile for: my-nextjs-app\r\n# Rules discovered from rule index\r\nstack_profiles:\r\n  my-nextjs-app:\r\n    # Auto-detected: Next.js 14 + TypeScript + Tailwind + Prisma\r\n    include:\r\n      # Master rules (from index, type: \"master\")\r\n      - \".claude/rules-master/TECH_STACK_NEXTJS.md\"\r\n      - \".claude/rules-master/PROTOCOL_ENGINEERING.md\"\r\n      \r\n      # Library rules (from index, type: \"library\", formerly archive)\r\n      # Selected based on technology_map queries\r\n      - \".claude/rules-library/nextjs.mdc\"\r\n      - \".claude/rules-library/typescript.mdc\"\r\n      - \".claude/rules-library/react.mdc\"\r\n      - \".claude/rules-library/tailwind.mdc\"\r\n      - \".claude/rules-library/vitest-unit-testing-cursorrules-prompt-file/**/*.mdc\"\r\n\r\n    exclude:\r\n      # Exclude rules for technologies NOT detected\r\n      # Query index.technology_map for all technologies\r\n      # Exclude rules not matching detected stack\r\n      - \".claude/rules-library/angular-*/**\"\r\n      - \".claude/rules-library/vue-*/**\"\r\n      - \".claude/rules-library/python-*/**\"\r\n      - \".claude/rules-library/go-*/**\"\r\n      - \".claude/rules-library/swift-*/**\"\r\n      - \".claude/rules-library/android-*/**\"\r\n\r\n    # Priority order (master rules first)\r\n    priority:\r\n      - TECH_STACK_NEXTJS      # Master rule (highest priority)\r\n      - PROTOCOL_ENGINEERING    # Master rule (universal)\r\n      - nextjs                  # Library rule (framework-specific)\r\n      - typescript              # Library rule (language)\r\n\r\n    metadata:\r\n      generated: \"2025-11-29\"\r\n      generated_by: \"rule-selector (index-based)\"\r\n      detected_stack:\r\n        - \"next@14.0.0\"\r\n        - \"react@18.2.0\"\r\n        - \"typescript@5.3.0\"\r\n        - \"tailwindcss@3.4.0\"\r\n        - \"@prisma/client@5.7.0\"\r\n      rules_source: \"rule-index.json\"\r\n      total_rules_available: 1081\r\n      rules_selected: 7\r\n```\r\n\r\n## Detection Patterns\r\n\r\n### Frontend Detection\r\n\r\n```yaml\r\n# React Ecosystem\r\nreact_detection:\r\n  signals:\r\n    - package.json: \"react\", \"react-dom\"\r\n  variants:\r\n    next: \"next\" in dependencies\r\n    gatsby: \"gatsby\" in dependencies\r\n    remix: \"@remix-run\" in dependencies\r\n    vite_react: \"vite\" + \"@vitejs/plugin-react\"\r\n  rules:\r\n    base: [\"react.mdc\"]\r\n    next: [\"nextjs.mdc\", \"nextjs-app-router-*\"]\r\n    gatsby: [\"gatsby-*\"]\r\n\r\n# Vue Ecosystem\r\nvue_detection:\r\n  signals:\r\n    - package.json: \"vue\"\r\n  variants:\r\n    nuxt: \"nuxt\" in dependencies\r\n    vue3: version >= 3.0\r\n  rules:\r\n    base: [\"vue.mdc\"]\r\n    nuxt: [\"vue3-nuxt-3-*\"]\r\n    vue3: [\"vue3-composition-api-*\"]\r\n\r\n# Angular Ecosystem\r\nangular_detection:\r\n  signals:\r\n    - package.json: \"@angular/core\"\r\n    - angular.json exists\r\n  rules: [\"angular-typescript-*\"]\r\n\r\n# Svelte Ecosystem\r\nsvelte_detection:\r\n  signals:\r\n    - package.json: \"svelte\"\r\n  variants:\r\n    sveltekit: \"@sveltejs/kit\" in dependencies\r\n  rules:\r\n    base: [\"svelte.mdc\"]\r\n    sveltekit: [\"sveltekit-*\"]\r\n```\r\n\r\n### Backend Detection\r\n\r\n```yaml\r\n# Python Ecosystem\r\npython_detection:\r\n  signals:\r\n    - requirements.txt exists\r\n    - pyproject.toml exists\r\n    - \"*.py\" files present\r\n  variants:\r\n    fastapi: \"fastapi\" in requirements\r\n    django: \"django\" in requirements\r\n    flask: \"flask\" in requirements\r\n    ml: \"pytorch\" or \"tensorflow\" in requirements\r\n  rules:\r\n    base: [\"python.mdc\"]\r\n    fastapi: [\"fastapi.mdc\", \"python-fastapi-*\"]\r\n    django: [\"python-django-*\"]\r\n    ml: [\"python-llm-ml-workflow-*\"]\r\n\r\n# Node.js Backend\r\nnode_backend_detection:\r\n  signals:\r\n    - package.json: \"express\" or \"fastify\" or \"nestjs\"\r\n  rules: [\"node-express.mdc\", \"javascript-*\"]\r\n\r\n# Go Backend\r\ngo_detection:\r\n  signals:\r\n    - go.mod exists\r\n    - \"*.go\" files present\r\n  rules: [\"go-*\", \"backend-scalability-*\"]\r\n```\r\n\r\n### Testing Detection\r\n\r\n```yaml\r\ntesting_detection:\r\n  e2e:\r\n    cypress: [\"cypress-e2e-testing-*\", \"cypress-api-testing-*\"]\r\n    playwright: [\"playwright-e2e-testing-*\", \"playwright-api-testing-*\"]\r\n  unit:\r\n    jest: [\"jest-unit-testing-*\"]\r\n    vitest: [\"vitest-unit-testing-*\"]\r\n    pytest: [\"python-*\"]  # Python testing included in python rules\r\n  bdd:\r\n    cucumber: [\"gherkin-*\"]\r\n```\r\n\r\n## Output Formats\r\n\r\n### Format 1: Manifest Update (default)\r\n\r\nGenerates updated `.claude/rules/manifest.yaml`:\r\n\r\n```yaml\r\n# AUTO-GENERATED by rule-selector skill\r\n# Project: my-nextjs-app\r\n# Generated: 2025-11-29T10:00:00Z\r\n\r\nstack_profiles:\r\n  # ... generated profile ...\r\n\r\nloading_policy:\r\n  max_rules_files: 5  # Increased for comprehensive stack\r\n  selection: \"most_relevant\"\r\n  auto_detect: true\r\n```\r\n\r\n### Format 2: Recommendation Report\r\n\r\n```markdown\r\n## Rule Selection Report\r\n\r\n**Project**: /path/to/my-nextjs-app\r\n**Scan Date**: 2025-11-29\r\n\r\n### Detected Stack\r\n\r\n| Category | Technology | Version | Confidence |\r\n|----------|------------|---------|------------|\r\n| Framework | Next.js | 14.0.0 | High |\r\n| Language | TypeScript | 5.3.0 | High |\r\n| Styling | Tailwind CSS | 3.4.0 | High |\r\n| Database | Prisma | 5.7.0 | High |\r\n| Testing | Vitest | 1.0.0 | High |\r\n\r\n### Recommended Rules\r\n\r\n**Primary Rules** (always load):\r\n1. `nextjs.mdc` - Next.js App Router best practices\r\n2. `typescript.mdc` - TypeScript coding standards\r\n3. `react.mdc` - React component patterns\r\n\r\n**Secondary Rules** (load when relevant):\r\n4. `tailwind.mdc` - Tailwind CSS conventions\r\n5. `clean-code.mdc` - Universal code quality\r\n\r\n**Testing Rules** (load during test tasks):\r\n6. `vitest-unit-testing-*` - Unit testing patterns\r\n\r\n### Rules NOT Recommended\r\n\r\nThese rules are excluded as irrelevant to your stack:\r\n- `angular-*` (No Angular detected)\r\n- `vue-*` (No Vue detected)\r\n- `python-*` (No Python detected)\r\n- `cypress-*` (Playwright detected instead)\r\n\r\n### Optimization Suggestions\r\n\r\n1. **Context Budget**: Your stack needs ~5 rule files. Current limit is 3.\r\n   → Recommend increasing `max_rules_files` to 5\r\n\r\n2. **Missing Coverage**: No accessibility rules detected.\r\n   → Consider adding `accessibility-guidelines.mdc`\r\n\r\n3. **Duplicate Coverage**: Both `nextjs.mdc` and `react.mdc` cover components.\r\n   → `nextjs.mdc` takes priority for Next.js projects\r\n```\r\n\r\n### Format 3: JSON (for automation)\r\n\r\n```json\r\n{\r\n  \"project_path\": \"/path/to/my-nextjs-app\",\r\n  \"scan_timestamp\": \"2025-11-29T10:00:00Z\",\r\n  \"detected_stack\": {\r\n    \"framework\": {\"name\": \"nextjs\", \"version\": \"14.0.0\", \"confidence\": 0.95},\r\n    \"language\": {\"name\": \"typescript\", \"version\": \"5.3.0\", \"confidence\": 1.0},\r\n    \"styling\": {\"name\": \"tailwindcss\", \"version\": \"3.4.0\", \"confidence\": 0.9},\r\n    \"testing\": {\"name\": \"vitest\", \"version\": \"1.0.0\", \"confidence\": 0.85}\r\n  },\r\n  \"recommended_rules\": {\r\n    \"primary\": [\"nextjs.mdc\", \"typescript.mdc\", \"react.mdc\"],\r\n    \"secondary\": [\"tailwind.mdc\", \"clean-code.mdc\"],\r\n    \"testing\": [\"vitest-unit-testing-cursorrules-prompt-file\"]\r\n  },\r\n  \"excluded_rules\": [\"angular-*\", \"vue-*\", \"python-*\"],\r\n  \"manifest_updates\": {\r\n    \"stack_profile_name\": \"my-nextjs-app\",\r\n    \"include_patterns\": [\"...\"],\r\n    \"exclude_patterns\": [\"...\"]\r\n  }\r\n}\r\n```\r\n\r\n## Quick Commands\r\n\r\n```\r\n# Auto-detect and show recommendations\r\n/select-rules\r\n\r\n# Auto-detect and update manifest.yaml\r\n/select-rules --apply\r\n\r\n# Detect for specific directory\r\n/select-rules --path ./packages/web\r\n\r\n# Generate JSON output\r\n/select-rules --format json\r\n\r\n# Show what rules would be excluded\r\n/select-rules --show-excluded\r\n\r\n# Force re-detection (ignore cached)\r\n/select-rules --fresh\r\n```\r\n\r\n## Integration with Project Setup\r\n\r\n### New Project Workflow\r\n\r\n```\r\n1. User creates new project\r\n2. Run: /select-rules --apply\r\n3. Skill detects stack from package.json\r\n4. Generates optimized manifest.yaml\r\n5. Rules auto-load on next Claude session\r\n```\r\n\r\n### Monorepo Support\r\n\r\nFor monorepos with multiple packages:\r\n\r\n```yaml\r\nstack_profiles:\r\n  monorepo_web:\r\n    root: \"packages/web\"\r\n    include: [\"nextjs-*\", \"react-*\"]\r\n\r\n  monorepo_api:\r\n    root: \"packages/api\"\r\n    include: [\"fastapi-*\", \"python-*\"]\r\n\r\n  monorepo_shared:\r\n    root: \"packages/shared\"\r\n    include: [\"typescript.mdc\", \"clean-code.mdc\"]\r\n```\r\n\r\n## Version Checking\r\n\r\n### Overview\r\n\r\nThe rule-selector skill relies on the rule index (`.claude/context/rule-index.json`) for dynamic rule discovery. To ensure compatibility, the skill validates the index version before use.\r\n\r\n### Version Compatibility Rules\r\n\r\n**Semantic Versioning** (MAJOR.MINOR.PATCH):\r\n- **MAJOR**: Breaking changes to index structure (must match exactly)\r\n- **MINOR**: New features/rules added (backward compatible, skill requires minimum)\r\n- **PATCH**: Bug fixes and re-indexing (always compatible)\r\n\r\n**Compatibility Check**:\r\n```javascript\r\n// Skill requires: 1.2.0\r\n// Index version: 1.3.0 ✅ Compatible (same major, higher minor)\r\n// Index version: 1.1.0 ❌ Incompatible (lower minor version)\r\n// Index version: 2.0.0 ❌ Incompatible (different major version)\r\n```\r\n\r\n### Automatic Version Validation\r\n\r\nWhen the skill loads the rule index, it automatically:\r\n\r\n1. **Checks version compatibility** against `min_required_version` in frontmatter\r\n2. **Warns if outdated** with clear instructions to regenerate\r\n3. **Offers auto-regeneration** (if running in interactive mode)\r\n4. **Falls back gracefully** to directory scanning if index is severely outdated\r\n\r\n### Warning Message Format\r\n\r\nWhen version mismatch is detected:\r\n\r\n```\r\n⚠️  RULE INDEX VERSION MISMATCH\r\n   Current index version: 1.0.0\r\n   Required version: 1.2.0+\r\n\r\n   The rule index may be outdated. Please regenerate it:\r\n\r\n   Command: pnpm index-rules\r\n   Or:      node scripts/generate-rule-index.mjs\r\n\r\n   This ensures all rules are discoverable by the skill.\r\n```\r\n\r\n### Regeneration Commands\r\n\r\n**Standard Regeneration** (updates index with all current rules):\r\n```bash\r\npnpm index-rules\r\n```\r\n\r\n**Manual Regeneration** (if pnpm not available):\r\n```bash\r\nnode scripts/generate-rule-index.mjs\r\n```\r\n\r\n**Prebuilt Index** (lightweight, common stacks only):\r\n```bash\r\npnpm index-rules:prebuilt\r\n```\r\n\r\n### When to Regenerate\r\n\r\nRegenerate the rule index when:\r\n\r\n| Scenario | Reason | Command |\r\n|----------|--------|---------|\r\n| **Added new rules** | New rules won't be discoverable | `pnpm index-rules` |\r\n| **Moved rule files** | Paths in index are stale | `pnpm index-rules` |\r\n| **Updated rule metadata** | Descriptions/technologies changed | `pnpm index-rules` |\r\n| **Version mismatch warning** | Skill requires newer index | `pnpm index-rules` |\r\n| **After git pull** | Other developers may have added rules | `pnpm index-rules` |\r\n| **Index file deleted** | Need to recreate from scratch | `pnpm index-rules` |\r\n\r\n### Version Increment Guide for Maintainers\r\n\r\nWhen updating `scripts/generate-rule-index.mjs`, increment version as follows:\r\n\r\n**Major Version (X.0.0)** - Breaking Changes:\r\n```javascript\r\n// Example: Renamed field\r\nconst index = {\r\n  version: '2.0.0', // Breaking: renamed 'technology_map' to 'tech_index'\r\n  tech_index: techMap, // <- Renamed from 'technology_map'\r\n  rules: allRules\r\n};\r\n```\r\n\r\n**Minor Version (1.X.0)** - New Features (Backward Compatible):\r\n```javascript\r\n// Example: New metadata field\r\nconst index = {\r\n  version: '1.2.0', // Minor: added 'templates' metadata\r\n  rules: allRules.map(rule => ({\r\n    ...rule,\r\n    templates: extractTemplates(rule.path) // <- New field\r\n  })),\r\n  technology_map: techMap\r\n};\r\n```\r\n\r\n**Patch Version (1.0.X)** - Bug Fixes:\r\n```javascript\r\n// Example: Fixed technology detection bug\r\nfunction extractTechnologies(filePath, content) {\r\n  // Fixed: Now correctly detects 'nextjs' from 'next.js'\r\n  const normalized = tech === 'next.js' ? 'nextjs' : tech;\r\n  return normalized;\r\n}\r\n// Version: 1.0.1 (patch bump for bug fix)\r\n```\r\n\r\n### Self-Healing Index\r\n\r\nIf a requested rule is not found in the index, the skill will:\r\n\r\n1. **Log the missing rule** with file path\r\n2. **Suggest regeneration** via `pnpm index-rules`\r\n3. **Offer auto-regeneration** (if running interactively)\r\n4. **Fall back to directory scan** (if index regeneration fails)\r\n\r\nThis ensures the skill remains functional even with stale or missing indexes.\r\n\r\n### Testing Version Compatibility\r\n\r\n**Test Scenario 1: Current Index**\r\n```bash\r\n# Check current index version\r\ncat .claude/context/rule-index.json | jq '.version'\r\n# Output: \"1.1.0\"\r\n\r\n# Check skill requirements\r\ncat .claude/skills/rule-selector/SKILL.md | grep min_required_version\r\n# Output: min_required_version: 1.0.0\r\n\r\n# Result: ✅ Compatible (1.1.0 >= 1.0.0)\r\n```\r\n\r\n**Test Scenario 2: Outdated Index**\r\n```bash\r\n# Simulate outdated index (edit version to 0.9.0)\r\n# Run skill - should show warning and offer regeneration\r\n```\r\n\r\n## Best Practices\r\n\r\n1. **Run on Setup**: Always run rule-selector when starting a new project\r\n2. **Update Periodically**: Re-run after major dependency changes\r\n3. **Review Exclusions**: Check excluded rules to ensure nothing important is missed\r\n4. **Customize Priorities**: Adjust rule priority based on team preferences\r\n5. **Document Decisions**: Keep notes on why certain rules were included/excluded\r\n6. **Keep Index Fresh**: Regenerate index after adding/moving rules (`pnpm index-rules`)\r\n7. **Check Version Compatibility**: Validate index version matches skill requirements\r\n",
          "tokens": 5754
        }
      }
    },
    "explaining-rules": {
      "name": "explaining-rules",
      "one_liner": "No description",
      "key_commands": ["/identity", "/capabilities", "/context", "/rule-index", "/rules-master"],
      "token_count": {
        "minimal": 12,
        "essential": 314,
        "standard": 688,
        "full": 947
      },
      "levels": {
        "minimal": {
          "content": "**explaining-rules**: No description available",
          "tokens": 12
        },
        "essential": {
          "content": "## Skill: explaining-rules\n\nExplaining Rules - Explains applicable coding rules by querying the rule index dynamically. Discovers all 1,081+ rules without hard-coding.\n\n### Key Steps:\n: Load Rule Index\r\n\r\nLoad the complete rule index to discover all available rules:\r\n- @.claude/context/rule-index.json\r\n\r\nThe index contains metadata for all rules in `.claude/rules-master/` and `.claude/archive/`.\r\n\r\n**Note**: If the index is empty or missing, it needs to be generated first:\r\n- Run `pnpm index-rules` or `node scripts/generate-rule-index.mjs`\r\n- This scans all rules and creates the index file\r\n\r\n\n### Step: Analyze Target File or Query\r\n\r\nDetermine what needs explanation:\r\n- **File path**: Analyze file extension, imports, and directory structure\r\n- **Technology stack**: User mentions specific technologies\r\n- **General query**: User asks about rules in general\r\n\r\n\n### Step: Detect Technologies\r\n\r\nFor file-based queries, detect technologies using:\r\n- File extension (`.tsx` → TypeScript, React)\r\n- Import statements (`next` → Next.js, `react` → React)\r\n- Directory structure (`app/` → Next.js App Router)\r\n- Framework-specific patterns\r\n\r\nSee [reference/technology-detection.md](reference/technology-detection.md) for detailed detection patterns.",
          "tokens": 314
        },
        "standard": {
          "content": "## Skill: explaining-rules\n\nExplaining Rules - Explains applicable coding rules by querying the rule index dynamically. Discovers all 1,081+ rules without hard-coding.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Load Rule Index\r\n\r\nLoad the complete rule index to discover all available rules:\r\n- @.claude/context/rule-index.json\r\n\r\nThe index contains metadata for all rules in `.claude/rules-master/` and `.claude/archive/`.\r\n\r\n**Note**: If the index is empty or missing, it needs to be generated first:\r\n- Run `pnpm index-rules` or `node scripts/generate-rule-index.mjs`\r\n- This scans all rules and creates the index file\r\n\r\n### Step 2: Analyze Target File or Query\r\n\r\nDetermine what needs explanation:\r\n- **File path**: Analyze file extension, imports, and directory structure\r\n- **Technology stack**: User mentions specific technologies\r\n- **General query**: User asks about rules in general\r\n\r\n### Step 3: Detect Technologies\r\n\r\nFor file-based queries, detect technologies using:\r\n- File extension (`.tsx` → TypeScript, React)\r\n- Import statements (`next` → Next.js, `react` → React)\r\n- Directory structure (`app/` → Next.js App Router)\r\n- Framework-specific patterns\r\n\r\nSee [reference/technology-detection.md](reference/technology-detection.md) for detailed detection patterns.\r\n\r\n### Step 4: Query Rule Index\r\n\r\nUse the index's `technology_map` to find relevant rules:\r\n\r\n```javascript\r\n// Pseudocode\r\nconst detectedTech = ['nextjs', 'react', 'typescript'];\r\nconst relevantRules = [];\r\n\r\ndetectedTech.forEach(tech => {\r\n  const rules = index.technology_map[tech] || [];\r\n  relevantRules.push(...rules);\r\n});\r\n\r\n// Remove duplicates\r\nconst uniqueRules = [...new Set(relevantRules)];\r\n```\r\n\r\n### Step 5: Load Relevant Rules\r\n\r\nLoad only the relevant rule files (progressive disclosure):\r\n- Master rules take priority (from `.claude/rules-master/`)\r\n- Archive rules supplement (from `.claude/archive/`)\r\n- Load 5-10 most relevant rules, not all 1,081\r\n\r\n### Step 6: Explain Rules\r\n\r\nFor each relevant rule, explain:\r\n- **What it covers**: Main purpose and scope\r\n- **Why it applies**: Connection to the file/query\r\n- **Key requirements**: Most important standards\r\n- **Examples**: Code examples showing compliance\r\n\r\nUse the template in [reference/rule-explanation-template.md](reference/rule-explanation-template.md) for consistent output.\r\n</execution_process>\r\n\r\n<best_practices>\r\n1. **Be Specific**: Explain why each rule applies, not just what it says\r\n2. **Prioritize**: Master rules first, then archive rules\r\n3. **Use Examples**: Show code examples from the rule files\r\n4. **Progressive Disclosure**: Load only relevant rules, not all 1,081\r\n5. **Context-Aware**: Adapt explanation to user's experience level\r\n</best_practices>\n",
          "tokens": 688
        },
        "full": {
          "content": "---\r\nname: explaining-rules\r\ndescription: Explains which coding rules apply to files and why they matter. Uses the rule index to discover all available rules dynamically. Use when the user asks about rules, coding standards, or best practices.\r\n---\r\n\r\n<identity>\r\nExplaining Rules - Explains applicable coding rules by querying the rule index dynamically. Discovers all 1,081+ rules without hard-coding.\r\n</identity>\r\n\r\n<capabilities>\r\n- User asks \"What rules apply to this file?\"\r\n- Explaining coding standards to team members\r\n- Onboarding new developers\r\n- Understanding rule coverage for a project\r\n- Reviewing which rules are active\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Load Rule Index\r\n\r\nLoad the complete rule index to discover all available rules:\r\n- @.claude/context/rule-index.json\r\n\r\nThe index contains metadata for all rules in `.claude/rules-master/` and `.claude/archive/`.\r\n\r\n**Note**: If the index is empty or missing, it needs to be generated first:\r\n- Run `pnpm index-rules` or `node scripts/generate-rule-index.mjs`\r\n- This scans all rules and creates the index file\r\n\r\n### Step 2: Analyze Target File or Query\r\n\r\nDetermine what needs explanation:\r\n- **File path**: Analyze file extension, imports, and directory structure\r\n- **Technology stack**: User mentions specific technologies\r\n- **General query**: User asks about rules in general\r\n\r\n### Step 3: Detect Technologies\r\n\r\nFor file-based queries, detect technologies using:\r\n- File extension (`.tsx` → TypeScript, React)\r\n- Import statements (`next` → Next.js, `react` → React)\r\n- Directory structure (`app/` → Next.js App Router)\r\n- Framework-specific patterns\r\n\r\nSee [reference/technology-detection.md](reference/technology-detection.md) for detailed detection patterns.\r\n\r\n### Step 4: Query Rule Index\r\n\r\nUse the index's `technology_map` to find relevant rules:\r\n\r\n```javascript\r\n// Pseudocode\r\nconst detectedTech = ['nextjs', 'react', 'typescript'];\r\nconst relevantRules = [];\r\n\r\ndetectedTech.forEach(tech => {\r\n  const rules = index.technology_map[tech] || [];\r\n  relevantRules.push(...rules);\r\n});\r\n\r\n// Remove duplicates\r\nconst uniqueRules = [...new Set(relevantRules)];\r\n```\r\n\r\n### Step 5: Load Relevant Rules\r\n\r\nLoad only the relevant rule files (progressive disclosure):\r\n- Master rules take priority (from `.claude/rules-master/`)\r\n- Archive rules supplement (from `.claude/archive/`)\r\n- Load 5-10 most relevant rules, not all 1,081\r\n\r\n### Step 6: Explain Rules\r\n\r\nFor each relevant rule, explain:\r\n- **What it covers**: Main purpose and scope\r\n- **Why it applies**: Connection to the file/query\r\n- **Key requirements**: Most important standards\r\n- **Examples**: Code examples showing compliance\r\n\r\nUse the template in [reference/rule-explanation-template.md](reference/rule-explanation-template.md) for consistent output.\r\n</execution_process>\r\n\r\n<best_practices>\r\n1. **Be Specific**: Explain why each rule applies, not just what it says\r\n2. **Prioritize**: Master rules first, then archive rules\r\n3. **Use Examples**: Show code examples from the rule files\r\n4. **Progressive Disclosure**: Load only relevant rules, not all 1,081\r\n5. **Context-Aware**: Adapt explanation to user's experience level\r\n</best_practices>\r\n</instructions>\r\n\r\n<examples>\r\n<formatting_example>\r\n**Output Format**\r\n\r\nStructure explanations clearly:\r\n\r\n```markdown\r\n## Rules Applicable to [file/query]\r\n\r\n**Technologies Detected**: [list]\r\n\r\n### Master Rules (Always Active)\r\n- **[Rule Name]**: [brief description]\r\n  - **Applies because**: [reason]\r\n  - **Key requirements**: [list]\r\n  - **Example**: [code snippet]\r\n\r\n### Archive Rules (On-Demand)\r\n- **[Rule Name]**: [brief description]\r\n  - **When to use**: [context]\r\n  - **Key points**: [list]\r\n```\r\n</formatting_example>\r\n</examples>\r\n\r\n",
          "tokens": 947
        }
      }
    },
    "migrating-rules": {
      "name": "migrating-rules",
      "one_liner": "No description",
      "key_commands": [
        "/identity",
        "/capabilities",
        "/context",
        "/rule-index",
        "/migration-patterns"
      ],
      "token_count": {
        "minimal": 12,
        "essential": 207,
        "standard": 489,
        "full": 1118
      },
      "levels": {
        "minimal": {
          "content": "**migrating-rules**: No description available",
          "tokens": 12
        },
        "essential": {
          "content": "## Skill: migrating-rules\n\nMigrating Rules - Helps migrate code when rules are updated or when switching between framework versions by comparing rule differences.\n\n### Key Steps:\n: Identify Migration Context\r\n\r\nDetermine what needs migration:\r\n- **Rule version update**: Same framework, updated rules\r\n- **Framework migration**: Different framework (e.g., Pages Router → App Router)\r\n- **Standard update**: Coding standards changed\r\n- **Technology change**: New technology added to stack\r\n\r\n\n### Step: Load Rule Index\r\n\r\nLoad the rule index to find relevant rules:\r\n- @.claude/context/rule-index.json\r\n\r\n\n### Step: Identify Source and Target Rules\r\n\r\nFind the rules involved in migration:\r\n- **Source rule**: Current rule being used\r\n- **Target rule**: New rule to migrate to\r\n- **Both rules**: If migrating between frameworks",
          "tokens": 207
        },
        "standard": {
          "content": "## Skill: migrating-rules\n\nMigrating Rules - Helps migrate code when rules are updated or when switching between framework versions by comparing rule differences.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Identify Migration Context\r\n\r\nDetermine what needs migration:\r\n- **Rule version update**: Same framework, updated rules\r\n- **Framework migration**: Different framework (e.g., Pages Router → App Router)\r\n- **Standard update**: Coding standards changed\r\n- **Technology change**: New technology added to stack\r\n\r\n### Step 2: Load Rule Index\r\n\r\nLoad the rule index to find relevant rules:\r\n- @.claude/context/rule-index.json\r\n\r\n### Step 3: Identify Source and Target Rules\r\n\r\nFind the rules involved in migration:\r\n- **Source rule**: Current rule being used\r\n- **Target rule**: New rule to migrate to\r\n- **Both rules**: If migrating between frameworks\r\n\r\n### Step 4: Load Rule Files\r\n\r\nLoad both source and target rule files:\r\n- Read source rule file\r\n- Read target rule file\r\n- Compare differences\r\n\r\n### Step 5: Analyze Differences\r\n\r\nCompare rules to identify:\r\n- **Removed patterns**: What's no longer allowed\r\n- **New patterns**: What's now required\r\n- **Changed patterns**: What's been modified\r\n- **Breaking changes**: Incompatible changes\r\n\r\nSee [reference/migration-patterns.md](reference/migration-patterns.md) for common migration patterns.\r\n\r\n### Step 6: Generate Migration Plan\r\n\r\nCreate step-by-step migration plan:\r\n- **Inventory**: List all files affected\r\n- **Priority**: Order of migration (critical first)\r\n- **Steps**: Specific code changes needed\r\n- **Verification**: How to verify migration success\r\n</execution_process>\r\n\r\n<best_practices>\r\n1. **Be Comprehensive**: Identify all affected code\r\n2. **Prioritize**: Critical changes first\r\n3. **Show Examples**: Before/after code for each change\r\n4. **Step-by-Step**: Break complex migrations into clear steps\r\n5. **Verify**: Include verification steps\r\n</best_practices>\n",
          "tokens": 489
        },
        "full": {
          "content": "---\r\nname: migrating-rules\r\ndescription: Helps migrate code when updating to new rule versions. Compares rule versions from the index and generates migration plans. Use when rules are updated or when migrating between framework versions.\r\n---\r\n\r\n<identity>\r\nMigrating Rules - Helps migrate code when rules are updated or when switching between framework versions by comparing rule differences.\r\n</identity>\r\n\r\n<capabilities>\r\n- Rules are updated to new versions\r\n- Migrating from one framework to another (e.g., Next.js 14 → 15)\r\n- Updating coding standards\r\n- User asks \"How do I update my code for the new rules?\"\r\n- Rule changes require code modifications\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Identify Migration Context\r\n\r\nDetermine what needs migration:\r\n- **Rule version update**: Same framework, updated rules\r\n- **Framework migration**: Different framework (e.g., Pages Router → App Router)\r\n- **Standard update**: Coding standards changed\r\n- **Technology change**: New technology added to stack\r\n\r\n### Step 2: Load Rule Index\r\n\r\nLoad the rule index to find relevant rules:\r\n- @.claude/context/rule-index.json\r\n\r\n### Step 3: Identify Source and Target Rules\r\n\r\nFind the rules involved in migration:\r\n- **Source rule**: Current rule being used\r\n- **Target rule**: New rule to migrate to\r\n- **Both rules**: If migrating between frameworks\r\n\r\n### Step 4: Load Rule Files\r\n\r\nLoad both source and target rule files:\r\n- Read source rule file\r\n- Read target rule file\r\n- Compare differences\r\n\r\n### Step 5: Analyze Differences\r\n\r\nCompare rules to identify:\r\n- **Removed patterns**: What's no longer allowed\r\n- **New patterns**: What's now required\r\n- **Changed patterns**: What's been modified\r\n- **Breaking changes**: Incompatible changes\r\n\r\nSee [reference/migration-patterns.md](reference/migration-patterns.md) for common migration patterns.\r\n\r\n### Step 6: Generate Migration Plan\r\n\r\nCreate step-by-step migration plan:\r\n- **Inventory**: List all files affected\r\n- **Priority**: Order of migration (critical first)\r\n- **Steps**: Specific code changes needed\r\n- **Verification**: How to verify migration success\r\n</execution_process>\r\n\r\n<best_practices>\r\n1. **Be Comprehensive**: Identify all affected code\r\n2. **Prioritize**: Critical changes first\r\n3. **Show Examples**: Before/after code for each change\r\n4. **Step-by-Step**: Break complex migrations into clear steps\r\n5. **Verify**: Include verification steps\r\n</best_practices>\r\n</instructions>\r\n\r\n<examples>\r\n<formatting_example>\r\n**Migration Plan Format**\r\n\r\nStructure migration plan clearly:\r\n\r\n```markdown\r\n## Migration Plan: [Source] → [Target]\r\n\r\n**Migration Type**: [Rule update / Framework migration / Standard update]\r\n**Affected Files**: [count]\r\n**Estimated Effort**: [low/medium/high]\r\n\r\n### Overview\r\n\r\n**Source Rule**: [rule name and path]\r\n**Target Rule**: [rule name and path]\r\n**Key Changes**: [summary of main differences]\r\n\r\n### Breaking Changes\r\n\r\n#### [Change 1]\r\n**Impact**: [high/medium/low]\r\n**Description**: [what changed]\r\n\r\n**Before**:\r\n\\`\\`\\`[language]\r\n[old code pattern]\r\n\\`\\`\\`\r\n\r\n**After**:\r\n\\`\\`\\`[language]\r\n[new code pattern]\r\n\\`\\`\\`\r\n\r\n**Migration Steps**:\r\n1. [Step 1]\r\n2. [Step 2]\r\n3. [Step 3]\r\n\r\n---\r\n\r\n### New Requirements\r\n\r\n#### [Requirement 1]\r\n**Description**: [new requirement]\r\n\r\n**Action Required**:\r\n[What needs to be done]\r\n\r\n**Example**:\r\n\\`\\`\\`[language]\r\n[code example]\r\n\\`\\`\\`\r\n\r\n---\r\n\r\n### Deprecated Patterns\r\n\r\n#### [Pattern 1]\r\n**Status**: Deprecated\r\n**Replacement**: [new pattern]\r\n\r\n**Migration**:\r\n\\`\\`\\`[language]\r\n// Old (deprecated)\r\n[old code]\r\n\r\n// New (recommended)\r\n[new code]\r\n\\`\\`\\`\r\n\r\n---\r\n\r\n### Migration Checklist\r\n\r\n- [ ] Step 1: [action]\r\n- [ ] Step 2: [action]\r\n- [ ] Step 3: [action]\r\n- [ ] Verification: [how to verify]\r\n\r\n### Verification\r\n\r\n[How to verify migration is complete and correct]\r\n```\r\n</formatting_example>\r\n</examples>\r\n\r\n<examples>\r\n<code_example>\r\n**Common Migration Scenarios**:\r\n\r\n**Next.js 14 → 15**:\r\n- App Router changes\r\n- React 19 features\r\n- Server Component patterns\r\n\r\n**Pages Router → App Router**:\r\n- Route structure changes\r\n- Data fetching patterns\r\n- Layout changes\r\n\r\n**TypeScript Strict Mode**:\r\n- Type safety improvements\r\n- `any` → proper types\r\n- Null checking\r\n\r\n**Python 3.10 → 3.12**:\r\n- Type hint improvements\r\n- Pattern matching\r\n- Performance optimizations\r\n\r\nFor each scenario, see migration-patterns.md for detailed patterns.\r\n</code_example>\r\n</examples>\r\n\r\n",
          "tokens": 1118
        }
      }
    },
    "recommending-rules": {
      "name": "recommending-rules",
      "one_liner": "No description",
      "key_commands": [
        "/identity",
        "/capabilities",
        "/context",
        "/rule-index",
        "/coverage-analysis"
      ],
      "token_count": {
        "minimal": 12,
        "essential": 248,
        "standard": 544,
        "full": 1049
      },
      "levels": {
        "minimal": {
          "content": "**recommending-rules**: No description available",
          "tokens": 12
        },
        "essential": {
          "content": "## Skill: recommending-rules\n\nRecommending Rules - Analyzes codebase to identify gaps in rule coverage by comparing against all indexed rules.\n\n### Key Steps:\n: Load Rule Index\r\n\r\nLoad the complete rule index:\r\n- @.claude/context/rule-index.json\r\n\r\nThis contains all 1,081+ available rules.\r\n\r\n\n### Step: Analyze Codebase\r\n\r\nScan the codebase to identify technologies used:\r\n- **File extensions**: `.tsx`, `.py`, `.sol`, etc.\r\n- **Package files**: `package.json`, `requirements.txt`, `Cargo.toml`\r\n- **Framework files**: `next.config.js`, `fastapi` imports, etc.\r\n- **Directory structure**: `app/`, `components/`, `routers/`, etc.\r\n\r\nSee [reference/coverage-analysis.md](reference/coverage-analysis.md) for detailed analysis patterns.\r\n\r\n\n### Step: Identify Technologies\r\n\r\nExtract technologies from codebase:\r\n- Primary languages (TypeScript, Python, etc.)\r\n- Frameworks (Next.js, FastAPI, etc.)\r\n- Testing tools (Cypress, Playwright, Jest, etc.)\r\n- Build tools (Docker, Kubernetes, etc.)",
          "tokens": 248
        },
        "standard": {
          "content": "## Skill: recommending-rules\n\nRecommending Rules - Analyzes codebase to identify gaps in rule coverage by comparing against all indexed rules.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Load Rule Index\r\n\r\nLoad the complete rule index:\r\n- @.claude/context/rule-index.json\r\n\r\nThis contains all 1,081+ available rules.\r\n\r\n### Step 2: Analyze Codebase\r\n\r\nScan the codebase to identify technologies used:\r\n- **File extensions**: `.tsx`, `.py`, `.sol`, etc.\r\n- **Package files**: `package.json`, `requirements.txt`, `Cargo.toml`\r\n- **Framework files**: `next.config.js`, `fastapi` imports, etc.\r\n- **Directory structure**: `app/`, `components/`, `routers/`, etc.\r\n\r\nSee [reference/coverage-analysis.md](reference/coverage-analysis.md) for detailed analysis patterns.\r\n\r\n### Step 3: Identify Technologies\r\n\r\nExtract technologies from codebase:\r\n- Primary languages (TypeScript, Python, etc.)\r\n- Frameworks (Next.js, FastAPI, etc.)\r\n- Testing tools (Cypress, Playwright, Jest, etc.)\r\n- Build tools (Docker, Kubernetes, etc.)\r\n\r\n### Step 4: Query Rule Index\r\n\r\nFor each detected technology, query the index:\r\n- Use `technology_map` to find all rules for each technology\r\n- Collect all potentially relevant rules\r\n- Remove duplicates\r\n\r\n### Step 5: Compare with Active Rules\r\n\r\nCheck which rules are currently active:\r\n- Check `.claude/rules/manifest.yaml` for loaded rules\r\n- Check `.claude/config.yaml` for agent-specific rules\r\n- Identify which indexed rules are NOT currently loaded\r\n\r\n### Step 6: Generate Recommendations\r\n\r\nFor each missing rule, provide:\r\n- **Rule name and description**: From index metadata\r\n- **Why it's relevant**: Connection to codebase technologies\r\n- **Priority**: High/Medium/Low based on codebase usage\r\n- **How to activate**: Instructions for loading the rule\r\n</execution_process>\r\n\r\n<best_practices>\r\n1. **Be Specific**: Explain why each rule is relevant\r\n2. **Prioritize**: High priority for core technologies, low for edge cases\r\n3. **Provide Context**: Show how rule connects to codebase\r\n4. **Actionable**: Include clear activation instructions\r\n5. **Comprehensive**: Check all technologies, not just obvious ones\r\n</best_practices>\n",
          "tokens": 544
        },
        "full": {
          "content": "---\r\nname: recommending-rules\r\ndescription: Analyzes codebase to find gaps in rule coverage and suggests rule improvements. Compares codebase against all indexed rules to identify missing standards. Use when setting up new projects or reviewing rule coverage.\r\n---\r\n\r\n<identity>\r\nRecommending Rules - Analyzes codebase to identify gaps in rule coverage by comparing against all indexed rules.\r\n</identity>\r\n\r\n<capabilities>\r\n- Setting up a new project\r\n- Reviewing rule coverage for existing project\r\n- User asks \"What rules should I use?\"\r\n- Identifying missing standards\r\n- Project uses technologies without corresponding rules\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Load Rule Index\r\n\r\nLoad the complete rule index:\r\n- @.claude/context/rule-index.json\r\n\r\nThis contains all 1,081+ available rules.\r\n\r\n### Step 2: Analyze Codebase\r\n\r\nScan the codebase to identify technologies used:\r\n- **File extensions**: `.tsx`, `.py`, `.sol`, etc.\r\n- **Package files**: `package.json`, `requirements.txt`, `Cargo.toml`\r\n- **Framework files**: `next.config.js`, `fastapi` imports, etc.\r\n- **Directory structure**: `app/`, `components/`, `routers/`, etc.\r\n\r\nSee [reference/coverage-analysis.md](reference/coverage-analysis.md) for detailed analysis patterns.\r\n\r\n### Step 3: Identify Technologies\r\n\r\nExtract technologies from codebase:\r\n- Primary languages (TypeScript, Python, etc.)\r\n- Frameworks (Next.js, FastAPI, etc.)\r\n- Testing tools (Cypress, Playwright, Jest, etc.)\r\n- Build tools (Docker, Kubernetes, etc.)\r\n\r\n### Step 4: Query Rule Index\r\n\r\nFor each detected technology, query the index:\r\n- Use `technology_map` to find all rules for each technology\r\n- Collect all potentially relevant rules\r\n- Remove duplicates\r\n\r\n### Step 5: Compare with Active Rules\r\n\r\nCheck which rules are currently active:\r\n- Check `.claude/rules/manifest.yaml` for loaded rules\r\n- Check `.claude/config.yaml` for agent-specific rules\r\n- Identify which indexed rules are NOT currently loaded\r\n\r\n### Step 6: Generate Recommendations\r\n\r\nFor each missing rule, provide:\r\n- **Rule name and description**: From index metadata\r\n- **Why it's relevant**: Connection to codebase technologies\r\n- **Priority**: High/Medium/Low based on codebase usage\r\n- **How to activate**: Instructions for loading the rule\r\n</execution_process>\r\n\r\n<best_practices>\r\n1. **Be Specific**: Explain why each rule is relevant\r\n2. **Prioritize**: High priority for core technologies, low for edge cases\r\n3. **Provide Context**: Show how rule connects to codebase\r\n4. **Actionable**: Include clear activation instructions\r\n5. **Comprehensive**: Check all technologies, not just obvious ones\r\n</best_practices>\r\n</instructions>\r\n\r\n<examples>\r\n<formatting_example>\r\n**Output Format**\r\n\r\nStructure recommendations clearly:\r\n\r\n```markdown\r\n## Rule Coverage Analysis\r\n\r\n**Codebase Technologies**: [list]\r\n**Currently Active Rules**: [count]\r\n**Recommended Rules**: [count]\r\n\r\n### High Priority Recommendations\r\n\r\n#### [Rule Name]\r\n**Path**: [path from index]\r\n**Type**: [master/archive]\r\n**Relevance**: [why it applies]\r\n**Priority**: High\r\n\r\n**Description**: [from index metadata]\r\n\r\n**Why You Need This**:\r\n[Explanation of why this rule is important for your codebase]\r\n\r\n**How to Activate**:\r\n[Instructions for loading the rule]\r\n\r\n---\r\n\r\n### Medium Priority Recommendations\r\n\r\n[Similar structure]\r\n\r\n---\r\n\r\n### Low Priority Recommendations\r\n\r\n[Similar structure]\r\n\r\n### Summary\r\n- **Total rules available**: [count]\r\n- **Rules currently active**: [count]\r\n- **Rules recommended**: [count]\r\n- **Coverage gap**: [percentage]\r\n```\r\n</formatting_example>\r\n</examples>\r\n\r\n<examples>\r\n<code_example>\r\n**Recommendation Criteria**:\r\n\r\n**High Priority**:\r\n- Core framework rules (Next.js, React, TypeScript for TS projects)\r\n- Universal standards (PROTOCOL_ENGINEERING)\r\n- Testing rules matching test framework used\r\n- Security rules for production code\r\n\r\n**Medium Priority**:\r\n- Framework-specific optimizations\r\n- Code style rules for secondary languages\r\n- Tool-specific rules (Docker, CI/CD)\r\n\r\n**Low Priority**:\r\n- Niche technology rules\r\n- Deprecated framework rules\r\n- Rules for unused features\r\n</code_example>\r\n</examples>\r\n\r\n",
          "tokens": 1049
        }
      }
    },
    "git": {
      "name": "git",
      "one_liner": "Git repository operations - status, diff, commit, branch, log. Converted from MCP server for 90%+ context savings.",
      "key_commands": ["/new-feature", "/index", "/new-file", "/updating", "/description"],
      "token_count": {
        "minimal": 31,
        "essential": 33,
        "standard": 33,
        "full": 3830
      },
      "levels": {
        "minimal": {
          "content": "**git**: Git repository operations - status, diff, commit, branch, log. Converted from MCP server for 90%+ context savings.",
          "tokens": 31
        },
        "essential": {
          "content": "## Skill: git\n\nGit repository operations - status, diff, commit, branch, log. Converted from MCP server for 90%+ context savings.\n",
          "tokens": 33
        },
        "standard": {
          "content": "## Skill: git\n\nGit repository operations - status, diff, commit, branch, log. Converted from MCP server for 90%+ context savings.\n",
          "tokens": 33
        },
        "full": {
          "content": "---\nname: git\ndescription: Git repository operations - status, diff, commit, branch, log. Converted from MCP server for 90%+ context savings.\nallowed-tools: read, write, bash\nversion: 1.0\nbest_practices:\n  - Check status before committing to see what will be committed\n  - Use git_diff_staged to review changes before committing\n  - Write clear, descriptive commit messages\n  - Create branches for new features or fixes\n  - Use git_log to understand commit history\nerror_handling: graceful\nstreaming: supported\n---\n\n# Git Skill\n\n## Overview\n\nThis skill provides comprehensive Git operations through a local MCP server. It enables version control management including status checking, staging, committing, branching, diffing, and history viewing.\n\n**Context Savings**: ~98% reduction\n- **MCP Mode**: ~25,000 tokens always loaded\n- **Skill Mode**: ~500 tokens metadata + on-demand loading\n\n## When to Use\n\n- Check repository status and see what files have changed\n- Stage files for commit\n- Create commits with messages\n- View differences between commits, branches, or working tree\n- Create and switch between branches\n- View commit history with flexible filtering\n- Inspect specific commits\n- Reset staged changes\n\n## Quick Reference\n\n```bash\n# List available tools\npython executor.py --list\n\n# Check repository status\npython executor.py --tool git_status --args '{\"repo_path\": \".\"}'\n\n# View unstaged changes\npython executor.py --tool git_diff_unstaged --args '{\"repo_path\": \".\"}'\n\n# View staged changes\npython executor.py --tool git_diff_staged --args '{\"repo_path\": \".\"}'\n\n# Stage files\npython executor.py --tool git_add --args '{\"repo_path\": \".\", \"files\": [\"file1.ts\", \"file2.ts\"]}'\n\n# Commit changes\npython executor.py --tool git_commit --args '{\"repo_path\": \".\", \"message\": \"feat: add new feature\"}'\n\n# View commit log\npython executor.py --tool git_log --args '{\"repo_path\": \".\", \"max_count\": 10}'\n\n# Create branch\npython executor.py --tool git_create_branch --args '{\"repo_path\": \".\", \"branch_name\": \"feature/new-feature\"}'\n\n# Switch branch\npython executor.py --tool git_checkout --args '{\"repo_path\": \".\", \"branch_name\": \"main\"}'\n```\n\n## Tools\n\n### git_status\n\nShows the working tree status - which files are modified, staged, or untracked.\n\n**Parameters:**\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `repo_path` | string | Yes | Path to the git repository |\n\n**Example:**\n```bash\npython executor.py --tool git_status --args '{\"repo_path\": \".\"}'\n```\n\n**Returns:**\n```\nOn branch main\nChanges not staged for commit:\n  modified:   src/index.ts\n\nUntracked files:\n  src/new-file.ts\n```\n\n---\n\n### git_diff_unstaged\n\nShows changes in the working directory that are not yet staged.\n\n**Parameters:**\n\n| Parameter | Type | Required | Default | Description |\n|-----------|------|----------|---------|-------------|\n| `repo_path` | string | Yes | - | Path to the git repository |\n| `context_lines` | integer | No | 3 | Number of context lines around changes |\n\n**Example:**\n```bash\npython executor.py --tool git_diff_unstaged --args '{\"repo_path\": \".\", \"context_lines\": 5}'\n```\n\n**Returns:**\nUnified diff format showing line-by-line changes in unstaged files.\n\n---\n\n### git_diff_staged\n\nShows changes that are staged for commit.\n\n**Parameters:**\n\n| Parameter | Type | Required | Default | Description |\n|-----------|------|----------|---------|-------------|\n| `repo_path` | string | Yes | - | Path to the git repository |\n| `context_lines` | integer | No | 3 | Number of context lines around changes |\n\n**Example:**\n```bash\npython executor.py --tool git_diff_staged --args '{\"repo_path\": \".\"}'\n```\n\n**Returns:**\nUnified diff format showing line-by-line changes in staged files.\n\n---\n\n### git_diff\n\nShows differences between branches, commits, or other targets.\n\n**Parameters:**\n\n| Parameter | Type | Required | Default | Description |\n|-----------|------|----------|---------|-------------|\n| `repo_path` | string | Yes | - | Path to the git repository |\n| `target` | string | Yes | - | Branch name, commit SHA, or diff target (e.g., \"main\", \"HEAD~1\") |\n| `context_lines` | integer | No | 3 | Number of context lines around changes |\n\n**Example:**\n```bash\n# Compare current branch to main\npython executor.py --tool git_diff --args '{\"repo_path\": \".\", \"target\": \"main\"}'\n\n# Compare to previous commit\npython executor.py --tool git_diff --args '{\"repo_path\": \".\", \"target\": \"HEAD~1\"}'\n\n# Compare two commits\npython executor.py --tool git_diff --args '{\"repo_path\": \".\", \"target\": \"abc123..def456\"}'\n```\n\n**Returns:**\nUnified diff format showing differences between current state and target.\n\n---\n\n### git_add\n\nAdds file contents to the staging area.\n\n**Parameters:**\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `repo_path` | string | Yes | Path to the git repository |\n| `files` | array | Yes | List of file paths to stage (relative to repo root) |\n\n**Example:**\n```bash\n# Stage specific files\npython executor.py --tool git_add --args '{\"repo_path\": \".\", \"files\": [\"src/index.ts\", \"README.md\"]}'\n\n# Stage all files (use \".\" in files array)\npython executor.py --tool git_add --args '{\"repo_path\": \".\", \"files\": [\".\"]}'\n```\n\n---\n\n### git_commit\n\nRecords changes to the repository with a commit message.\n\n**Parameters:**\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `repo_path` | string | Yes | Path to the git repository |\n| `message` | string | Yes | Commit message |\n\n**Example:**\n```bash\npython executor.py --tool git_commit --args '{\"repo_path\": \".\", \"message\": \"feat: add user authentication\"}'\n```\n\n**Best Practices:**\n- Use conventional commit format: `type: description`\n- Common types: `feat`, `fix`, `docs`, `refactor`, `test`, `chore`\n- Keep first line under 72 characters\n- Add detailed description in multi-line messages\n\n---\n\n### git_reset\n\nUnstages all staged changes (does not modify working directory).\n\n**Parameters:**\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `repo_path` | string | Yes | Path to the git repository |\n\n**Example:**\n```bash\npython executor.py --tool git_reset --args '{\"repo_path\": \".\"}'\n```\n\n**Note:** This is equivalent to `git reset HEAD` - it unstages files but preserves working directory changes.\n\n---\n\n### git_log\n\nShows the commit logs with flexible filtering options.\n\n**Parameters:**\n\n| Parameter | Type | Required | Default | Description |\n|-----------|------|----------|---------|-------------|\n| `repo_path` | string | Yes | - | Path to the git repository |\n| `max_count` | integer | No | 10 | Maximum number of commits to show |\n| `start_timestamp` | string | No | null | Start timestamp for filtering commits |\n| `end_timestamp` | string | No | null | End timestamp for filtering commits |\n\n**Timestamp Formats:**\n- ISO 8601: `\"2024-01-15T14:30:25\"`\n- Relative: `\"2 weeks ago\"`, `\"yesterday\"`\n- Absolute: `\"2024-01-15\"`, `\"Jan 15 2024\"`\n\n**Example:**\n```bash\n# Last 10 commits\npython executor.py --tool git_log --args '{\"repo_path\": \".\", \"max_count\": 10}'\n\n# Last 20 commits\npython executor.py --tool git_log --args '{\"repo_path\": \".\", \"max_count\": 20}'\n\n# Commits from last week\npython executor.py --tool git_log --args '{\"repo_path\": \".\", \"start_timestamp\": \"1 week ago\"}'\n\n# Commits in date range\npython executor.py --tool git_log --args '{\"repo_path\": \".\", \"start_timestamp\": \"2024-01-01\", \"end_timestamp\": \"2024-01-31\"}'\n```\n\n**Returns:**\n```\ncommit abc123def456...\nAuthor: Name <email@example.com>\nDate: Mon Jan 15 14:30:25 2024\n\n    feat: add new feature\n```\n\n---\n\n### git_create_branch\n\nCreates a new branch from an optional base branch.\n\n**Parameters:**\n\n| Parameter | Type | Required | Default | Description |\n|-----------|------|----------|---------|-------------|\n| `repo_path` | string | Yes | - | Path to the git repository |\n| `branch_name` | string | Yes | - | Name for the new branch |\n| `base_branch` | string | No | null | Branch to create from (defaults to current branch) |\n\n**Example:**\n```bash\n# Create branch from current branch\npython executor.py --tool git_create_branch --args '{\"repo_path\": \".\", \"branch_name\": \"feature/new-feature\"}'\n\n# Create branch from specific base\npython executor.py --tool git_create_branch --args '{\"repo_path\": \".\", \"branch_name\": \"feature/new-feature\", \"base_branch\": \"main\"}'\n```\n\n---\n\n### git_checkout\n\nSwitches branches.\n\n**Parameters:**\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `repo_path` | string | Yes | Path to the git repository |\n| `branch_name` | string | Yes | Name of branch to switch to |\n\n**Example:**\n```bash\npython executor.py --tool git_checkout --args '{\"repo_path\": \".\", \"branch_name\": \"main\"}'\n```\n\n**Note:** Branch must already exist. Use `git_create_branch` to create a new branch.\n\n---\n\n### git_show\n\nShows the contents of a specific commit.\n\n**Parameters:**\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `repo_path` | string | Yes | Path to the git repository |\n| `revision` | string | Yes | Commit SHA, branch name, or revision (e.g., \"HEAD\", \"HEAD~1\", \"abc123\") |\n\n**Example:**\n```bash\n# Show latest commit\npython executor.py --tool git_show --args '{\"repo_path\": \".\", \"revision\": \"HEAD\"}'\n\n# Show specific commit\npython executor.py --tool git_show --args '{\"repo_path\": \".\", \"revision\": \"abc123def456\"}'\n\n# Show commit 2 commits ago\npython executor.py --tool git_show --args '{\"repo_path\": \".\", \"revision\": \"HEAD~2\"}'\n```\n\n**Returns:**\nCommit metadata (author, date, message) and full diff of changes.\n\n---\n\n### git_branch\n\nList Git branches with filtering options.\n\n**Parameters:**\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `repo_path` | string | Yes | Path to the git repository |\n| `branch_type` | string | Yes | Type of branches to list: `\"local\"`, `\"remote\"`, or `\"all\"` |\n| `contains` | string | No | Only list branches containing this commit SHA |\n| `not_contains` | string | No | Only list branches NOT containing this commit SHA |\n\n**Example:**\n```bash\n# List local branches\npython executor.py --tool git_branch --args '{\"repo_path\": \".\", \"branch_type\": \"local\"}'\n\n# List remote branches\npython executor.py --tool git_branch --args '{\"repo_path\": \".\", \"branch_type\": \"remote\"}'\n\n# List all branches\npython executor.py --tool git_branch --args '{\"repo_path\": \".\", \"branch_type\": \"all\"}'\n\n# List branches containing a commit\npython executor.py --tool git_branch --args '{\"repo_path\": \".\", \"branch_type\": \"local\", \"contains\": \"abc123\"}'\n\n# List branches NOT containing a commit\npython executor.py --tool git_branch --args '{\"repo_path\": \".\", \"branch_type\": \"local\", \"not_contains\": \"abc123\"}'\n```\n\n**Returns:**\n```\n* main\n  feature/new-feature\n  develop\n```\n\n---\n\n## Common Workflows\n\n### Check Status and Commit Changes\n\n```bash\n# 1. Check what files have changed\npython executor.py --tool git_status --args '{\"repo_path\": \".\"}'\n\n# 2. View unstaged changes\npython executor.py --tool git_diff_unstaged --args '{\"repo_path\": \".\"}'\n\n# 3. Stage specific files\npython executor.py --tool git_add --args '{\"repo_path\": \".\", \"files\": [\"src/index.ts\", \"README.md\"]}'\n\n# 4. View staged changes\npython executor.py --tool git_diff_staged --args '{\"repo_path\": \".\"}'\n\n# 5. Commit with message\npython executor.py --tool git_commit --args '{\"repo_path\": \".\", \"message\": \"feat: add new feature\"}'\n```\n\n### Create Feature Branch\n\n```bash\n# 1. Check current branch\npython executor.py --tool git_status --args '{\"repo_path\": \".\"}'\n\n# 2. Create new branch from main\npython executor.py --tool git_create_branch --args '{\"repo_path\": \".\", \"branch_name\": \"feature/new-feature\", \"base_branch\": \"main\"}'\n\n# 3. Switch to new branch\npython executor.py --tool git_checkout --args '{\"repo_path\": \".\", \"branch_name\": \"feature/new-feature\"}'\n\n# 4. Make changes and commit\n# ... (stage and commit as above)\n```\n\n### View History\n\n```bash\n# 1. View recent commits\npython executor.py --tool git_log --args '{\"repo_path\": \".\", \"max_count\": 10}'\n\n# 2. Inspect specific commit\npython executor.py --tool git_show --args '{\"repo_path\": \".\", \"revision\": \"abc123\"}'\n\n# 3. Compare to another branch\npython executor.py --tool git_diff --args '{\"repo_path\": \".\", \"target\": \"main\"}'\n```\n\n### Branch Management\n\n```bash\n# 1. List all branches\npython executor.py --tool git_branch --args '{\"repo_path\": \".\", \"branch_type\": \"all\"}'\n\n# 2. Check which branches contain a commit\npython executor.py --tool git_branch --args '{\"repo_path\": \".\", \"branch_type\": \"local\", \"contains\": \"abc123\"}'\n\n# 3. Switch to different branch\npython executor.py --tool git_checkout --args '{\"repo_path\": \".\", \"branch_name\": \"develop\"}'\n```\n\n### Reset Staged Changes\n\n```bash\n# 1. Check what's staged\npython executor.py --tool git_diff_staged --args '{\"repo_path\": \".\"}'\n\n# 2. Unstage all files\npython executor.py --tool git_reset --args '{\"repo_path\": \".\"}'\n\n# 3. Verify reset\npython executor.py --tool git_status --args '{\"repo_path\": \".\"}'\n```\n\n## Best Practices\n\n### Commit Messages\n\n- **Use Conventional Commits**: `type: description`\n  - `feat`: New feature\n  - `fix`: Bug fix\n  - `docs`: Documentation changes\n  - `refactor`: Code refactoring\n  - `test`: Adding/updating tests\n  - `chore`: Maintenance tasks\n\n- **Keep it concise**: First line under 72 characters\n- **Be descriptive**: Explain what and why, not how\n\n### Workflow\n\n1. **Always check status first**: Know what you're committing\n2. **Review diffs before committing**: Use `git_diff_staged`\n3. **Stage selectively**: Don't use `git add .` blindly\n4. **Commit frequently**: Small, focused commits are better\n5. **Use branches**: Create feature branches for new work\n\n### Branch Naming\n\n- `feature/description` - New features\n- `fix/description` - Bug fixes\n- `refactor/description` - Code refactoring\n- `docs/description` - Documentation updates\n\n## Configuration\n\nMCP server configuration stored in `config.json`:\n- **Command**: `python`\n- **Args**: `[\"-m\", \"mcp_server_git\"]`\n\n### Requirements\n\n- Python with `mcp_server_git` package installed\n- Valid git repository at `repo_path`\n\n## Error Handling\n\n**Common Issues:**\n- **Not a git repository**: Ensure `repo_path` points to a valid git repo\n- **Nothing to commit**: Check status first, stage files before committing\n- **Merge conflicts**: Resolve conflicts before committing\n- **Branch already exists**: Use unique branch names or checkout existing branch\n\n**Recovery:**\n- Check repository status with `git_status`\n- Use `git_reset` to unstage if needed\n- Review logs with `git_log` to understand repository state\n- Verify branch exists with `git_branch` before checkout\n\n## Integration\n\n### With GitHub Skill\n\nThis skill works alongside the `github` skill:\n- **git**: Local repository operations\n- **github**: Remote GitHub operations (PRs, issues, etc.)\n\n### With Workflows\n\nCommon workflow integration:\n1. Use `git_status` to check changes\n2. Use `git_diff_staged` to review before commit\n3. Use `git_commit` to commit changes\n4. Use `github` skill to create PR\n\n## Related\n\n- Original MCP server: `python -m mcp_server_git`\n- GitHub Skill: `.claude/skills/github/`\n- MCP Converter Skill: `.claude/skills/mcp-converter/`\n- Skill Manager: `.claude/skills/skill-manager/`\n",
          "tokens": 3830
        }
      }
    },
    "github": {
      "name": "github",
      "one_liner": "No description",
      "key_commands": ["/update", "/submit", "/github", "/github-mcp-server", "/docs"],
      "token_count": {
        "minimal": 9,
        "essential": 5,
        "standard": 5,
        "full": 1365
      },
      "levels": {
        "minimal": {
          "content": "**github**: No description available",
          "tokens": 9
        },
        "essential": {
          "content": "## Skill: github\n",
          "tokens": 5
        },
        "standard": {
          "content": "## Skill: github\n",
          "tokens": 5
        },
        "full": {
          "content": "---\r\nname: github\r\ndescription: GitHub API operations - repositories, issues, pull requests, actions, code security, discussions, gists, and more. Use for GitHub-related tasks like managing PRs, issues, searching code, and monitoring workflows.\r\nallowed-tools: read, write, bash\r\n---\r\n\r\n# GitHub Skill\r\n\r\n## Overview\r\n\r\nThis skill provides access to the official GitHub MCP server with progressive disclosure for optimal context usage.\r\n\r\n**Context Savings**: ~95% reduction\r\n- **MCP Mode**: ~50,000 tokens always loaded (80+ tools)\r\n- **Skill Mode**: ~500 tokens metadata + on-demand loading\r\n\r\n## Requirements\r\n\r\n- Docker installed and running\r\n- `GITHUB_PERSONAL_ACCESS_TOKEN` environment variable set\r\n\r\n## Toolsets\r\n\r\nThe server provides 80+ tools across 19 toolsets:\r\n\r\n| Toolset | Description |\r\n|---------|-------------|\r\n| `actions` | Workflow management, runs, jobs, artifacts |\r\n| `code_security` | Scanning alerts, code analysis |\r\n| `discussions` | Forum interactions |\r\n| `gists` | Code snippets management |\r\n| `issues` | Issue creation, updates, commenting |\r\n| `labels` | Label management and filtering |\r\n| `projects` | GitHub Projects board management |\r\n| `pull_requests` | PR creation, review, merging |\r\n| `repos` | Code search, commits, releases, branches |\r\n| `users` | User search and management |\r\n| `orgs` | Organization and team management |\r\n| `notifications` | Notification management |\r\n| `secret_scanning` | Secret scanning alerts |\r\n| `context` | Context about the user |\r\n\r\n## Quick Reference\r\n\r\n```bash\r\n# List available tools\r\npython executor.py --list\r\n\r\n# Get repository info\r\npython executor.py --tool get_repository --args '{\"owner\": \"anthropics\", \"repo\": \"claude-code\"}'\r\n\r\n# List issues\r\npython executor.py --tool list_issues --args '{\"owner\": \"anthropics\", \"repo\": \"claude-code\"}'\r\n\r\n# Search code\r\npython executor.py --tool search_code --args '{\"query\": \"language:python MCP\"}'\r\n\r\n# Create issue\r\npython executor.py --tool create_issue --args '{\"owner\": \"me\", \"repo\": \"myrepo\", \"title\": \"Bug\", \"body\": \"Description\"}'\r\n\r\n# List pull requests\r\npython executor.py --tool list_pull_requests --args '{\"owner\": \"anthropics\", \"repo\": \"claude-code\"}'\r\n```\r\n\r\n## Common Tools (Default Toolsets: 40 tools)\r\n\r\n### Repository Operations\r\n- `search_repositories` - Search for repositories\r\n- `create_repository` - Create a new repository\r\n- `fork_repository` - Fork a repository\r\n- `list_commits` - List repository commits\r\n- `get_commit` - Get commit details\r\n- `get_file_contents` - Get file contents from a repository\r\n- `create_or_update_file` - Create or update a file\r\n- `delete_file` - Delete a file\r\n- `push_files` - Push multiple files\r\n- `search_code` - Search for code across GitHub\r\n- `list_branches` - List repository branches\r\n- `create_branch` - Create a new branch\r\n- `list_tags` - List repository tags\r\n- `get_tag` - Get tag details\r\n- `list_releases` - List releases\r\n- `get_latest_release` - Get latest release\r\n- `get_release_by_tag` - Get release by tag\r\n\r\n### Issue Operations\r\n- `list_issues` - List repository issues\r\n- `issue_read` - Read issue details\r\n- `issue_write` - Create/update issues\r\n- `add_issue_comment` - Add a comment to an issue\r\n- `search_issues` - Search for issues\r\n- `list_issue_types` - List issue types (for organizations)\r\n- `get_label` - Get label details\r\n- `sub_issue_write` - Manage sub-issues\r\n- `assign_copilot_to_issue` - Assign Copilot to an issue\r\n\r\n### Pull Request Operations\r\n- `list_pull_requests` - List repository pull requests\r\n- `pull_request_read` - Read PR details\r\n- `create_pull_request` - Create a new PR\r\n- `update_pull_request` - Update a PR\r\n- `update_pull_request_branch` - Update PR branch\r\n- `merge_pull_request` - Merge a PR\r\n- `search_pull_requests` - Search for pull requests\r\n- `pull_request_review_write` - Create/submit PR reviews\r\n- `add_comment_to_pending_review` - Add comments to pending review\r\n- `request_copilot_review` - Request Copilot review\r\n\r\n### User & Team Operations\r\n- `get_me` - Get current authenticated user\r\n- `search_users` - Search for users\r\n- `get_teams` - Get organization teams\r\n- `get_team_members` - Get team members\r\n\r\n## Configuration\r\n\r\nThe skill uses Docker to run the official GitHub MCP server:\r\n- **Image**: `ghcr.io/github/github-mcp-server`\r\n- **Auth**: `GITHUB_PERSONAL_ACCESS_TOKEN` environment variable\r\n\r\n### Environment Variables\r\n\r\n| Variable | Required | Description |\r\n|----------|----------|-------------|\r\n| `GITHUB_PERSONAL_ACCESS_TOKEN` | Yes | GitHub PAT for authentication |\r\n| `GITHUB_HOST` | No | For GitHub Enterprise (default: github.com) |\r\n| `GITHUB_TOOLSETS` | No | Comma-separated toolsets to enable |\r\n| `GITHUB_READ_ONLY` | No | Set to 1 for read-only mode |\r\n\r\n### Limiting Toolsets\r\n\r\nTo reduce context and improve tool selection, enable only needed toolsets:\r\n\r\n```bash\r\n# Only repos and issues\r\nGITHUB_TOOLSETS=repos,issues python executor.py --list\r\n\r\n# Only pull requests and code security\r\nGITHUB_TOOLSETS=pull_requests,code_security python executor.py --list\r\n```\r\n\r\n## Error Handling\r\n\r\nIf tool execution fails:\r\n1. Verify Docker is running: `docker ps`\r\n2. Check GitHub token is set: `echo $GITHUB_PERSONAL_ACCESS_TOKEN`\r\n3. Ensure token has required permissions for the operation\r\n4. Review executor.py output for details\r\n\r\n## Related\r\n\r\n- Official GitHub MCP Server: https://github.com/github/github-mcp-server\r\n- GitHub API Documentation: https://docs.github.com/en/rest\r\n",
          "tokens": 1365
        }
      }
    },
    "cloud-run": {
      "name": "cloud-run",
      "one_liner": "No description",
      "key_commands": ["/region", "/skills", "/cloud-run", "/executor"],
      "token_count": {
        "minimal": 10,
        "essential": 5,
        "standard": 5,
        "full": 1656
      },
      "levels": {
        "minimal": {
          "content": "**cloud-run**: No description available",
          "tokens": 10
        },
        "essential": {
          "content": "## Skill: cloud-run\n",
          "tokens": 5
        },
        "standard": {
          "content": "## Skill: cloud-run\n",
          "tokens": 5
        },
        "full": {
          "content": "---\r\nname: cloud-run\r\ndescription: Google Cloud Run deployment and management. Deploy applications, list services, get logs, and manage GCP projects. Use for Cloud Run deployments, service monitoring, and GCP project management.\r\nallowed-tools: read, write, bash\r\n---\r\n\r\n# Cloud Run Skill\r\n\r\n## Overview\r\n\r\nThis skill provides access to the Google Cloud Platform Cloud Run MCP server with progressive disclosure for optimal context usage.\r\n\r\n**Context Savings**: ~90% reduction\r\n- **MCP Mode**: ~15,000 tokens always loaded (7 tools + prompts)\r\n- **Skill Mode**: ~300 tokens metadata + on-demand loading\r\n\r\n## Requirements\r\n\r\n- Node.js 18+ OR Docker installed and running\r\n- Google Cloud credentials configured via `gcloud auth application-default login`\r\n- Optional: `GOOGLE_CLOUD_PROJECT` and `GOOGLE_CLOUD_REGION` environment variables\r\n\r\n## Tools\r\n\r\nThe server provides 8 tools across deployment and management categories:\r\n\r\n### Deployment Tools\r\n\r\n| Tool | Description | Mode |\r\n|------|-------------|------|\r\n| `deploy-file-contents` | Deploy files to Cloud Run by providing contents directly | Local + Remote |\r\n| `deploy-local-folder` | Deploy a local folder to Cloud Run | Local only |\r\n| `deploy-container-image` | Deploy a container image URL to Cloud Run | Local + Remote |\r\n\r\n### Service Management Tools\r\n\r\n| Tool | Description | Mode |\r\n|------|-------------|------|\r\n| `list-services` | List Cloud Run services in a project/region | Local + Remote |\r\n| `get-service` | Get details for a specific Cloud Run service | Local + Remote |\r\n| `get-service-log` | Get logs and errors for a specific service | Local + Remote |\r\n\r\n### Project Management Tools (Local Only)\r\n\r\n| Tool | Description |\r\n|------|-------------|\r\n| `list-projects` | List available GCP projects |\r\n| `create-project` | Create a new GCP project and attach to billing |\r\n\r\n## Quick Reference\r\n\r\n```bash\r\n# List available tools\r\npython executor.py --list\r\n\r\n# List Cloud Run services\r\npython executor.py --tool list-services --args '{\"projectId\": \"my-project\", \"region\": \"us-central1\"}'\r\n\r\n# Get service details\r\npython executor.py --tool get-service --args '{\"projectId\": \"my-project\", \"region\": \"us-central1\", \"serviceName\": \"my-service\"}'\r\n\r\n# Get service logs\r\npython executor.py --tool get-service-log --args '{\"projectId\": \"my-project\", \"region\": \"us-central1\", \"serviceName\": \"my-service\"}'\r\n\r\n# Deploy file contents\r\npython executor.py --tool deploy-file-contents --args '{\"projectId\": \"my-project\", \"region\": \"us-central1\", \"serviceName\": \"my-service\", \"files\": [{\"path\": \"main.py\", \"contents\": \"...\"}]}'\r\n\r\n# List GCP projects\r\npython executor.py --tool list-projects\r\n```\r\n\r\n## Configuration\r\n\r\n### Environment Variables\r\n\r\n| Variable | Description | Default |\r\n|----------|-------------|---------|\r\n| `GOOGLE_CLOUD_PROJECT` | Default GCP project ID | None |\r\n| `GOOGLE_CLOUD_REGION` | Default Cloud Run region | `us-central1` |\r\n| `DEFAULT_SERVICE_NAME` | Default service name for deployments | None |\r\n| `SKIP_IAM_CHECK` | Skip IAM permission validation | `false` |\r\n| `ENABLE_HOST_VALIDATION` | Enable Host header validation | `false` |\r\n\r\n### Setup\r\n\r\n1. **Authenticate with GCP**:\r\n   ```bash\r\n   gcloud auth application-default login\r\n   ```\r\n\r\n2. **Set default project** (optional):\r\n   ```bash\r\n   export GOOGLE_CLOUD_PROJECT=my-project-id\r\n   export GOOGLE_CLOUD_REGION=us-central1\r\n   ```\r\n\r\n3. **Use the skill**:\r\n   ```bash\r\n   python .claude/skills/cloud-run/executor.py --list\r\n   ```\r\n\r\n## Prompts\r\n\r\nThe MCP server also provides natural language prompts:\r\n\r\n| Prompt | Description |\r\n|--------|-------------|\r\n| `deploy` | Deploy current working directory to Cloud Run |\r\n| `logs` | Get logs for a Cloud Run service |\r\n\r\n## Tool Details\r\n\r\n### deploy-file-contents\r\n\r\nDeploy files to Cloud Run by providing their contents directly.\r\n\r\n**Parameters**:\r\n- `projectId` (string, required): GCP project ID\r\n- `region` (string, required): Cloud Run region\r\n- `serviceName` (string, required): Name for the Cloud Run service\r\n- `files` (array, required): Array of file objects with `path` and `contents`\r\n\r\n**Example**:\r\n```json\r\n{\r\n  \"projectId\": \"my-project\",\r\n  \"region\": \"us-central1\",\r\n  \"serviceName\": \"my-api\",\r\n  \"files\": [\r\n    {\"path\": \"main.py\", \"contents\": \"from flask import Flask\\napp = Flask(__name__)\\n...\"},\r\n    {\"path\": \"requirements.txt\", \"contents\": \"flask==2.0.0\\ngunicorn==20.1.0\"}\r\n  ]\r\n}\r\n```\r\n\r\n### list-services\r\n\r\nList Cloud Run services in a given project and region.\r\n\r\n**Parameters**:\r\n- `projectId` (string, required): GCP project ID\r\n- `region` (string, optional): Cloud Run region (defaults to configured region)\r\n\r\n### get-service\r\n\r\nGet detailed information about a specific Cloud Run service.\r\n\r\n**Parameters**:\r\n- `projectId` (string, required): GCP project ID\r\n- `region` (string, required): Cloud Run region\r\n- `serviceName` (string, required): Cloud Run service name\r\n\r\n### get-service-log\r\n\r\nGet logs and error messages for a specific Cloud Run service.\r\n\r\n**Parameters**:\r\n- `projectId` (string, required): GCP project ID\r\n- `region` (string, required): Cloud Run region\r\n- `serviceName` (string, required): Cloud Run service name\r\n- `limit` (number, optional): Maximum number of log entries\r\n\r\n### deploy-local-folder\r\n\r\nDeploy a local folder to a Cloud Run service (local mode only).\r\n\r\n**Parameters**:\r\n- `projectId` (string, required): GCP project ID\r\n- `region` (string, required): Cloud Run region\r\n- `serviceName` (string, required): Cloud Run service name\r\n- `folderPath` (string, required): Path to local folder to deploy\r\n\r\n### list-projects\r\n\r\nList available GCP projects (local mode only).\r\n\r\n**Parameters**: None\r\n\r\n### create-project\r\n\r\nCreate a new GCP project and attach it to billing (local mode only).\r\n\r\n**Parameters**:\r\n- `projectId` (string, required): Desired project ID\r\n- `projectName` (string, optional): Human-readable project name\r\n\r\n## Integration with Agents\r\n\r\nThis skill integrates with the following agents:\r\n- **devops**: For Cloud Run deployments and infrastructure management\r\n- **developer**: For deploying applications during development\r\n- **architect**: For service architecture decisions\r\n\r\n## Troubleshooting\r\n\r\n| Error | Cause | Fix |\r\n|-------|-------|-----|\r\n| \"Permission denied\" | Missing GCP credentials | Run `gcloud auth application-default login` |\r\n| \"Project not found\" | Invalid project ID | Verify project ID with `gcloud projects list` |\r\n| \"Region not found\" | Invalid region | Use valid Cloud Run regions (e.g., `us-central1`) |\r\n| \"Service not found\" | Service doesn't exist | Check service name with `list-services` |\r\n",
          "tokens": 1656
        }
      }
    },
    "puppeteer": {
      "name": "puppeteer",
      "one_liner": "Browser automation with Puppeteer. Navigate pages, interact with elements, fill forms, take screenshots, and execute JavaScript. Converted from MCP server for 90%+ context savings.",
      "key_commands": ["/Chromium", "/select", "/element", "/example", "/login"],
      "token_count": {
        "minimal": 49,
        "essential": 51,
        "standard": 51,
        "full": 4279
      },
      "levels": {
        "minimal": {
          "content": "**puppeteer**: Browser automation with Puppeteer. Navigate pages, interact with elements, fill forms, take screenshots, and execute JavaScript. Converted from MCP server for 90%+ context savings.",
          "tokens": 49
        },
        "essential": {
          "content": "## Skill: puppeteer\n\nBrowser automation with Puppeteer. Navigate pages, interact with elements, fill forms, take screenshots, and execute JavaScript. Converted from MCP server for 90%+ context savings.\n",
          "tokens": 51
        },
        "standard": {
          "content": "## Skill: puppeteer\n\nBrowser automation with Puppeteer. Navigate pages, interact with elements, fill forms, take screenshots, and execute JavaScript. Converted from MCP server for 90%+ context savings.\n",
          "tokens": 51
        },
        "full": {
          "content": "---\nname: puppeteer\ndescription: Browser automation with Puppeteer. Navigate pages, interact with elements, fill forms, take screenshots, and execute JavaScript. Converted from MCP server for 90%+ context savings.\nallowed-tools: read, write, bash\nversion: 1.0\nbest_practices:\n  - Start with puppeteer_navigate before other operations\n  - Use puppeteer_screenshot to verify page state\n  - Wait for elements to load before interacting\n  - Handle navigation timing with launchOptions\n  - Use puppeteer_evaluate for complex JavaScript operations\nerror_handling: graceful\nstreaming: supported\n---\n\n# Puppeteer Skill\n\n## Overview\n\nThis skill provides browser automation capabilities using Puppeteer, a Node.js library for controlling headless Chrome/Chromium browsers. It enables page navigation, element interaction, form filling, screenshot capture, and JavaScript execution.\n\n**Context Savings**: ~97% reduction\n- **MCP Mode**: ~15,000 tokens always loaded\n- **Skill Mode**: ~500 tokens metadata + on-demand loading\n\n## When to Use\n\n- Automated browser testing and QA workflows\n- Web scraping and data extraction\n- Form automation and submission\n- Screenshot capture for visual testing\n- JavaScript execution in browser context\n- Dropdown/select element automation\n- Hover state testing and interaction\n\n## Quick Reference\n\n| Tool | Purpose | Key Parameters |\n|------|---------|----------------|\n| `puppeteer_navigate` | Navigate to URL | `url`, `launchOptions`, `allowDangerous` |\n| `puppeteer_screenshot` | Capture page/element | `name`, `selector`, `width`, `height`, `encoded` |\n| `puppeteer_click` | Click element | `selector` |\n| `puppeteer_fill` | Fill input field | `selector`, `value` |\n| `puppeteer_select` | Select dropdown option | `selector`, `value` |\n| `puppeteer_hover` | Hover over element | `selector` |\n| `puppeteer_evaluate` | Execute JavaScript | `script` |\n\n```bash\n# List available tools\npython executor.py --list\n\n# Navigate to a page\npython executor.py --tool puppeteer_navigate --args '{\"url\": \"https://example.com\"}'\n\n# Take a screenshot\npython executor.py --tool puppeteer_screenshot --args '{\"name\": \"homepage\"}'\n\n# Fill a form field\npython executor.py --tool puppeteer_fill --args '{\"selector\": \"#email\", \"value\": \"user@example.com\"}'\n```\n\n## Tools\n\n### Navigation (1 tool)\n\n#### puppeteer_navigate\n\nNavigate to a URL and optionally configure browser launch options.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `url` | string | Yes | URL to navigate to |\n| `launchOptions` | object | No | Puppeteer LaunchOptions. Browser restarts if changed. Example: `{ headless: true, args: ['--no-sandbox'] }` |\n| `allowDangerous` | boolean | No | Allow dangerous LaunchOptions like `--no-sandbox`. Default: `false` |\n\n**Example:**\n```bash\n# Basic navigation\npython executor.py --tool puppeteer_navigate --args '{\"url\": \"https://example.com\"}'\n\n# Navigation with headless mode\npython executor.py --tool puppeteer_navigate --args '{\n  \"url\": \"https://example.com\",\n  \"launchOptions\": {\"headless\": true}\n}'\n\n# Dangerous launch options (use with caution)\npython executor.py --tool puppeteer_navigate --args '{\n  \"url\": \"https://example.com\",\n  \"launchOptions\": {\"args\": [\"--no-sandbox\", \"--disable-setuid-sandbox\"]},\n  \"allowDangerous\": true\n}'\n```\n\n**Notes:**\n- Changing `launchOptions` triggers browser restart\n- `allowDangerous` must be `true` to use security-reducing flags like `--no-sandbox`\n- Default `launchOptions` is `null` (uses Puppeteer defaults)\n\n### Capture (1 tool)\n\n#### puppeteer_screenshot\n\nTake a screenshot of the current page or a specific element.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `name` | string | Yes | Name for the screenshot file |\n| `selector` | string | No | CSS selector for specific element to capture |\n| `width` | number | No | Viewport width in pixels (default: 800) |\n| `height` | number | No | Viewport height in pixels (default: 600) |\n| `encoded` | boolean | No | Return base64-encoded data URI instead of binary (default: false) |\n\n**Example:**\n```bash\n# Full page screenshot\npython executor.py --tool puppeteer_screenshot --args '{\"name\": \"homepage\"}'\n\n# Specific element screenshot\npython executor.py --tool puppeteer_screenshot --args '{\n  \"name\": \"header\",\n  \"selector\": \"#main-header\"\n}'\n\n# Custom viewport size\npython executor.py --tool puppeteer_screenshot --args '{\n  \"name\": \"mobile-view\",\n  \"width\": 375,\n  \"height\": 667\n}'\n\n# Base64-encoded screenshot\npython executor.py --tool puppeteer_screenshot --args '{\n  \"name\": \"encoded-screenshot\",\n  \"encoded\": true\n}'\n```\n\n**Notes:**\n- Without `selector`, captures entire viewport\n- `encoded: true` returns text (base64 data URI) instead of binary image\n- Default viewport is 800x600px\n\n### Interaction (4 tools)\n\n#### puppeteer_click\n\nClick an element on the page.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `selector` | string | Yes | CSS selector for element to click |\n\n**Example:**\n```bash\n# Click a button\npython executor.py --tool puppeteer_click --args '{\"selector\": \"#submit-button\"}'\n\n# Click a link\npython executor.py --tool puppeteer_click --args '{\"selector\": \"a[href='/login']\"}'\n\n# Click by class\npython executor.py --tool puppeteer_click --args '{\"selector\": \".btn-primary\"}'\n```\n\n#### puppeteer_fill\n\nFill out an input field with text.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `selector` | string | Yes | CSS selector for input field |\n| `value` | string | Yes | Text value to enter |\n\n**Example:**\n```bash\n# Fill email field\npython executor.py --tool puppeteer_fill --args '{\n  \"selector\": \"#email\",\n  \"value\": \"user@example.com\"\n}'\n\n# Fill password field\npython executor.py --tool puppeteer_fill --args '{\n  \"selector\": \"input[type='password']\",\n  \"value\": \"securePassword123\"\n}'\n\n# Fill textarea\npython executor.py --tool puppeteer_fill --args '{\n  \"selector\": \"textarea[name='message']\",\n  \"value\": \"Hello, this is a test message.\"\n}'\n```\n\n**Notes:**\n- Works with `<input>` and `<textarea>` elements\n- Clears existing value before filling\n- Triggers input events (suitable for validation testing)\n\n#### puppeteer_select\n\nSelect an option from a dropdown (`<select>` element).\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `selector` | string | Yes | CSS selector for select element |\n| `value` | string | Yes | Value attribute of option to select |\n\n**Example:**\n```bash\n# Select country\npython executor.py --tool puppeteer_select --args '{\n  \"selector\": \"#country\",\n  \"value\": \"US\"\n}'\n\n# Select from dropdown by ID\npython executor.py --tool puppeteer_select --args '{\n  \"selector\": \"select[name='plan']\",\n  \"value\": \"premium\"\n}'\n```\n\n**Notes:**\n- Works only with `<select>` elements\n- Matches the `value` attribute of `<option>` elements, not visible text\n- Triggers change events\n\n#### puppeteer_hover\n\nHover over an element to trigger hover states.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `selector` | string | Yes | CSS selector for element to hover |\n\n**Example:**\n```bash\n# Hover over navigation menu\npython executor.py --tool puppeteer_hover --args '{\"selector\": \".nav-dropdown\"}'\n\n# Hover to reveal tooltip\npython executor.py --tool puppeteer_hover --args '{\"selector\": \".info-icon\"}'\n\n# Hover for dropdown menu\npython executor.py --tool puppeteer_hover --args '{\"selector\": \"#user-menu\"}'\n```\n\n**Notes:**\n- Useful for testing hover states and dropdown menus\n- Does not click the element\n- Can be combined with screenshot to verify hover effects\n\n### JavaScript Execution (1 tool)\n\n#### puppeteer_evaluate\n\nExecute arbitrary JavaScript code in the browser console context.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `script` | string | Yes | JavaScript code to execute |\n\n**Example:**\n```bash\n# Get page title\npython executor.py --tool puppeteer_evaluate --args '{\"script\": \"document.title\"}'\n\n# Get element count\npython executor.py --tool puppeteer_evaluate --args '{\n  \"script\": \"document.querySelectorAll(\\\".product-card\\\").length\"\n}'\n\n# Scroll to bottom\npython executor.py --tool puppeteer_evaluate --args '{\n  \"script\": \"window.scrollTo(0, document.body.scrollHeight)\"\n}'\n\n# Get local storage\npython executor.py --tool puppeteer_evaluate --args '{\n  \"script\": \"JSON.stringify(localStorage)\"\n}'\n\n# Inject CSS\npython executor.py --tool puppeteer_evaluate --args '{\n  \"script\": \"const style = document.createElement(\\\"style\\\"); style.textContent = \\\"body { background: red; }\\\"; document.head.appendChild(style);\"\n}'\n```\n\n**Notes:**\n- Runs in page context, not Node.js context\n- Has access to DOM, window, and page-level JavaScript\n- Return values are serialized to JSON\n- Useful for complex operations not covered by other tools\n\n## Common Workflows\n\n### Login Flow Automation\n\n```bash\n# 1. Navigate to login page\npython executor.py --tool puppeteer_navigate --args '{\"url\": \"https://myapp.com/login\"}'\n\n# 2. Fill email field\npython executor.py --tool puppeteer_fill --args '{\"selector\": \"#email\", \"value\": \"user@example.com\"}'\n\n# 3. Fill password field\npython executor.py --tool puppeteer_fill --args '{\"selector\": \"#password\", \"value\": \"securePass123\"}'\n\n# 4. Click submit button\npython executor.py --tool puppeteer_click --args '{\"selector\": \"button[type=\\\"submit\\\"]\"}'\n\n# 5. Take screenshot of result\npython executor.py --tool puppeteer_screenshot --args '{\"name\": \"login-result\"}'\n```\n\n### Form Submission\n\n```bash\n# 1. Navigate to form\npython executor.py --tool puppeteer_navigate --args '{\"url\": \"https://myapp.com/contact\"}'\n\n# 2. Fill name\npython executor.py --tool puppeteer_fill --args '{\"selector\": \"#name\", \"value\": \"John Doe\"}'\n\n# 3. Fill email\npython executor.py --tool puppeteer_fill --args '{\"selector\": \"#email\", \"value\": \"john@example.com\"}'\n\n# 4. Select reason dropdown\npython executor.py --tool puppeteer_select --args '{\"selector\": \"#reason\", \"value\": \"support\"}'\n\n# 5. Fill message\npython executor.py --tool puppeteer_fill --args '{\"selector\": \"#message\", \"value\": \"I need help with my account.\"}'\n\n# 6. Submit form\npython executor.py --tool puppeteer_click --args '{\"selector\": \"#submit\"}'\n```\n\n### Visual Regression Testing\n\n```bash\n# 1. Navigate to page\npython executor.py --tool puppeteer_navigate --args '{\"url\": \"https://myapp.com\"}'\n\n# 2. Capture baseline screenshot\npython executor.py --tool puppeteer_screenshot --args '{\"name\": \"baseline-homepage\"}'\n\n# 3. Hover over element to test hover state\npython executor.py --tool puppeteer_hover --args '{\"selector\": \".nav-item\"}'\n\n# 4. Capture hover state\npython executor.py --tool puppeteer_screenshot --args '{\"name\": \"hover-state-nav\"}'\n\n# 5. Click to reveal modal\npython executor.py --tool puppeteer_click --args '{\"selector\": \".open-modal\"}'\n\n# 6. Capture modal state\npython executor.py --tool puppeteer_screenshot --args '{\"name\": \"modal-open\", \"selector\": \".modal\"}'\n```\n\n### Data Extraction\n\n```bash\n# 1. Navigate to page\npython executor.py --tool puppeteer_navigate --args '{\"url\": \"https://news.ycombinator.com\"}'\n\n# 2. Extract headlines using JavaScript\npython executor.py --tool puppeteer_evaluate --args '{\n  \"script\": \"Array.from(document.querySelectorAll(\\\".titleline > a\\\")).map(a => a.textContent).slice(0, 10)\"\n}'\n\n# 3. Get page metadata\npython executor.py --tool puppeteer_evaluate --args '{\n  \"script\": \"{title: document.title, url: window.location.href, description: document.querySelector(\\\"meta[name=description]\\\")?.content}\"\n}'\n```\n\n### Dropdown Menu Testing\n\n```bash\n# 1. Navigate to page\npython executor.py --tool puppeteer_navigate --args '{\"url\": \"https://myapp.com\"}'\n\n# 2. Hover over menu to reveal dropdown\npython executor.py --tool puppeteer_hover --args '{\"selector\": \"#nav-products\"}'\n\n# 3. Take screenshot of dropdown\npython executor.py --tool puppeteer_screenshot --args '{\"name\": \"products-dropdown\"}'\n\n# 4. Click dropdown item\npython executor.py --tool puppeteer_click --args '{\"selector\": \"#nav-products .dropdown-item:nth-child(2)\"}'\n```\n\n### Mobile Viewport Testing\n\n```bash\n# 1. Navigate with mobile viewport\npython executor.py --tool puppeteer_navigate --args '{\n  \"url\": \"https://myapp.com\",\n  \"launchOptions\": {\n    \"defaultViewport\": {\"width\": 375, \"height\": 667, \"isMobile\": true}\n  }\n}'\n\n# 2. Take mobile screenshot\npython executor.py --tool puppeteer_screenshot --args '{\n  \"name\": \"mobile-view\",\n  \"width\": 375,\n  \"height\": 667\n}'\n\n# 3. Test mobile menu interaction\npython executor.py --tool puppeteer_click --args '{\"selector\": \".mobile-menu-toggle\"}'\n\n# 4. Capture mobile menu state\npython executor.py --tool puppeteer_screenshot --args '{\"name\": \"mobile-menu-open\"}'\n```\n\n## Configuration\n\nMCP server configuration stored in `config.json`:\n- **Command**: `npx`\n- **Args**: `[\"-y\", \"@modelcontextprotocol/server-puppeteer\"]`\n\n### Headless Mode\n\nBy default, Puppeteer runs in headless mode. To run with visible browser:\n\n```bash\npython executor.py --tool puppeteer_navigate --args '{\n  \"url\": \"https://example.com\",\n  \"launchOptions\": {\"headless\": false}\n}'\n```\n\n### Custom Browser Arguments\n\n```bash\npython executor.py --tool puppeteer_navigate --args '{\n  \"url\": \"https://example.com\",\n  \"launchOptions\": {\n    \"args\": [\"--window-size=1920,1080\", \"--disable-gpu\"],\n    \"headless\": true\n  }\n}'\n```\n\n### Dangerous Launch Options\n\nSome options reduce security and require `allowDangerous: true`:\n\n```bash\npython executor.py --tool puppeteer_navigate --args '{\n  \"url\": \"https://example.com\",\n  \"launchOptions\": {\n    \"args\": [\"--no-sandbox\", \"--disable-setuid-sandbox\"]\n  },\n  \"allowDangerous\": true\n}'\n```\n\n**Warning:** Use `--no-sandbox` only in trusted environments. It disables Chrome's security sandbox.\n\n## Error Handling\n\n**Common Issues:**\n\n| Error | Cause | Solution |\n|-------|-------|----------|\n| \"Navigation timeout\" | Page took too long to load | Increase timeout in `launchOptions` or check network |\n| \"Element not found\" | Selector doesn't match any element | Verify selector, check if element is dynamic |\n| \"Element not visible\" | Element is hidden or off-screen | Scroll to element or wait for visibility |\n| \"Cannot set property\" | Trying to fill non-input element | Verify selector targets `<input>` or `<textarea>` |\n| \"Browser launch failed\" | Chrome/Chromium not found | Install Chrome or set `executablePath` in `launchOptions` |\n| \"Dangerous option rejected\" | Using `--no-sandbox` without flag | Add `\"allowDangerous\": true` to args |\n\n**Recovery Strategies:**\n\n1. **Take screenshot to verify page state**\n   ```bash\n   python executor.py --tool puppeteer_screenshot --args '{\"name\": \"debug\"}'\n   ```\n\n2. **Use evaluate to check element existence**\n   ```bash\n   python executor.py --tool puppeteer_evaluate --args '{\n     \"script\": \"!!document.querySelector(\\\"#my-element\\\")\"\n   }'\n   ```\n\n3. **Add delays with evaluate**\n   ```bash\n   python executor.py --tool puppeteer_evaluate --args '{\n     \"script\": \"new Promise(resolve => setTimeout(resolve, 2000))\"\n   }'\n   ```\n\n4. **Check console logs with evaluate**\n   ```bash\n   python executor.py --tool puppeteer_evaluate --args '{\n     \"script\": \"console.log(\\\"Debug checkpoint reached\\\")\"\n   }'\n   ```\n\n## Comparison: Puppeteer vs Chrome DevTools Skill\n\n| Feature | Puppeteer | Chrome DevTools |\n|---------|-----------|-----------------|\n| **Tools** | 7 | 26 |\n| **Navigation** | Basic | Advanced (multi-page, wait conditions) |\n| **Screenshots** | Yes (element/full) | Yes (element/full/format options) |\n| **Performance** | No | Yes (tracing, analysis, insights) |\n| **Network Inspection** | No | Yes (request/response details) |\n| **Console Access** | Via evaluate | Direct (list, filter, retrieve) |\n| **Form Automation** | Yes (fill, select, click) | Yes (fill, fill_form, upload) |\n| **Hover Support** | Yes | Yes |\n| **JavaScript Execution** | Yes (evaluate) | Yes (evaluate_script) |\n| **Device Emulation** | Via launchOptions | Direct (emulate tool) |\n| **Use Case** | Simpler automation, form testing | Advanced debugging, performance, network analysis |\n\n**When to Choose Puppeteer:**\n- Simple form automation workflows\n- Basic screenshot capture\n- Straightforward navigation and clicking\n- Lightweight browser automation\n\n**When to Choose Chrome DevTools:**\n- Performance profiling and optimization\n- Network request inspection\n- Console message analysis\n- Multi-page workflows\n- Advanced debugging scenarios\n\n## Related\n\n- Chrome DevTools Skill: `.claude/skills/chrome-devtools/` (more advanced browser automation)\n- Computer-Use Skill: `.claude/skills/computer-use/` (Playwright-based automation)\n- Original MCP: `npx -y @modelcontextprotocol/server-puppeteer`\n- MCP Converter: `.claude/skills/mcp-converter/`\n- Skill Manager: `.claude/skills/skill-manager/`\n\n## Sources\n\n- [Puppeteer MCP Server - npm](https://www.npmjs.com/package/@modelcontextprotocol/server-puppeteer)\n- [Puppeteer Documentation](https://pptr.dev/)\n- [Model Context Protocol](https://modelcontextprotocol.io/)\n",
          "tokens": 4279
        }
      }
    },
    "memory": {
      "name": "memory",
      "one_liner": "No description",
      "key_commands": ["/server-memory", "/path", "/to", "/memory", "/skills"],
      "token_count": {
        "minimal": 9,
        "essential": 5,
        "standard": 5,
        "full": 2241
      },
      "levels": {
        "minimal": {
          "content": "**memory**: No description available",
          "tokens": 9
        },
        "essential": {
          "content": "## Skill: memory\n",
          "tokens": 5
        },
        "standard": {
          "content": "## Skill: memory\n",
          "tokens": 5
        },
        "full": {
          "content": "---\r\nname: memory\r\ndescription: Persistent knowledge graph memory system. Store and retrieve entities, relations, and observations across conversations. Use for maintaining user context, preferences, and learned patterns.\r\nallowed-tools: read, write, bash\r\nversion: 1.0\r\nbest_practices:\r\n  - Create entities for important people, organizations, and concepts\r\n  - Use relations to capture connections between entities\r\n  - Add observations as discrete, atomic facts\r\n  - Search before creating to avoid duplicates\r\n  - Use active voice for relations\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# Memory Skill\r\n\r\n## Overview\r\n\r\nThis skill provides persistent memory using a local knowledge graph. It enables Claude to retain information about users, topics, and patterns across conversations through three core components:\r\n\r\n- **Entities**: Primary nodes representing people, organizations, or concepts\r\n- **Relations**: Directed connections between entities (stored in active voice)\r\n- **Observations**: Discrete, atomic facts attached to specific entities\r\n\r\n**Context Savings**: ~95% reduction\r\n- **MCP Mode**: ~12,000 tokens always loaded\r\n- **Skill Mode**: ~400 tokens metadata + on-demand loading\r\n\r\n## When to Use\r\n\r\n- Remembering user preferences and context across sessions\r\n- Tracking relationships between people and organizations\r\n- Storing learned patterns and insights\r\n- Building knowledge graphs about domains\r\n- Maintaining conversation context over time\r\n\r\n## Quick Reference\r\n\r\n```bash\r\n# List available tools\r\npython executor.py --list\r\n\r\n# Create an entity\r\npython executor.py --tool create_entities --args '{\"entities\": [{\"name\": \"John\", \"entityType\": \"person\", \"observations\": [\"Works at Acme Corp\"]}]}'\r\n\r\n# Search for entities\r\npython executor.py --tool search_nodes --args '{\"query\": \"John\"}'\r\n\r\n# Read entire graph\r\npython executor.py --tool read_graph --args '{}'\r\n```\r\n\r\n## Tools\r\n\r\n### create_entities\r\n\r\nCreate new entities in the knowledge graph.\r\n\r\n**Parameters:**\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `entities` | array | Array of entity objects |\r\n\r\n**Entity Object:**\r\n\r\n| Field | Type | Description |\r\n|-------|------|-------------|\r\n| `name` | string | Unique identifier for the entity |\r\n| `entityType` | string | Type classification (person, organization, concept, etc.) |\r\n| `observations` | array | Initial observations about the entity |\r\n\r\n**Example:**\r\n```bash\r\npython executor.py --tool create_entities --args '{\r\n  \"entities\": [\r\n    {\r\n      \"name\": \"Alice\",\r\n      \"entityType\": \"person\",\r\n      \"observations\": [\"Software engineer\", \"Works on AI projects\"]\r\n    }\r\n  ]\r\n}'\r\n```\r\n\r\n### create_relations\r\n\r\nCreate relations between existing entities.\r\n\r\n**Parameters:**\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `relations` | array | Array of relation objects |\r\n\r\n**Relation Object:**\r\n\r\n| Field | Type | Description |\r\n|-------|------|-------------|\r\n| `from` | string | Source entity name |\r\n| `to` | string | Target entity name |\r\n| `relationType` | string | Type of relationship (active voice) |\r\n\r\n**Example:**\r\n```bash\r\npython executor.py --tool create_relations --args '{\r\n  \"relations\": [\r\n    {\r\n      \"from\": \"Alice\",\r\n      \"to\": \"Acme Corp\",\r\n      \"relationType\": \"works_at\"\r\n    }\r\n  ]\r\n}'\r\n```\r\n\r\n### add_observations\r\n\r\nAdd new observations to existing entities.\r\n\r\n**Parameters:**\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `observations` | array | Array of observation objects |\r\n\r\n**Observation Object:**\r\n\r\n| Field | Type | Description |\r\n|-------|------|-------------|\r\n| `entityName` | string | Name of entity to add observations to |\r\n| `contents` | array | New observations to add |\r\n\r\n**Example:**\r\n```bash\r\npython executor.py --tool add_observations --args '{\r\n  \"observations\": [\r\n    {\r\n      \"entityName\": \"Alice\",\r\n      \"contents\": [\"Prefers TypeScript over JavaScript\"]\r\n    }\r\n  ]\r\n}'\r\n```\r\n\r\n### delete_entities\r\n\r\nDelete entities and their associated relations.\r\n\r\n**Parameters:**\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `entityNames` | array | Names of entities to delete |\r\n\r\n**Example:**\r\n```bash\r\npython executor.py --tool delete_entities --args '{\r\n  \"entityNames\": [\"OldEntity\"]\r\n}'\r\n```\r\n\r\n### delete_observations\r\n\r\nDelete specific observations from entities.\r\n\r\n**Parameters:**\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `deletions` | array | Array of deletion objects |\r\n\r\n**Deletion Object:**\r\n\r\n| Field | Type | Description |\r\n|-------|------|-------------|\r\n| `entityName` | string | Name of entity |\r\n| `observations` | array | Specific observations to delete |\r\n\r\n**Example:**\r\n```bash\r\npython executor.py --tool delete_observations --args '{\r\n  \"deletions\": [\r\n    {\r\n      \"entityName\": \"Alice\",\r\n      \"observations\": [\"Outdated info\"]\r\n    }\r\n  ]\r\n}'\r\n```\r\n\r\n### delete_relations\r\n\r\nDelete specific relations between entities.\r\n\r\n**Parameters:**\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `relations` | array | Array of relation objects to delete |\r\n\r\n**Example:**\r\n```bash\r\npython executor.py --tool delete_relations --args '{\r\n  \"relations\": [\r\n    {\r\n      \"from\": \"Alice\",\r\n      \"to\": \"OldCompany\",\r\n      \"relationType\": \"worked_at\"\r\n    }\r\n  ]\r\n}'\r\n```\r\n\r\n### read_graph\r\n\r\nRead the entire knowledge graph.\r\n\r\n**Parameters:** None\r\n\r\n**Example:**\r\n```bash\r\npython executor.py --tool read_graph --args '{}'\r\n```\r\n\r\n**Returns:**\r\n```json\r\n{\r\n  \"entities\": [\r\n    {\r\n      \"name\": \"Alice\",\r\n      \"entityType\": \"person\",\r\n      \"observations\": [\"Software engineer\"]\r\n    }\r\n  ],\r\n  \"relations\": [\r\n    {\r\n      \"from\": \"Alice\",\r\n      \"to\": \"Acme Corp\",\r\n      \"relationType\": \"works_at\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n### search_nodes\r\n\r\nSearch for entities by name, type, or observation content.\r\n\r\n**Parameters:**\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `query` | string | Search query string |\r\n\r\n**Example:**\r\n```bash\r\npython executor.py --tool search_nodes --args '{\"query\": \"software engineer\"}'\r\n```\r\n\r\n### open_nodes\r\n\r\nOpen specific entities by name.\r\n\r\n**Parameters:**\r\n\r\n| Parameter | Type | Description |\r\n|-----------|------|-------------|\r\n| `names` | array | Names of entities to retrieve |\r\n\r\n**Example:**\r\n```bash\r\npython executor.py --tool open_nodes --args '{\"names\": [\"Alice\", \"Bob\"]}'\r\n```\r\n\r\n## Usage Strategy\r\n\r\nThe recommended approach for using memory:\r\n\r\n1. **Identify User**: Create an entity for the user if not exists\r\n2. **Retrieve Memories**: At conversation start, search for user's entity\r\n3. **Track Information**: As you learn new things, categorize by:\r\n   - Identity (name, preferences, background)\r\n   - Behaviors (patterns, habits, workflows)\r\n   - Preferences (likes, dislikes, choices)\r\n   - Goals (objectives, targets, aspirations)\r\n   - Relationships (connections to other entities)\r\n4. **Update Graph**: Add observations and relations as you learn\r\n\r\n## Best Practices\r\n\r\n### Entity Design\r\n\r\n- **Unique Names**: Use specific, unique names for entities\r\n- **Clear Types**: Use consistent entity types (person, organization, project, concept)\r\n- **Atomic Observations**: Keep observations discrete and fact-based\r\n\r\n### Relation Design\r\n\r\n- **Active Voice**: Always use active voice for relations (\"works_at\" not \"is_employed_by\")\r\n- **Bidirectional**: Consider if both directions are needed\r\n- **Typed**: Use consistent relation types\r\n\r\n### Maintenance\r\n\r\n- **Search First**: Before creating, search for existing entities\r\n- **Prune Stale Data**: Delete outdated observations\r\n- **Update Relations**: Keep relations current\r\n\r\n## Configuration\r\n\r\nMCP server configuration stored in `config.json`:\r\n- **Command**: `npx -y @modelcontextprotocol/server-memory`\r\n- **Environment**: `MEMORY_FILE_PATH` for custom storage location\r\n\r\n### Custom Storage Location\r\n\r\n```json\r\n{\r\n  \"env\": {\r\n    \"MEMORY_FILE_PATH\": \"/path/to/memory.json\"\r\n  }\r\n}\r\n```\r\n\r\n## Integration\r\n\r\n### With Memory Manager Skill\r\n\r\nThis skill works alongside the `memory-manager` skill:\r\n- **memory**: Low-level knowledge graph operations\r\n- **memory-manager**: High-level patterns for dual persistence\r\n\r\n### With Agents\r\n\r\nAll agents can use memory to:\r\n- Store learned patterns\r\n- Track user preferences\r\n- Remember decisions and rationale\r\n- Build domain knowledge\r\n\r\n## Error Handling\r\n\r\n**Common Issues:**\r\n- Entity not found: Search first, create if needed\r\n- Duplicate entity: Use unique names or merge observations\r\n- Relation invalid: Both entities must exist\r\n\r\n**Recovery:**\r\n- Read graph to verify state\r\n- Delete and recreate if corrupted\r\n- Use search to find correct entity names\r\n\r\n## Related\r\n\r\n- Original MCP server: `@modelcontextprotocol/server-memory`\r\n- Memory Manager Skill: `.claude/skills/memory-manager/`\r\n- MCP Converter Skill: `.claude/skills/mcp-converter/`\r\n",
          "tokens": 2241
        }
      }
    },
    "memory-manager": {
      "name": "memory-manager",
      "one_liner": "No description",
      "key_commands": ["/memories", "/context", "/runs", "/skills", "/memory-manager"],
      "token_count": {
        "minimal": 11,
        "essential": 7,
        "standard": 7,
        "full": 2486
      },
      "levels": {
        "minimal": {
          "content": "**memory-manager**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: memory-manager\n",
          "tokens": 7
        },
        "standard": {
          "content": "## Skill: memory-manager\n",
          "tokens": 7
        },
        "full": {
          "content": "---\r\nname: memory-manager\r\ndescription: Manages memory tool integration with CLAUDE.md files for dual persistence and redundancy. Handles cross-conversation learning, memory sync, and context persistence.\r\nallowed-tools: read, write, memory, grep, glob\r\nversion: 1.0\r\nbest_practices:\r\n  - Use memory tool for learned patterns and insights\r\n  - Keep CLAUDE.md for static rules and standards\r\n  - Sync important patterns from memory to CLAUDE.md\r\n  - Validate memory file paths for security\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# Memory Manager Skill\r\n\r\n## Identity\r\n\r\nMemory Manager - Provides dual persistence (CLAUDE.md + Memory Tool) for redundancy and cross-conversation learning.\r\n\r\n## Capabilities\r\n\r\n- **Memory Tool Integration**: Store and retrieve learned patterns via memory tool\r\n- **CLAUDE.md Sync**: Sync important patterns from memory to CLAUDE.md\r\n- **Cross-Conversation Learning**: Enable agents to learn from previous sessions\r\n- **Dual Persistence**: Maintain knowledge in both memory tool and CLAUDE.md\r\n- **Security Validation**: Validate memory file paths to prevent memory poisoning\r\n\r\n## Dual Persistence Strategy\r\n\r\n### CLAUDE.md Files (Primary - Version-Controlled)\r\n- Hierarchical context loading (root → subdirectories)\r\n- Version-controlled in git\r\n- Project-specific, structured knowledge\r\n- Loaded automatically by Claude Code\r\n- Best for: Static rules, project structure, coding standards\r\n\r\n### Memory Tool (Secondary - Dynamic Learning)\r\n- Cross-conversation pattern persistence\r\n- Dynamic knowledge accumulation\r\n- Session-specific learnings\r\n- File-based storage under `/memories/` directory\r\n- Best for: Learned patterns, user preferences, task-specific insights\r\n\r\n### How They Work Together\r\n\r\n1. **CLAUDE.md**: Provides foundational context (rules, structure, standards)\r\n2. **Memory Tool**: Captures learned patterns and insights from interactions\r\n3. **Redundancy**: If one fails, the other provides backup context\r\n4. **Synergy**: Memory tool can reference CLAUDE.md patterns, CLAUDE.md can reference memory insights\r\n\r\n## Usage Patterns\r\n\r\n### Storing Learned Patterns\r\n\r\n**When to Store in Memory**:\r\n- User preferences discovered during interaction\r\n- Task-specific insights and solutions\r\n- Patterns learned from codebase analysis\r\n- Workflow optimizations discovered\r\n- Common mistakes to avoid\r\n\r\n**How to Store**:\r\n```\r\nUse memory tool to store: \"User prefers TypeScript over JavaScript for new features\"\r\n```\r\n\r\n### Reading from Memory\r\n\r\n**When to Read from Memory**:\r\n- Starting a new task (check for relevant patterns)\r\n- Encountering similar problems (look for previous solutions)\r\n- User preferences (check for known preferences)\r\n- Workflow patterns (check for optimized approaches)\r\n\r\n**How to Read**:\r\n```\r\nUse memory tool to read: \"What patterns do we have for authentication implementation?\"\r\n```\r\n\r\n### Syncing to CLAUDE.md\r\n\r\n**When to Sync**:\r\n- Pattern is project-wide and should be version-controlled\r\n- Rule discovered that applies to all future work\r\n- Standard that should be part of project documentation\r\n- Important decision that affects project structure\r\n\r\n**How to Sync**:\r\n1. Read pattern from memory tool\r\n2. Determine if it should be in CLAUDE.md\r\n3. Add to appropriate CLAUDE.md file (root or phase-specific)\r\n4. Keep in memory tool for redundancy\r\n\r\n## Memory File Organization\r\n\r\n### Directory Structure\r\n\r\nMemory files are stored in the run directory structure:\r\n\r\n```\r\n.claude/context/runs/{run-id}/\r\n├── memory/\r\n│   ├── patterns/\r\n│   │   ├── authentication-patterns.md\r\n│   │   ├── api-design-patterns.md\r\n│   │   └── testing-patterns.md\r\n│   ├── preferences/\r\n│   │   ├── user-preferences.md\r\n│   │   └── coding-style.md\r\n│   └── insights/\r\n│       ├── performance-insights.md\r\n│       └── security-insights.md\r\n```\r\n\r\n**Note**: Use `path-resolver.mjs` to resolve memory paths within a run directory.\r\n\r\n### Naming Conventions\r\n\r\n- **Patterns**: `{category}-patterns.md` (e.g., `authentication-patterns.md`)\r\n- **Preferences**: `{type}-preferences.md` (e.g., `user-preferences.md`)\r\n- **Insights**: `{domain}-insights.md` (e.g., `performance-insights.md`)\r\n\r\n## Security Best Practices\r\n\r\n### Path Validation (Production-Ready)\r\n\r\nBased on Claude Cookbooks patterns, always validate memory file paths:\r\n\r\n**Required Validation:**\r\n- Path must start with `/memories` prefix\r\n- Reject paths with `..` (directory traversal attacks)\r\n- Verify resolved path is within memory_root directory\r\n- Validate file extensions (`.txt`, `.md`, `.json`, `.py`, `.yaml`, `.yml`)\r\n\r\n**Implementation:**\r\nSee `.claude/skills/memory-manager/memory_tool_handler.py` for production-ready handler with:\r\n- Path validation and sanitization\r\n- Directory traversal protection\r\n- Comprehensive error handling\r\n- Security checks for all operations\r\n- File operation security (view, create, str_replace, insert, delete, rename)\r\n\r\n**Example Validation:**\r\n```python\r\ndef _validate_path(self, path: str) -> Path:\r\n    \"\"\"Validate and resolve memory paths to prevent directory traversal attacks.\"\"\"\r\n    if not path.startswith(\"/memories\"):\r\n        raise ValueError(\"Path must start with /memories\")\r\n    \r\n    # Remove /memories prefix and resolve\r\n    relative_path = path[len(\"/memories\"):].lstrip(\"/\")\r\n    full_path = (self.memory_root / relative_path).resolve()\r\n    \r\n    # Verify path is still within memory_root\r\n    try:\r\n        full_path.relative_to(self.memory_root.resolve())\r\n    except ValueError:\r\n        raise ValueError(\"Path would escape /memories directory\")\r\n    \r\n    return full_path\r\n```\r\n\r\n**Using the Handler:**\r\n```python\r\nfrom .claude.skills.memory_manager.memory_tool_handler import MemoryToolHandler\r\n\r\nhandler = MemoryToolHandler(base_path=\"./memory_storage\")\r\nresult = handler.execute(command=\"view\", path=\"/memories/patterns/auth.md\")\r\n```\r\n\r\n### Memory Poisoning Prevention\r\n\r\n**Prevent malicious memory content**:\r\n- Validate memory content before storing\r\n- Sanitize user input in memory files\r\n- Review memory files periodically\r\n- Use structured formats (JSON, YAML) when possible\r\n- Restrict file types to text-based formats only\r\n- Validate string uniqueness for replacements (prevent ambiguous edits)\r\n\r\n### Security Features\r\n\r\n**Production-Ready Handler Includes:**\r\n- ✅ Path validation with directory traversal protection\r\n- ✅ File extension validation\r\n- ✅ Root directory protection (cannot delete `/memories`)\r\n- ✅ String uniqueness validation for replacements\r\n- ✅ Comprehensive error handling\r\n- ✅ UTF-8 encoding validation\r\n\r\n## Integration with Agents\r\n\r\n### All Agents Use Both\r\n\r\nEvery agent should:\r\n1. **Load CLAUDE.md files** automatically (via Claude Code)\r\n2. **Use memory tool** for learned patterns\r\n3. **Store insights** in memory tool\r\n4. **Sync important patterns** to CLAUDE.md when appropriate\r\n\r\n### Agent-Specific Memory\r\n\r\n- **Orchestrator**: Workflow patterns, routing decisions, coordination strategies\r\n- **Developer**: Implementation patterns, code solutions, debugging insights\r\n- **Architect**: Design patterns, technology choices, architecture decisions\r\n- **QA**: Testing patterns, quality insights, bug patterns\r\n\r\n## Memory Sync Utility\r\n\r\n### Automatic Sync\r\n\r\nThe memory sync utility (`memory-sync.mjs`) can:\r\n- Sync important patterns from memory to CLAUDE.md\r\n- Merge memory insights into project documentation\r\n- Archive old memory files\r\n- Validate memory file integrity\r\n\r\n### Manual Sync\r\n\r\nAgents can manually sync:\r\n1. Identify pattern in memory that should be in CLAUDE.md\r\n2. Read pattern from memory tool\r\n3. Add to appropriate CLAUDE.md file\r\n4. Keep in memory for redundancy\r\n\r\n## Examples\r\n\r\n### Example 1: Storing User Preference\r\n\r\n```\r\nUser: \"I prefer using async/await over promises\"\r\n\r\nAgent stores in memory:\r\n- File: `.claude/context/runs/{run-id}/memory/preferences/coding-style.md`\r\n- Content: \"User prefers async/await syntax over Promise chains for asynchronous code\"\r\n```\r\n\r\n### Example 2: Storing Learned Pattern\r\n\r\n```\r\nAgent discovers: \"Using Zod for validation reduces bugs by 40%\"\r\n\r\nAgent stores in memory:\r\n- File: `.claude/context/runs/{run-id}/memory/patterns/validation-patterns.md`\r\n- Content: \"Zod validation pattern: Use Zod schemas for all API input validation. Reduces bugs by 40%.\"\r\n```\r\n\r\n### Example 3: Reading from Memory\r\n\r\n```\r\nAgent needs to implement authentication\r\n\r\nAgent reads from memory:\r\n- Query: \"authentication implementation patterns\"\r\n- Returns: Relevant patterns from memory files\r\n- Uses patterns to guide implementation\r\n```\r\n\r\n### Example 4: Syncing to CLAUDE.md\r\n\r\n```\r\nAgent discovers important pattern: \"Always use TypeScript strict mode\"\r\n\r\nAgent syncs:\r\n1. Reads from memory: \"typescript-strict-mode-pattern.md\"\r\n2. Adds to .claude/CLAUDE.md: \"TypeScript Configuration: Always use strict mode\"\r\n3. Keeps in memory for redundancy\r\n```\r\n\r\n## Best Practices\r\n\r\n1. **Store Frequently**: Store patterns as you discover them\r\n2. **Read Before Starting**: Check memory for relevant patterns before new tasks\r\n3. **Sync Important Patterns**: Move project-wide patterns to CLAUDE.md\r\n4. **Organize by Category**: Use directory structure for organization\r\n5. **Validate Paths**: Always validate memory file paths\r\n6. **Review Periodically**: Clean up old or outdated memory files\r\n7. **Maintain Redundancy**: Keep important patterns in both systems\r\n\r\n## Troubleshooting\r\n\r\n### Memory Tool Not Available\r\n\r\n- Check that memory tool is enabled in `.claude/config.yaml`\r\n- Verify memory tool is available in agent's tool list\r\n- Ensure memory directory exists and is writable\r\n\r\n### Memory Files Not Persisting\r\n\r\n- Check file permissions on memory directory\r\n- Verify memory tool is writing to correct location\r\n- Check for errors in memory tool execution\r\n\r\n### CLAUDE.md Sync Fails\r\n\r\n- Verify CLAUDE.md file is writable\r\n- Check that pattern is appropriate for CLAUDE.md\r\n- Ensure proper formatting when adding to CLAUDE.md\r\n\r\n",
          "tokens": 2486
        }
      }
    },
    "tool-search": {
      "name": "tool-search",
      "one_liner": "No description",
      "key_commands": [
        "/docs",
        "/PTC_PATTERNS",
        "/ADVANCED_TOOL_USE",
        "/CONTEXT_OPTIMIZATION",
        "/github"
      ],
      "token_count": {
        "minimal": 11,
        "essential": 6,
        "standard": 6,
        "full": 2133
      },
      "levels": {
        "minimal": {
          "content": "**tool-search**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: tool-search\n",
          "tokens": 6
        },
        "standard": {
          "content": "## Skill: tool-search\n",
          "tokens": 6
        },
        "full": {
          "content": "---\r\nname: tool-search\r\ndescription: Semantic tool search with embeddings for scalable tool discovery. Enables on-demand tool loading to reduce context usage by 90%+ for large tool libraries.\r\nallowed-tools: read, write, grep, glob\r\nversion: 1.0\r\nbest_practices:\r\n  - Use for tool libraries with 10+ tools\r\n  - Keep 3-5 most-used tools always loaded\r\n  - Use clear, descriptive tool names\r\n  - Add system prompt guidance\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# Tool Search Skill\r\n\r\n## Identity\r\n\r\nTool Search - Provides semantic tool discovery using embeddings to scale from dozens to thousands of tools with 90%+ context reduction.\r\n\r\n## Capabilities\r\n\r\n- **Semantic Tool Search**: Find relevant tools based on task context\r\n- **Embedding-Based Matching**: Use embeddings for accurate tool discovery\r\n- **On-Demand Loading**: Load tools only when needed\r\n- **Context Efficiency**: 90%+ reduction in tool definition tokens\r\n\r\n## The Problem\r\n\r\nTraditional tool loading:\r\n- All tools loaded upfront\r\n- 58 tools = ~55K tokens\r\n- Context fills quickly\r\n- Hard to scale beyond ~100 tools\r\n\r\n## The Solution\r\n\r\nTool Search with Embeddings:\r\n- Only Tool Search Tool loaded initially (~500 tokens)\r\n- Tools discovered on-demand via semantic search\r\n- 3-5 relevant tools loaded per search (~3K tokens)\r\n- Total: ~8.7K tokens vs. ~77K traditional (85% reduction)\r\n\r\n## How It Works\r\n\r\n1. **Initial State**: Only Tool Search Tool + critical tools loaded\r\n2. **Tool Discovery**: Agent searches for tools based on task\r\n3. **Semantic Matching**: Embeddings match tools to task context\r\n4. **Tool Expansion**: Matching tools expanded into full definitions\r\n5. **Tool Use**: Agent uses discovered tools\r\n\r\n## Configuration\r\n\r\n### MCP Configuration (`.claude/.mcp.json`)\r\n\r\n```json\r\n{\r\n  \"betaFeatures\": [\"advanced-tool-use-2025-11-20\"],\r\n  \"toolSearch\": {\r\n    \"enabled\": true,\r\n    \"autoEnableThreshold\": 20,\r\n    \"defaultDeferLoading\": true\r\n  },\r\n  \"mcpServers\": {\r\n    \"repo\": {\r\n      \"deferLoading\": true,\r\n      \"alwaysLoadTools\": [\"search_code\", \"read_file\"]\r\n    },\r\n    \"github\": {\r\n      \"deferLoading\": true,\r\n      \"alwaysLoadTools\": [\"create_pull_request\", \"get_issue\"]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### Always Load Critical Tools\r\n\r\nKeep 3-5 most-used tools always loaded:\r\n- Core file operations: `read_file`, `write_file`, `search_code`\r\n- Essential integrations: `create_pull_request`, `get_issue`\r\n- Frequently used: `take_screenshot`, `navigate_page`\r\n\r\n## Usage Patterns\r\n\r\n### When to Use Tool Search\r\n\r\n**Most Beneficial When**:\r\n- Tool definitions consuming >10K tokens\r\n- Tool library has 10+ tools\r\n- Experiencing tool selection accuracy issues\r\n- Building MCP-powered systems with multiple servers\r\n\r\n**Less Beneficial When**:\r\n- Small tool library (<10 tools)\r\n- All tools used frequently in every session\r\n- Tool definitions are compact\r\n\r\n### Tool Discovery\r\n\r\n**Agent Workflow**:\r\n1. Agent needs capability (e.g., \"create a pull request\")\r\n2. Agent searches: \"github pull request creation\"\r\n3. Tool Search returns: `create_pull_request` tool\r\n4. Tool expanded into full definition\r\n5. Agent uses tool\r\n\r\n**Example**:\r\n```\r\nUser: \"Create a pull request for my changes\"\r\n\r\nAgent searches: \"github pull request creation\"\r\nTool Search finds: create_pull_request tool\r\nTool loaded and used\r\n```\r\n\r\n## Best Practices\r\n\r\n### 1. Clear Tool Names and Descriptions\r\n\r\n**Good**:\r\n```json\r\n{\r\n  \"name\": \"search_customer_orders\",\r\n  \"description\": \"Search for customer orders by date range, status, or total amount. Returns order details including items, shipping, and payment info.\"\r\n}\r\n```\r\n\r\n**Bad**:\r\n```json\r\n{\r\n  \"name\": \"query_db_orders\",\r\n  \"description\": \"Execute order query\"\r\n}\r\n```\r\n\r\n### 2. System Prompt Guidance\r\n\r\nAdd guidance in agent prompts:\r\n```\r\nYou have access to tools for Slack messaging, Google Drive file management, \r\nJira ticket tracking, and GitHub repository operations. Use the tool search \r\nto find specific capabilities when needed.\r\n```\r\n\r\n### 3. Keep Critical Tools Always Loaded\r\n\r\nDon't defer loading for:\r\n- Core file operations\r\n- Essential integrations\r\n- Frequently used tools\r\n\r\n### 4. Monitor Tool Usage\r\n\r\nTrack which tools are discovered:\r\n- Most searched tools\r\n- Tool discovery patterns\r\n- Context savings achieved\r\n\r\n## Implementation\r\n\r\n### Embedding-Based Tool Search\r\n\r\nThe tool search uses embeddings to match tools to queries:\r\n\r\n1. **Tool Indexing**: Create embeddings for all tool definitions\r\n2. **Query Embedding**: Create embedding for user query\r\n3. **Similarity Search**: Find tools with similar embeddings\r\n4. **Tool Expansion**: Load matching tools into context\r\n\r\n### Tool Search Tool\r\n\r\nThe Tool Search Tool itself:\r\n- Searches tool library semantically\r\n- Returns relevant tools based on query\r\n- Expands tools into full definitions\r\n- Maintains tool index\r\n\r\n## Benefits\r\n\r\n### Context Efficiency\r\n\r\n- **85% reduction** in tool definition tokens\r\n- **52.5% total context** (down from 87%)\r\n- **Within optimal range** (60-70% target)\r\n\r\n### Improved Accuracy\r\n\r\n- **11% improvement** in tool selection accuracy\r\n- **79.5% → 88.1%** (Opus 4.5)\r\n- Better tool matching for complex queries\r\n\r\n### Scalability\r\n\r\n- Scales to **thousands of tools**\r\n- No context limit concerns\r\n- Dynamic tool discovery\r\n\r\n## Examples\r\n\r\n### Example 1: GitHub Operations\r\n\r\n```\r\nUser: \"Create a pull request\"\r\n\r\nAgent workflow:\r\n1. Searches: \"github pull request creation\"\r\n2. Tool Search finds: create_pull_request tool\r\n3. Tool loaded (3K tokens)\r\n4. Agent uses tool\r\n5. Total context: ~8.7K tokens (vs. 55K traditional)\r\n```\r\n\r\n### Example 2: File Operations\r\n\r\n```\r\nUser: \"Search for authentication code\"\r\n\r\nAgent workflow:\r\n1. Searches: \"code search file operations\"\r\n2. Tool Search finds: search_code, read_file tools\r\n3. Tools loaded (5K tokens)\r\n4. Agent uses tools\r\n```\r\n\r\n### Example 3: Multiple Integrations\r\n\r\n```\r\nUser: \"Check Slack messages and create Jira ticket\"\r\n\r\nAgent workflow:\r\n1. Searches: \"slack message reading\"\r\n2. Tool Search finds: read_slack_message tool\r\n3. Searches: \"jira ticket creation\"\r\n4. Tool Search finds: create_jira_ticket tool\r\n5. Both tools loaded (6K tokens total)\r\n```\r\n\r\n## Integration\r\n\r\n### With MCP Servers\r\n\r\nTool search works with MCP servers:\r\n- GitHub MCP: 35 tools → 3-5 loaded on-demand\r\n- Slack MCP: 11 tools → 2-3 loaded on-demand\r\n- Custom MCPs: Any number of tools → Loaded as needed\r\n\r\n### With Agent System\r\n\r\nAll agents benefit from tool search:\r\n- Reduced context usage\r\n- Better tool selection\r\n- Scalable tool libraries\r\n\r\n## Troubleshooting\r\n\r\n### Tools Not Found\r\n\r\n- Check tool names and descriptions are clear\r\n- Verify tool search is enabled\r\n- Review search queries\r\n- Check tool index is up to date\r\n\r\n### Context Still High\r\n\r\n- Verify deferLoading is enabled\r\n- Check alwaysLoadTools list (should be minimal)\r\n- Review tool definitions (may be too verbose)\r\n- Monitor actual tool usage\r\n\r\n### Tool Selection Issues\r\n\r\n- Improve tool descriptions\r\n- Add more context to search queries\r\n- Review tool naming conventions\r\n- Check embedding quality\r\n\r\n## Integration with Programmatic Tool Calling (PTC)\r\n\r\nTool Search works excellently with Programmatic Tool Calling:\r\n\r\n1. **Tool Search** finds relevant tools (on-demand loading)\r\n2. **PTC** orchestrates tools efficiently (reduced context)\r\n3. **Result**: Optimal tool usage with minimal token consumption\r\n\r\n**Example Workflow**:\r\n```python\r\n# Tool Search finds tools\r\ntools = search_tools(\"github issue management\")\r\n\r\n# PTC orchestrates multiple tool calls\r\nteam = await get_team_members(\"engineering\")\r\nissues = await asyncio.gather(*[\r\n    get_issue(member[\"github_username\"]) for member in team\r\n])\r\n# Only final results in context, not all intermediate data\r\n```\r\n\r\nSee [PTC Patterns Guide](../docs/PTC_PATTERNS.md) for comprehensive PTC documentation.\r\n\r\n## Related Documentation\r\n\r\n- [Advanced Tool Use](../docs/ADVANCED_TOOL_USE.md) - Comprehensive tool use guide\r\n- [PTC Patterns](../docs/PTC_PATTERNS.md) - Programmatic Tool Calling patterns\r\n- [Context Optimization](../docs/CONTEXT_OPTIMIZATION.md) - Context management\r\n\r\n## References\r\n\r\n- [Tool Search with Embeddings Cookbook](https://github.com/anthropics/anthropic-cookbook/tree/main/tool_use/tool_search_with_embeddings.ipynb)\r\n- [Programmatic Tool Calling Cookbook](https://github.com/anthropics/anthropic-cookbook/tree/main/tool_use/programmatic_tool_calling_ptc.ipynb)\r\n- [Advanced Tool Use Documentation](https://docs.claude.com/en/docs/agents-and-tools/advanced-tool-use)\r\n\r\n",
          "tokens": 2133
        }
      }
    },
    "mcp-converter": {
      "name": "mcp-converter",
      "one_liner": "No description",
      "key_commands": ["/skills", "/github", "/mcp-converter", "/conversion_rules"],
      "token_count": {
        "minimal": 11,
        "essential": 6,
        "standard": 6,
        "full": 2238
      },
      "levels": {
        "minimal": {
          "content": "**mcp-converter**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: mcp-converter\n",
          "tokens": 6
        },
        "standard": {
          "content": "## Skill: mcp-converter\n",
          "tokens": 6
        },
        "full": {
          "content": "---\r\nname: mcp-converter\r\ndescription: Converts MCP servers to Claude Skills with 90%+ context savings using progressive disclosure pattern. Supports automatic detection and on-demand conversion.\r\nallowed-tools: read, write, bash, grep, glob\r\nversion: 1.0\r\nbest_practices:\r\n  - Convert MCP servers with 10+ tools\r\n  - Keep critical tools (1-5) as MCP\r\n  - Use automatic detection for new MCP servers\r\n  - Validate generated Skills before installation\r\nerror_handling: graceful\r\nstreaming: supported\r\n---\r\n\r\n# MCP-to-Skill Converter Skill\r\n\r\n## Identity\r\n\r\nMCP-to-Skill Converter - Transforms MCP servers into Claude Skills using progressive disclosure to achieve 90%+ context savings while maintaining full functionality.\r\n\r\n## Capabilities\r\n\r\n- **MCP Server Introspection**: Analyze MCP servers to discover tools and capabilities\r\n- **Skill Generation**: Generate complete Skill structure (SKILL.md, executor.py, config)\r\n- **Progressive Disclosure**: Create Skills with metadata-only loading (~100 tokens)\r\n- **Automatic Detection**: Monitor and detect new MCP servers for conversion\r\n- **Validation**: Validate generated Skills before installation\r\n- **Installation**: Install converted Skills to user's Skills directory\r\n\r\n## The Problem\r\n\r\nMCP servers load all tool definitions into context at startup:\r\n- 20+ tools = 30-50k tokens consumed immediately\r\n- Context fills before Claude does any work\r\n- Hard to scale beyond ~100 tools\r\n- Most tools unused in each conversation\r\n\r\n## The Solution\r\n\r\nConvert MCP servers to Skills with progressive disclosure:\r\n- **Startup**: ~100 tokens (metadata only)\r\n- **When used**: ~5k tokens (full instructions)\r\n- **Executing**: 0 tokens (runs externally)\r\n- **Savings**: 90%+ context reduction\r\n\r\n## How It Works\r\n\r\n1. **Introspection**: Connect to MCP server and discover all tools\r\n2. **Analysis**: Calculate token usage and conversion eligibility\r\n3. **Generation**: Create Skill structure with progressive disclosure\r\n4. **Validation**: Verify Skill structure and functionality\r\n5. **Installation**: Install to `~/.claude/skills/`\r\n\r\n## Usage Patterns\r\n\r\n### On-Demand Conversion\r\n\r\n**When to Use**:\r\n- You have an MCP server with 10+ tools\r\n- Context space is critical\r\n- Most tools aren't used in every conversation\r\n- You want maximum context efficiency\r\n\r\n**How to Invoke**:\r\n```\r\n\"Convert the github MCP server to a Skill\"\r\n\"Convert all MCP servers with more than 10 tools\"\r\n\"Convert the custom-server MCP to a Skill\"\r\n```\r\n\r\n**What It Does**:\r\n- Reads MCP server configuration\r\n- Introspects server to discover tools\r\n- Generates Skill structure\r\n- Validates and installs Skill\r\n\r\n### Automatic Detection\r\n\r\n**When Enabled**:\r\n- Monitor `.claude/.mcp.json` for changes\r\n- Detect new MCP servers\r\n- Analyze tool count and token usage\r\n- Auto-convert based on rules\r\n\r\n**Configuration**:\r\n```yaml\r\nauto_convert:\r\n  enabled: true\r\n  threshold:\r\n    tool_count: 10\r\n    estimated_tokens: 5000\r\n  exceptions:\r\n    - github  # Keep as MCP\r\n    - memory  # Keep as MCP\r\n```\r\n\r\n## Skill Structure\r\n\r\nGenerated Skills follow this structure:\r\n\r\n```\r\nskill-name/\r\n├── SKILL.md          # Metadata and instructions (~100 tokens)\r\n├── executor.py       # Dynamic MCP tool execution\r\n└── config.json       # MCP server configuration\r\n```\r\n\r\n### SKILL.md (Progressive Disclosure)\r\n\r\n**Metadata Only** (~100 tokens):\r\n- Skill name and description\r\n- Tool categories\r\n- When to use guidance\r\n- Quick reference\r\n\r\n**Full Instructions** (~5k tokens, loaded when used):\r\n- Complete tool documentation\r\n- Usage examples\r\n- Error handling\r\n- Best practices\r\n\r\n### executor.py\r\n\r\nHandles MCP tool calls dynamically:\r\n- Connects to MCP server\r\n- Executes tool calls\r\n- Returns results\r\n- Handles errors\r\n\r\n## Integration\r\n\r\n### With Tool Search\r\n\r\nSkills work alongside Tool Search:\r\n- **Tool Search**: Semantic discovery of tools\r\n- **Skills**: On-demand tool loading with minimal context\r\n- **Combined**: Optimal context usage for large tool libraries\r\n\r\n### With Skill Builder\r\n\r\nUses Skill Builder plugin for:\r\n- Validation of generated Skills\r\n- Template-based generation\r\n- Testing and verification\r\n- Installation management\r\n\r\n### With Marketplace\r\n\r\nIntegrates with superpowers-marketplace:\r\n- Install marketplace plugins\r\n- Auto-detect MCP servers in plugins\r\n- Convert plugin MCP servers to Skills\r\n- Manage plugin ecosystem\r\n\r\n## Best Practices\r\n\r\n### When to Convert\r\n\r\n**Convert to Skill When**:\r\n- MCP server has 10+ tools\r\n- Most tools unused in each conversation\r\n- Context space is critical\r\n- Tools are independent\r\n\r\n**Keep as MCP When**:\r\n- 1-5 tools (minimal context impact)\r\n- Complex OAuth flows required\r\n- Persistent connections needed\r\n- Cross-platform compatibility critical\r\n\r\n### Critical Tools to Keep as MCP\r\n\r\nKeep these as MCP (always loaded):\r\n- Core file operations: `read_file`, `write_file`, `search_code`\r\n- Essential integrations: `create_pull_request`, `get_issue`\r\n- Frequently used: `take_screenshot`, `navigate_page`\r\n\r\n### Hybrid Approach\r\n\r\n**Best Strategy**: Use both MCP and Skills\r\n- **MCP**: Core tools (1-5 tools, always loaded)\r\n- **Skills**: Extended toolset (10+ tools, on-demand)\r\n- **Tool Search**: Discovery and semantic matching\r\n\r\n## Examples\r\n\r\n### Example 1: Convert GitHub MCP\r\n\r\n```bash\r\n# On-demand conversion\r\n\"Convert the github MCP server to a Skill\"\r\n\r\n# Result: Creates ~/.claude/skills/github/\r\n# - SKILL.md (100 tokens metadata)\r\n# - executor.py (dynamic tool calls)\r\n# - config.json (MCP configuration)\r\n```\r\n\r\n### Example 2: Batch Conversion\r\n\r\n```bash\r\n# Convert multiple MCP servers\r\n\"Convert all MCP servers with more than 10 tools to Skills\"\r\n\r\n# Analyzes all MCP servers\r\n# Converts eligible servers\r\n# Installs all generated Skills\r\n```\r\n\r\n### Example 3: Automatic Detection\r\n\r\n```yaml\r\n# .claude/skills/mcp-converter/conversion_rules.yaml\r\nauto_convert:\r\n  enabled: true\r\n  threshold:\r\n    tool_count: 10\r\n  exceptions:\r\n    - github\r\n    - memory\r\n```\r\n\r\n## Error Handling\r\n\r\n**Common Issues**:\r\n- MCP server not responding: Check configuration and environment variables\r\n- Tool introspection fails: Verify MCP server is accessible\r\n- Skill generation errors: Check templates and validation\r\n- Installation fails: Verify Skills directory permissions\r\n\r\n**Recovery**:\r\n- Retry with verbose logging\r\n- Validate MCP configuration\r\n- Check Skill Builder integration\r\n- Review conversion rules\r\n\r\n## Context Savings\r\n\r\n**Before (MCP)**:\r\n```\r\n20 tools = 30k tokens always loaded\r\nContext available: 170k / 200k = 85%\r\n```\r\n\r\n**After (Skills)**:\r\n```\r\n20 skills = 2k tokens metadata\r\nWhen 1 skill active: 7k tokens\r\nContext available: 193k / 200k = 96.5%\r\n```\r\n\r\n## Dependencies\r\n\r\n- `mcp` Python package (for MCP server introspection)\r\n- Skill Builder plugin (for validation)\r\n- Existing MCP configuration (`.claude/.mcp.json`)\r\n\r\n## Batch Conversion\r\n\r\n**Convert Multiple MCP Servers at Once**:\r\n\r\n```bash\r\n\"Convert all MCP servers from the catalog\"\r\n\"Convert all MCP servers with more than 15 tools\"\r\n\"Convert MCP servers: postgres, aws, docker\"\r\n```\r\n\r\n**Catalog-Based Conversion**:\r\n\r\nThe skill uses `mcp-catalog.yaml` to identify popular MCP servers for conversion:\r\n\r\n- **Automatic Detection**: Servers in catalog are automatically considered\r\n- **Priority-Based**: High priority servers converted first\r\n- **Batch Processing**: Convert multiple servers concurrently (max 3 at a time)\r\n- **Validation**: All converted skills validated before installation\r\n\r\n**Catalog Features**:\r\n- 25+ popular MCP servers pre-configured\r\n- Tool count and token estimates\r\n- Conversion priority levels\r\n- Category tagging\r\n- Keep-as-MCP exceptions (github, filesystem, memory)\r\n\r\n**Batch Conversion Process**:\r\n1. Load `mcp-catalog.yaml` to get server list\r\n2. Filter by conversion criteria (tool count, tokens, priority)\r\n3. Convert servers in parallel (max 3 concurrent)\r\n4. Validate all generated skills\r\n5. Install to `~/.claude/skills/`\r\n6. Generate conversion report\r\n\r\n## Catalog Support\r\n\r\n**Using the MCP Catalog**:\r\n\r\nThe catalog (`mcp-catalog.yaml`) provides:\r\n- **Server Metadata**: Name, description, tool count, token estimates\r\n- **Conversion Rules**: Auto-convert thresholds and exceptions\r\n- **Batch Settings**: Concurrent conversion limits and timeouts\r\n- **Statistics**: Total servers, conversion recommendations\r\n\r\n**Catalog Integration**:\r\n- Catalog automatically loaded when skill is invoked\r\n- Servers filtered by conversion criteria\r\n- Exceptions (keep-as-MCP) respected\r\n- Priority-based conversion order\r\n\r\n**Example Catalog Entry**:\r\n```yaml\r\n- name: postgres\r\n  description: PostgreSQL database operations\r\n  tool_count: 20\r\n  estimated_tokens: 35000\r\n  conversion_priority: high\r\n  keep_as_mcp: false\r\n  categories:\r\n    - database\r\n    - data\r\n```\r\n\r\n## Related Skills\r\n\r\n- **tool-search**: Semantic tool discovery\r\n- **marketplace-manager**: Plugin installation and management\r\n- **memory-manager**: Context persistence\r\n\r\n",
          "tokens": 2238
        }
      }
    },
    "skill-manager": {
      "name": "skill-manager",
      "one_liner": "No description",
      "key_commands": ["/skills", "/skill-manager", "/scripts", "/list", "/validate"],
      "token_count": {
        "minimal": 11,
        "essential": 6,
        "standard": 6,
        "full": 3595
      },
      "levels": {
        "minimal": {
          "content": "**skill-manager**: No description available",
          "tokens": 11
        },
        "essential": {
          "content": "## Skill: skill-manager\n",
          "tokens": 6
        },
        "standard": {
          "content": "## Skill: skill-manager\n",
          "tokens": 6
        },
        "full": {
          "content": "---\r\nname: skill-manager\r\ndescription: Create, validate, install, convert, port, and manage Claude Code skills. Use when users want to create a new skill, validate existing skills, install from GitHub, list skills, convert MCP servers to skills, or port skills between Claude and Gemini platforms. Covers the full skill lifecycle from creation to cross-platform distribution.\r\n---\r\n\r\n# Skill Manager\r\n\r\n## ⚠️ ORCHESTRATION NOTICE\r\n\r\n**If you are an orchestrator invoking this skill for bulk operations (e.g., \"validate all skills\", \"review all skills\", \"fix all skills\"), you MUST:**\r\n\r\n1. **Spawn a subagent** using the Task tool with `subagent_type=\"developer\"` or `subagent_type=\"qa\"`\r\n2. **Pass the task** to the subagent with clear instructions\r\n3. **DO NOT** read skill files directly yourself\r\n\r\n**Example proper delegation:**\r\n```\r\nTask: developer\r\nPrompt: \"Use the skill-manager skill to validate all skills in .claude/skills/.\r\nRun: node .claude/skills/skill-manager/scripts/list.cjs --format json\r\nThen validate each skill with: node .claude/skills/skill-manager/scripts/validate.cjs <path>\r\nFix any issues found in the SKILL.md frontmatter.\"\r\n```\r\n\r\n---\r\n\r\nUnified skill for managing Claude Code skills: create, validate, install, list, convert MCP servers, and port between Claude/Gemini platforms.\r\n\r\n## Quick Reference\r\n\r\n| Operation | Command |\r\n|-----------|---------|\r\n| Create new skill | `node scripts/create.cjs <name> [--resources scripts,references,assets] [--no-test]` |\r\n| Validate skill | `node scripts/validate.cjs <path>` |\r\n| Install from GitHub | `node scripts/install.cjs --repo owner/repo --path path/to/skill` |\r\n| List installed | `node scripts/list.cjs` |\r\n| List from repo | `node scripts/list.cjs --repo owner/repo --path skills/` |\r\n| Convert MCP to skill | `node scripts/convert.cjs --server <name>` |\r\n| Convert from URL/name | `node scripts/convert.cjs <name-or-url>` |\r\n| List known servers | `node scripts/convert.cjs --known` |\r\n| List MCP servers | `node scripts/convert.cjs --list` |\r\n| Show MCP catalog | `node scripts/convert.cjs --catalog` |\r\n| Test a skill | `node scripts/test.cjs <path>` |\r\n| Port to Gemini | `node scripts/port.cjs <path> --to gemini` |\r\n| Port to Claude | `node scripts/port.cjs <path> --to claude` |\r\n| Make universal | `node scripts/port.cjs <path> --universal` |\r\n| Analyze platform | `node scripts/port.cjs <path> --analyze` |\r\n\r\n## Creating Skills\r\n\r\n### Skill Structure\r\n\r\n```\r\nskill-name/\r\n├── SKILL.md              # Required: Frontmatter + instructions\r\n├── scripts/              # Optional: Executable code\r\n├── references/           # Optional: Documentation to load as needed\r\n└── assets/               # Optional: Templates, images, fonts\r\n```\r\n\r\n### SKILL.md Format\r\n\r\n```yaml\r\n---\r\nname: skill-name\r\ndescription: What the skill does and WHEN to use it. Include triggers.\r\n---\r\n\r\n# Skill Title\r\n\r\nInstructions for using the skill...\r\n```\r\n\r\n### Create Command\r\n\r\n```bash\r\n# Basic skill (auto-tests after creation)\r\nnode scripts/create.cjs my-skill\r\n\r\n# With resource directories\r\nnode scripts/create.cjs my-skill --resources scripts,references\r\n\r\n# With example files\r\nnode scripts/create.cjs my-skill --resources scripts,references,assets --examples\r\n\r\n# Custom location\r\nnode scripts/create.cjs my-skill --path /custom/path\r\n\r\n# Skip auto-testing\r\nnode scripts/create.cjs my-skill --no-test\r\n```\r\n\r\n**Note**: Skills are automatically validated after creation. New skills will show TODO warnings - this is expected until you complete the SKILL.md template.\r\n\r\n### Core Principles\r\n\r\n**Concise is Key**: The context window is shared. Only add what Claude doesn't already know.\r\n\r\n**Progressive Disclosure**:\r\n1. Metadata (name + description) - Always loaded (~100 words)\r\n2. SKILL.md body - When skill triggers (<500 lines)\r\n3. Bundled resources - As needed (unlimited)\r\n\r\n**Degrees of Freedom**:\r\n- High freedom (text instructions): Multiple valid approaches\r\n- Medium freedom (pseudocode/parameters): Preferred pattern with variation\r\n- Low freedom (specific scripts): Fragile operations requiring consistency\r\n\r\n## Validating Skills\r\n\r\n```bash\r\nnode scripts/validate.cjs .claude/skills/my-skill\r\n```\r\n\r\nChecks:\r\n- SKILL.md exists with valid YAML frontmatter\r\n- Required fields: `name`, `description`\r\n- Name format: lowercase, hyphens, digits only\r\n- Description: No angle brackets, max 1024 chars\r\n- No TODO placeholders in production skills\r\n\r\n## Installing Skills\r\n\r\n### From GitHub Repository\r\n\r\n```bash\r\n# Using repo + path\r\nnode scripts/install.cjs --repo owner/repo --path path/to/skill\r\n\r\n# Using full URL\r\nnode scripts/install.cjs --url https://github.com/owner/repo/tree/main/skills/my-skill\r\n\r\n# Multiple skills\r\nnode scripts/install.cjs --repo owner/repo --path skills/skill-1 skills/skill-2\r\n\r\n# Specific branch/tag\r\nnode scripts/install.cjs --repo owner/repo --path skills/my-skill --ref v1.0.0\r\n\r\n# Custom destination\r\nnode scripts/install.cjs --repo owner/repo --path skills/my-skill --dest ./custom/skills\r\n```\r\n\r\n### Install Behavior\r\n\r\n- Downloads via GitHub API (public repos) or git sparse checkout (private repos)\r\n- Validates SKILL.md exists before installing\r\n- Installs to `.claude/skills/<skill-name>/` by default\r\n- Aborts if destination already exists\r\n- Supports `GITHUB_TOKEN` or `GH_TOKEN` for private repos\r\n\r\n## Listing Skills\r\n\r\n```bash\r\n# List installed skills\r\nnode scripts/list.cjs\r\n\r\n# List skills from a GitHub repo\r\nnode scripts/list.cjs --repo owner/repo --path skills/\r\n\r\n# JSON output\r\nnode scripts/list.cjs --format json\r\n```\r\n\r\n## Converting MCP Servers to Skills\r\n\r\nConvert MCP servers to skills for 90%+ context savings. Instead of loading all MCP tools into context at startup, skills use progressive disclosure.\r\n\r\n### Why Convert?\r\n\r\n| Mode | Context Usage | When Loaded |\r\n|------|---------------|-------------|\r\n| MCP Server | ~30k tokens | Always (startup) |\r\n| Skill | ~500 tokens | On-demand |\r\n\r\n### Convert Without .mcp.json (Recommended)\r\n\r\nFor official MCP servers, you can convert directly without adding to .mcp.json first:\r\n\r\n```bash\r\n# Convert by name (known servers - npm)\r\nnode scripts/convert.cjs filesystem\r\nnode scripts/convert.cjs puppeteer\r\nnode scripts/convert.cjs slack\r\n\r\n# Convert by name (known servers - PyPI)\r\nnode scripts/convert.cjs git\r\nnode scripts/convert.cjs time\r\nnode scripts/convert.cjs sentry\r\n\r\n# Convert from GitHub URL\r\nnode scripts/convert.cjs https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem\r\nnode scripts/convert.cjs https://github.com/modelcontextprotocol/servers/tree/main/src/git\r\n\r\n# List all known servers (npm + PyPI)\r\nnode scripts/convert.cjs --known\r\n```\r\n\r\n**Known servers** are built-in with correct package names and environment variables. The converter supports both:\r\n- **npm servers**: Node.js packages (14 servers: filesystem, memory, github, slack, etc.)\r\n- **PyPI servers**: Python packages (9 servers: git, time, sentry, aws-kb-retrieval, etc.)\r\n\r\nRun `--known` to see the full list.\r\n\r\n### Convert from .mcp.json\r\n\r\nFor servers already in your `.mcp.json`, or third-party servers:\r\n\r\n```bash\r\n# List configured MCP servers with conversion eligibility\r\nnode scripts/convert.cjs --list\r\n\r\n# Convert specific server from .mcp.json\r\nnode scripts/convert.cjs --server slack\r\n\r\n# Show catalog with tool counts and token estimates\r\nnode scripts/convert.cjs --catalog\r\n```\r\n\r\n### Convert Options\r\n\r\n```bash\r\n# Dry run (show what would happen)\r\nnode scripts/convert.cjs filesystem --dry-run\r\n\r\n# Overwrite existing skill\r\nnode scripts/convert.cjs filesystem --force\r\n\r\n# Skip automatic testing\r\nnode scripts/convert.cjs filesystem --no-test\r\n\r\n# Convert all eligible servers from .mcp.json\r\nnode scripts/convert.cjs --all\r\n```\r\n\r\n### Generated Files\r\n\r\nConverted skills include:\r\n- `SKILL.md`: Progressive disclosure documentation\r\n- `executor.py`: Python wrapper for MCP tool calls (with path auto-detection for servers like git)\r\n- `config.json`: MCP server configuration\r\n\r\n**Python servers** (PyPI) generate executors with special path handling:\r\n- `git`: Auto-detects git repository root\r\n- Future: Other servers may auto-detect project roots, working directories, etc.\r\n\r\n### Catalog Integration\r\n\r\nThe converter uses `.claude/skills/mcp-converter/mcp-catalog.yaml` for:\r\n- Tool count estimates\r\n- Token usage estimates\r\n- Conversion priority\r\n- Keep-as-MCP exceptions (github, filesystem, memory)\r\n\r\n### When to Keep as MCP\r\n\r\nSome servers work better as MCP (always loaded):\r\n- **github**: Frequently used for PRs/issues\r\n- **filesystem**: Core file operations\r\n- **memory**: Always needed for context\r\n\r\nThe catalog marks these with `keep_as_mcp: true`.\r\n\r\n## Testing Skills\r\n\r\nSkills are automatically tested after conversion. You can also run tests manually:\r\n\r\n```bash\r\n# Test a skill (validation + introspection if executor exists)\r\nnode scripts/test.cjs .claude/skills/my-skill\r\n\r\n# Test with specific tool call\r\nnode scripts/test.cjs .claude/skills/sequential-thinking --call sequentialthinking --args '{\"thought\": \"test\", \"thoughtNumber\": 1, \"totalThoughts\": 1, \"nextThoughtNeeded\": false}'\r\n\r\n# Skip introspection\r\nnode scripts/test.cjs .claude/skills/my-skill --no-validate\r\n\r\n# JSON output\r\nnode scripts/test.cjs .claude/skills/my-skill --json\r\n```\r\n\r\n### What Gets Tested\r\n\r\n1. **Validation**: Checks SKILL.md structure and frontmatter\r\n2. **Introspection**: Runs `executor.py --list` to verify MCP connection\r\n3. **Tool Call** (optional): Calls a specific tool with test arguments\r\n\r\n### Automatic Testing on Convert\r\n\r\nWhen using `convert.cjs`, tests run automatically after conversion:\r\n\r\n```bash\r\n# Converts and tests\r\nnode scripts/convert.cjs --server slack\r\n\r\n# Skip testing\r\nnode scripts/convert.cjs --server slack --no-test\r\n```\r\n\r\n## Skill Design Patterns\r\n\r\n### Pattern 1: Workflow-Based (Sequential Processes)\r\n\r\n```markdown\r\n## Workflow Decision Tree\r\n1. If creating new → Section A\r\n2. If editing existing → Section B\r\n\r\n## Section A: Creating\r\nStep-by-step instructions...\r\n```\r\n\r\n### Pattern 2: Task-Based (Tool Collections)\r\n\r\n```markdown\r\n## Quick Start\r\nBasic usage example...\r\n\r\n## Merge PDFs\r\nInstructions for merging...\r\n\r\n## Extract Text\r\nInstructions for extraction...\r\n```\r\n\r\n### Pattern 3: Reference-Based (Standards/Specs)\r\n\r\n```markdown\r\n## Guidelines\r\nCore principles...\r\n\r\n## Specifications\r\nDetailed specs...\r\n```\r\n\r\n### Pattern 4: Progressive Disclosure\r\n\r\n```markdown\r\n## Quick Start\r\nBasic example here...\r\n\r\n## Advanced Features\r\n- **Form filling**: See [references/forms.md](references/forms.md)\r\n- **API reference**: See [references/api.md](references/api.md)\r\n```\r\n\r\n## Resource Guidelines\r\n\r\n### scripts/\r\nExecutable code for deterministic operations.\r\n- When: Same code rewritten repeatedly, needs reliability\r\n- Example: `rotate_pdf.py`, `convert_image.py`\r\n\r\n### references/\r\nDocumentation loaded into context as needed.\r\n- When: Detailed info needed only for specific tasks\r\n- Example: `api_reference.md`, `schema.md`\r\n\r\n### assets/\r\nFiles used in output, not loaded into context.\r\n- When: Templates, images, fonts for final output\r\n- Example: `template.pptx`, `logo.png`\r\n\r\n## What NOT to Include\r\n\r\n- README.md, CHANGELOG.md, INSTALLATION_GUIDE.md\r\n- User-facing documentation\r\n- Setup/testing procedures\r\n- Process documentation\r\n\r\nThe skill should only contain what Claude needs to do the job.\r\n\r\n## Porting Skills (Cross-Platform Conversion)\r\n\r\nConvert skills between Claude Code and Gemini CLI platforms. Based on [skill-porter](https://github.com/jduncan-rva/skill-porter).\r\n\r\n### Why Port?\r\n\r\n- **Write once, deploy to both**: Create a skill for Claude, port it to Gemini (or vice versa)\r\n- **~85% code reuse**: MCP server configurations are 100% reusable across platforms\r\n- **Automatic translation**: Tool restrictions (allowlist ↔ denylist), paths, and metadata transform automatically\r\n\r\n### Platform Detection\r\n\r\n```bash\r\n# Analyze a skill/extension to detect its platform\r\nnode scripts/port.cjs ./my-skill --analyze\r\n```\r\n\r\nOutput shows:\r\n- Detected platform (claude, gemini, universal, unknown)\r\n- Platform-specific files found\r\n- Metadata from config files\r\n- Conversion recommendations\r\n\r\n### Convert to Gemini\r\n\r\n```bash\r\n# Convert Claude skill to Gemini extension\r\nnode scripts/port.cjs .claude/skills/my-skill --to gemini\r\n\r\n# Custom output path\r\nnode scripts/port.cjs .claude/skills/my-skill --to gemini --output ./gemini-extensions/my-skill\r\n\r\n# Force overwrite\r\nnode scripts/port.cjs .claude/skills/my-skill --to gemini --force\r\n```\r\n\r\n**What gets converted:**\r\n- `SKILL.md` → `gemini-extension.json` + `GEMINI.md`\r\n- `config.json` → MCP server entries in manifest\r\n- `allowed-tools` (allowlist) → `excludeTools` (denylist)\r\n- `scripts/` → `servers/`\r\n- Environment variables → Settings schema\r\n\r\n### Convert to Claude\r\n\r\n```bash\r\n# Convert Gemini extension to Claude skill\r\nnode scripts/port.cjs ./gemini-ext --to claude\r\n\r\n# Custom output path\r\nnode scripts/port.cjs ./gemini-ext --to claude --output .claude/skills/converted\r\n```\r\n\r\n**What gets converted:**\r\n- `gemini-extension.json` → `SKILL.md` frontmatter\r\n- `GEMINI.md` → `SKILL.md` body\r\n- `excludeTools` (denylist) → `allowed-tools` (allowlist)\r\n- `servers/` → `scripts/`\r\n- Settings → Environment variables in `config.json`\r\n\r\n### Make Universal\r\n\r\n```bash\r\n# Add support for both platforms\r\nnode scripts/port.cjs .claude/skills/my-skill --universal\r\n\r\n# Custom output (creates new directory with both formats)\r\nnode scripts/port.cjs .claude/skills/my-skill --universal --output ./universal-skill\r\n```\r\n\r\nThis creates a skill that works on both Claude Code and Gemini CLI by including:\r\n- `SKILL.md` (Claude)\r\n- `gemini-extension.json` + `GEMINI.md` (Gemini)\r\n- Shared resources in `shared/`\r\n\r\n### Tool Restriction Mapping\r\n\r\n| Claude (allowlist) | Gemini (denylist) |\r\n|--------------------|-------------------|\r\n| `allowed-tools: [Read, Write]` | `excludeTools: [Edit, Bash, Glob, Grep, WebFetch, ...]` |\r\n| `allowed-tools: []` (all allowed) | `excludeTools: []` (none excluded) |\r\n\r\n### Path Variable Mapping\r\n\r\n| Claude | Gemini |\r\n|--------|--------|\r\n| `${skillPath}` | `${extensionPath}` |\r\n\r\n### Limitations\r\n\r\n- Slash commands (Claude) ↔ TOML commands (Gemini) require manual adjustment\r\n- Complex subagent configurations may need review\r\n- Platform-specific tool names should be verified after conversion\r\n",
          "tokens": 3595
        }
      }
    },
    "filesystem": {
      "name": "filesystem",
      "one_liner": "File system operations - read, write, list directories. Converted from MCP server for 90%+ context savings.",
      "key_commands": ["/renaming", "/path", "/to", "/file", "/dir"],
      "token_count": {
        "minimal": 31,
        "essential": 33,
        "standard": 33,
        "full": 3243
      },
      "levels": {
        "minimal": {
          "content": "**filesystem**: File system operations - read, write, list directories. Converted from MCP server for 90%+ context savings.",
          "tokens": 31
        },
        "essential": {
          "content": "## Skill: filesystem\n\nFile system operations - read, write, list directories. Converted from MCP server for 90%+ context savings.\n",
          "tokens": 33
        },
        "standard": {
          "content": "## Skill: filesystem\n\nFile system operations - read, write, list directories. Converted from MCP server for 90%+ context savings.\n",
          "tokens": 33
        },
        "full": {
          "content": "---\nname: filesystem\ndescription: File system operations - read, write, list directories. Converted from MCP server for 90%+ context savings.\nallowed-tools: read, write, bash\nversion: 1.0\nbest_practices:\n  - Verify allowed directories with list_allowed_directories first\n  - Use read_multiple_files for batch operations\n  - Use edit_file for surgical changes instead of read-modify-write\n  - Always specify paths relative to allowed directories\nerror_handling: graceful\n---\n\n# Filesystem Skill\n\n## Overview\n\nThis skill provides comprehensive file system operations for AI agents. It offers 14 tools for reading, writing, editing, searching, and managing files and directories.\n\n**Context Savings**: ~97% reduction\n- **MCP Mode**: ~18,000 tokens always loaded\n- **Skill Mode**: ~500 tokens metadata + on-demand loading\n\n## When to Use\n\n- Reading single or multiple files\n- Creating or modifying files and directories\n- Searching for files by pattern\n- Listing directory contents\n- Moving/renaming files\n- Getting file metadata and statistics\n- Verifying allowed directory access\n\n## Quick Reference\n\n```bash\n# List available tools\npython executor.py --list\n\n# Read a file\npython executor.py --tool read_text_file --args '{\"path\": \"/path/to/file.txt\"}'\n\n# Write a file\npython executor.py --tool write_file --args '{\"path\": \"/path/to/file.txt\", \"content\": \"Hello World\"}'\n\n# List directory\npython executor.py --tool list_directory --args '{\"path\": \"/path/to/dir\"}'\n\n# Search for files\npython executor.py --tool search_files --args '{\"path\": \"/project\", \"pattern\": \"**/*.ts\"}'\n\n# Check allowed directories\npython executor.py --tool list_allowed_directories --args '{}'\n```\n\n## Tools\n\n### Reading Files (4 tools)\n\n#### read_text_file\n\nRead complete contents of a text file. Handles various encodings with detailed error messages.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `path` | string | Yes | File path to read |\n| `tail` | number | No | Read only last N lines |\n| `head` | number | No | Read only first N lines |\n\n```bash\n# Read entire file\npython executor.py --tool read_text_file --args '{\"path\": \"/project/README.md\"}'\n\n# Read first 10 lines\npython executor.py --tool read_text_file --args '{\"path\": \"/logs/app.log\", \"head\": 10}'\n\n# Read last 50 lines\npython executor.py --tool read_text_file --args '{\"path\": \"/logs/app.log\", \"tail\": 50}'\n```\n\n#### read_file\n\n**DEPRECATED**: Use `read_text_file` instead. Same parameters and functionality.\n\n```bash\npython executor.py --tool read_file --args '{\"path\": \"/path/to/file.txt\"}'\n```\n\n#### read_media_file\n\nRead image or audio files. Returns base64-encoded data with MIME type.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `path` | string | Yes | Path to media file |\n\n```bash\n# Read an image\npython executor.py --tool read_media_file --args '{\"path\": \"/images/logo.png\"}'\n\n# Read an audio file\npython executor.py --tool read_media_file --args '{\"path\": \"/audio/sound.mp3\"}'\n```\n\n#### read_multiple_files\n\nRead multiple files simultaneously - more efficient than one-by-one reads.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `paths` | array | Yes | Array of file paths to read |\n\n```bash\n# Read multiple files at once\npython executor.py --tool read_multiple_files --args '{\"paths\": [\"/src/app.ts\", \"/src/config.ts\", \"/src/utils.ts\"]}'\n```\n\n### Writing Files (2 tools)\n\n#### write_file\n\nCreate new file or completely overwrite existing file. **Use with caution** - overwrites without warning.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `path` | string | Yes | File path to write |\n| `content` | string | Yes | File content |\n\n```bash\n# Create new file\npython executor.py --tool write_file --args '{\"path\": \"/project/config.json\", \"content\": \"{\\\"env\\\": \\\"prod\\\"}\"}'\n\n# Overwrite existing file\npython executor.py --tool write_file --args '{\"path\": \"/project/README.md\", \"content\": \"# New README\"}'\n```\n\n#### edit_file\n\nMake line-based edits to text files. Replaces exact line sequences with new content. Returns git-style diff.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `path` | string | Yes | File path to edit |\n| `edits` | array | Yes | Array of edit objects |\n| `dryRun` | boolean | No | Preview changes without applying |\n\n**Edit Object Structure**:\n```json\n{\n  \"oldText\": \"exact text to replace\",\n  \"newText\": \"replacement text\"\n}\n```\n\n```bash\n# Edit a file (dry run)\npython executor.py --tool edit_file --args '{\"path\": \"/src/app.ts\", \"edits\": [{\"oldText\": \"const port = 3000;\", \"newText\": \"const port = 8080;\"}], \"dryRun\": true}'\n\n# Apply the edit\npython executor.py --tool edit_file --args '{\"path\": \"/src/app.ts\", \"edits\": [{\"oldText\": \"const port = 3000;\", \"newText\": \"const port = 8080;\"}]}'\n```\n\n### Directory Operations (4 tools)\n\n#### create_directory\n\nCreate directory or ensure it exists. Creates nested directories in one operation. Succeeds silently if directory exists.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `path` | string | Yes | Directory path to create |\n\n```bash\n# Create single directory\npython executor.py --tool create_directory --args '{\"path\": \"/project/dist\"}'\n\n# Create nested directories\npython executor.py --tool create_directory --args '{\"path\": \"/project/src/components/auth\"}'\n```\n\n#### list_directory\n\nGet detailed listing of files and directories. Results prefixed with `[FILE]` or `[DIR]`.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `path` | string | Yes | Directory path to list |\n\n```bash\n# List directory contents\npython executor.py --tool list_directory --args '{\"path\": \"/project/src\"}'\n```\n\n#### list_directory_with_sizes\n\nList directory contents with file sizes. Can sort by name or size.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `path` | string | Yes | Directory path to list |\n| `sortBy` | string | No | Sort by \"name\" or \"size\" (default: \"name\") |\n\n```bash\n# List with sizes (sorted by name)\npython executor.py --tool list_directory_with_sizes --args '{\"path\": \"/project/dist\"}'\n\n# List with sizes (sorted by size)\npython executor.py --tool list_directory_with_sizes --args '{\"path\": \"/project/dist\", \"sortBy\": \"size\"}'\n```\n\n#### directory_tree\n\nGet recursive tree view as JSON. Each entry includes name, type (file/directory), and children array.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `path` | string | Yes | Root directory path |\n| `excludePatterns` | array | No | Glob patterns to exclude |\n\n```bash\n# Get full tree\npython executor.py --tool directory_tree --args '{\"path\": \"/project/src\"}'\n\n# Exclude node_modules and build directories\npython executor.py --tool directory_tree --args '{\"path\": \"/project\", \"excludePatterns\": [\"node_modules\", \"dist\", \"build\"]}'\n```\n\n### File Management (2 tools)\n\n#### move_file\n\nMove or rename files and directories. **Fails if destination exists**. Works across directories.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `source` | string | Yes | Source path |\n| `destination` | string | Yes | Destination path |\n\n```bash\n# Rename a file\npython executor.py --tool move_file --args '{\"source\": \"/project/old.txt\", \"destination\": \"/project/new.txt\"}'\n\n# Move to different directory\npython executor.py --tool move_file --args '{\"source\": \"/project/file.txt\", \"destination\": \"/archive/file.txt\"}'\n```\n\n#### search_files\n\nRecursively search for files matching glob patterns. Patterns are relative to working directory.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `path` | string | Yes | Root path to search |\n| `pattern` | string | Yes | Glob pattern to match |\n| `excludePatterns` | array | No | Patterns to exclude |\n\n**Pattern Examples**:\n- `*.ext` - Files in current directory\n- `**/*.ext` - Files in all subdirectories\n- `**/test-*.ts` - Test files in all subdirectories\n\n```bash\n# Find all TypeScript files\npython executor.py --tool search_files --args '{\"path\": \"/project/src\", \"pattern\": \"**/*.ts\"}'\n\n# Find test files, exclude node_modules\npython executor.py --tool search_files --args '{\"path\": \"/project\", \"pattern\": \"**/*.test.ts\", \"excludePatterns\": [\"node_modules\"]}'\n\n# Find all JSON configs\npython executor.py --tool search_files --args '{\"path\": \"/project\", \"pattern\": \"**/*.json\"}'\n```\n\n### File Information (2 tools)\n\n#### get_file_info\n\nRetrieve detailed metadata about a file or directory. Returns size, timestamps, permissions, and type.\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `path` | string | Yes | File or directory path |\n\n```bash\n# Get file info\npython executor.py --tool get_file_info --args '{\"path\": \"/project/package.json\"}'\n\n# Get directory info\npython executor.py --tool get_file_info --args '{\"path\": \"/project/src\"}'\n```\n\n#### list_allowed_directories\n\nReturns list of directories accessible to the server. Subdirectories within these are also accessible.\n\n```bash\n# Check allowed directories\npython executor.py --tool list_allowed_directories --args '{}'\n```\n\n## Common Workflows\n\n### Reading Files\n\n```bash\n# 1. Check allowed directories\npython executor.py --tool list_allowed_directories --args '{}'\n\n# 2. List directory to find files\npython executor.py --tool list_directory --args '{\"path\": \"/project/src\"}'\n\n# 3. Read single file\npython executor.py --tool read_text_file --args '{\"path\": \"/project/src/app.ts\"}'\n\n# 4. Read multiple files at once (more efficient)\npython executor.py --tool read_multiple_files --args '{\"paths\": [\"/project/src/app.ts\", \"/project/src/config.ts\", \"/project/src/utils.ts\"]}'\n```\n\n### Searching and Analyzing\n\n```bash\n# 1. Search for files by pattern\npython executor.py --tool search_files --args '{\"path\": \"/project\", \"pattern\": \"**/*.test.ts\"}'\n\n# 2. Get directory tree structure\npython executor.py --tool directory_tree --args '{\"path\": \"/project/src\", \"excludePatterns\": [\"node_modules\"]}'\n\n# 3. Get file sizes\npython executor.py --tool list_directory_with_sizes --args '{\"path\": \"/project/dist\", \"sortBy\": \"size\"}'\n\n# 4. Get specific file metadata\npython executor.py --tool get_file_info --args '{\"path\": \"/project/package.json\"}'\n```\n\n### Creating and Modifying Files\n\n```bash\n# 1. Create directory structure\npython executor.py --tool create_directory --args '{\"path\": \"/project/src/components/auth\"}'\n\n# 2. Write new file\npython executor.py --tool write_file --args '{\"path\": \"/project/src/components/auth/Login.tsx\", \"content\": \"export const Login = () => {};\"}'\n\n# 3. Edit existing file (dry run first)\npython executor.py --tool edit_file --args '{\"path\": \"/project/src/config.ts\", \"edits\": [{\"oldText\": \"DEBUG = false\", \"newText\": \"DEBUG = true\"}], \"dryRun\": true}'\n\n# 4. Apply edit\npython executor.py --tool edit_file --args '{\"path\": \"/project/src/config.ts\", \"edits\": [{\"oldText\": \"DEBUG = false\", \"newText\": \"DEBUG = true\"}]}'\n```\n\n### File Organization\n\n```bash\n# 1. Search for files to organize\npython executor.py --tool search_files --args '{\"path\": \"/project\", \"pattern\": \"**/*.log\"}'\n\n# 2. Create archive directory\npython executor.py --tool create_directory --args '{\"path\": \"/project/archive/logs\"}'\n\n# 3. Move files\npython executor.py --tool move_file --args '{\"source\": \"/project/old.log\", \"destination\": \"/project/archive/logs/old.log\"}'\n```\n\n## Configuration\n\nMCP server configuration stored in `config.json`:\n- **Command**: `npx`\n- **Args**: `[\"-y\", \"@modelcontextprotocol/server-filesystem\"]`\n- **Allowed Directories**: Specified via command-line args or MCP roots protocol\n\n### Allowed Directories\n\nThe server restricts access to explicitly allowed directories:\n\n1. **Command-line**: `npx @modelcontextprotocol/server-filesystem /allowed/dir1 /allowed/dir2`\n2. **MCP Roots Protocol**: Client provides roots dynamically\n\n**Important**: At least one directory must be allowed for server to operate.\n\n## Error Handling\n\n**Common Issues**:\n- Path not allowed: Check allowed directories with `list_allowed_directories`\n- File not found: Verify path exists with `get_file_info`\n- Permission denied: Check file permissions\n- Destination exists: Use different path for `move_file`\n- Edit failed: Verify `oldText` matches exactly\n\n**Recovery**:\n- Always check allowed directories first\n- Use `get_file_info` to verify file existence\n- Use `list_directory` to verify parent directory\n- Use `edit_file` with `dryRun: true` to preview changes\n- Handle errors gracefully - failed file reads don't stop batch operations\n\n## Related\n\n- Original MCP: `@modelcontextprotocol/server-filesystem`\n- Git Skill: `.claude/skills/git/`\n- MCP Converter: `.claude/skills/mcp-converter/`\n- Skill Manager: `.claude/skills/skill-manager/`\n",
          "tokens": 3243
        }
      }
    },
    "sdk": {
      "name": "sdk",
      "one_liner": "No description",
      "key_commands": ["/context", "/cache", "/skill-cache", "/skills", "/sdk"],
      "token_count": {
        "minimal": 9,
        "essential": 4,
        "standard": 4,
        "full": 913
      },
      "levels": {
        "minimal": {
          "content": "**sdk**: No description available",
          "tokens": 9
        },
        "essential": {
          "content": "## Skill: sdk\n",
          "tokens": 4
        },
        "standard": {
          "content": "## Skill: sdk\n",
          "tokens": 4
        },
        "full": {
          "content": "---\r\nname: sdk\r\ndescription: Skill SDK utilities for loading, registering, and managing skills with caching and auto-selection\r\n---\r\n\r\n# Skill SDK\r\n\r\nThis is not a user-facing skill - it's a **utility SDK** that provides infrastructure for the skill system.\r\n\r\n## Purpose\r\n\r\nThe SDK directory contains core utilities that power the skill system:\r\n\r\n1. **skill-loader.mjs**: Loads skill instructions and metadata with intelligent caching\r\n2. **skill-registry.mjs**: Registers skills and integrates with Anthropic Agent SDK patterns\r\n\r\n## Components\r\n\r\n### skill-loader.mjs\r\n\r\nProvides functions for loading and caching skill instructions:\r\n\r\n- `loadSkillInstructions(skillName, useCache)`: Load skill instructions from SKILL.md\r\n- `loadSkillMetadata(skillName)`: Extract YAML frontmatter metadata\r\n- `getAllSkillNames()`: Get list of all available skills\r\n- `autoSelectSkills(query, maxResults)`: Intelligently select skills based on query\r\n- `clearCache()`: Clear skill cache\r\n- `getCacheStats()`: Get cache statistics\r\n\r\n**Caching**: Skills are cached in `.claude/context/cache/skill-cache.json` for performance.\r\n\r\n### skill-registry.mjs\r\n\r\nIntegrates skills with Anthropic Agent SDK patterns:\r\n\r\n- `registerSkill(skillName)`: Register a skill and parse its metadata\r\n- `getAllSkills()`: Get all registered skills\r\n- `getSkill(skillName)`: Retrieve a registered skill\r\n- `registerSkillWithSDK(skillName)`: Create SDK-compatible skill object\r\n- `initializeSkills()`: Initialize all skills on startup\r\n- `invokeSkill(skillName, input, context)`: Invoke a skill with context\r\n- `createSDKSkill(skillConfig)`: Create SDK skill instance\r\n\r\n## Usage\r\n\r\nThese utilities are used internally by the skill system and skill-manager. They are not invoked directly by users.\r\n\r\n**Example (internal use)**:\r\n```javascript\r\nimport { loadSkillInstructions, autoSelectSkills } from '.claude/skills/sdk/skill-loader.mjs';\r\n\r\n// Load specific skill\r\nconst instructions = await loadSkillInstructions('rule-auditor');\r\n\r\n// Auto-select relevant skills\r\nconst skills = await autoSelectSkills('audit code for violations', 3);\r\n// Returns: ['rule-auditor', 'code-style-validator', 'fixing-rule-violations']\r\n```\r\n\r\n## Skill Format\r\n\r\nAll skills must follow this format in their SKILL.md:\r\n\r\n```markdown\r\n---\r\nname: skill-name\r\ndescription: Brief description\r\nallowed-tools: tool1, tool2\r\nversion: 1.0.0\r\n---\r\n\r\n# Skill Instructions\r\n\r\nDetailed instructions for the skill...\r\n```\r\n\r\n## Auto-Selection Algorithm\r\n\r\nThe auto-selection algorithm scores skills based on:\r\n\r\n1. **Name match** (10 points): Skill name contains query words\r\n2. **Description match** (5 points per word): Description contains query words\r\n3. **Tool match** (3 points per word): Allowed tools contain query words\r\n\r\nTop N skills by score are returned.\r\n\r\n## Cache Management\r\n\r\n- **Cache Location**: `.claude/context/cache/skill-cache.json`\r\n- **Cache Contents**: Skill instructions and metadata\r\n- **Cache Invalidation**: Manual via `clearCache()` or by deleting cache file\r\n- **Performance**: 90%+ reduction in disk I/O for repeated skill loads\r\n\r\n## Integration Points\r\n\r\nThe SDK is used by:\r\n\r\n- **skill-manager**: Managing and validating all skills\r\n- **Skill tool invocations**: Loading skill instructions when invoked\r\n- **Auto-selection**: Finding relevant skills for user queries\r\n- **Workflow execution**: Loading skills for workflow steps\r\n\r\n## Notes\r\n\r\n- This is **infrastructure code**, not a user-facing skill\r\n- Do not invoke this skill directly\r\n- Do not create prompts or commands that reference this skill\r\n- This directory should contain only utility modules for the skill system\r\n",
          "tokens": 913
        }
      }
    },
    "commit-validator": {
      "name": "commit-validator",
      "one_liner": "No description",
      "key_commands": ["/www", "/identity", "/CD", "/capabilities", "/execution_process"],
      "token_count": {
        "minimal": 12,
        "essential": 260,
        "standard": 453,
        "full": 1178
      },
      "levels": {
        "minimal": {
          "content": "**commit-validator**: No description available",
          "tokens": 12
        },
        "essential": {
          "content": "## Skill: commit-validator\n\nCommit Message Validator - Programmatically validates commit messages against the [Conventional Commits](https://www.conventionalcommits.org/) specification.\n\n### Key Steps:\n: Validate Commit Message\r\n\r\nValidate a commit message string against Conventional Commits format:\r\n\r\n**Format**: `<type>(<scope>): <subject>`\r\n\r\n**Types**:\r\n- `feat`: A new feature\r\n- `fix`: A bug fix\r\n- `docs`: Documentation only changes\r\n- `style`: Code style changes (formatting, etc.)\r\n- `refactor`: Code refactoring\r\n- `perf`: Performance improvements\r\n- `test`: Adding or updating tests\r\n- `chore`: Maintenance tasks\r\n- `ci`: CI/CD changes\r\n- `build`: Build system changes\r\n- `revert`: Reverting a previous commit\r\n\r\n**Validation Rules**:\r\n1. Must start with type (required)\r\n2. Scope is optional (in parentheses)\r\n3. Subject is required (after colon and space)\r\n4. Use imperative, present tense (\"add\" not \"added\")\r\n5. Don't capitalize first letter\r\n6. No period at end\r\n7. Can include body and footer (separated by blank line)",
          "tokens": 260
        },
        "standard": {
          "content": "## Skill: commit-validator\n\nCommit Message Validator - Programmatically validates commit messages against the [Conventional Commits](https://www.conventionalcommits.org/) specification.\n\n### Instructions:\n<execution_process>\r\n\r\n### Step 1: Validate Commit Message\r\n\r\nValidate a commit message string against Conventional Commits format:\r\n\r\n**Format**: `<type>(<scope>): <subject>`\r\n\r\n**Types**:\r\n- `feat`: A new feature\r\n- `fix`: A bug fix\r\n- `docs`: Documentation only changes\r\n- `style`: Code style changes (formatting, etc.)\r\n- `refactor`: Code refactoring\r\n- `perf`: Performance improvements\r\n- `test`: Adding or updating tests\r\n- `chore`: Maintenance tasks\r\n- `ci`: CI/CD changes\r\n- `build`: Build system changes\r\n- `revert`: Reverting a previous commit\r\n\r\n**Validation Rules**:\r\n1. Must start with type (required)\r\n2. Scope is optional (in parentheses)\r\n3. Subject is required (after colon and space)\r\n4. Use imperative, present tense (\"add\" not \"added\")\r\n5. Don't capitalize first letter\r\n6. No period at end\r\n7. Can include body and footer (separated by blank line)\r\n</execution_process>\n\n### Example:\n**Implementation**\r\n\r\nUse this regex pattern for validation:\r\n\r\n```javascript\r\nconst CONVENTIONAL_COMMIT_REGEX = /^(feat|fix|docs|style|refactor|perf|test|chore|ci|build|revert)(\\(.+\\))?: .{1,72}/;\r\n\r\nfunction validateCommitMessage(message) {\r\n  const lines = message.trim().split('\\n');\r\n  const header = lines[0];\r\n  \r\n  // Check format\r\n  if (!CONVENTIONAL_COMMIT_REGEX.test(header)) {\r\n    return {\r\n      valid: false,\r\n      error: 'Commit message does not follow Conventional Commits format'\r\n    };\r\n  }\r\n  \r\n  // Check length\r\n  if (header.length > 72) {\r\n    return {\r\n      valid: false,\r\n      error: 'Commit header exceeds 72 characters'\r\n    };\r\n  }\r\n  \r\n  return { valid: true };\r\n}\r\n```",
          "tokens": 453
        },
        "full": {
          "content": "---\r\nname: commit-validator\r\ndescription: Validates commit messages against Conventional Commits specification using programmatic validation. Replaces the git-conventional-commit-messages text file with a tool that provides instant feedback.\r\nallowed-tools: read, grep, bash\r\n---\r\n\r\n<identity>\r\nCommit Message Validator - Programmatically validates commit messages against the [Conventional Commits](https://www.conventionalcommits.org/) specification.\r\n</identity>\r\n\r\n<capabilities>\r\n- Before committing code\r\n- In pre-commit hooks\r\n- In CI/CD pipelines\r\n- During code review\r\n- To enforce team standards\r\n</capabilities>\r\n\r\n<instructions>\r\n<execution_process>\r\n\r\n### Step 1: Validate Commit Message\r\n\r\nValidate a commit message string against Conventional Commits format:\r\n\r\n**Format**: `<type>(<scope>): <subject>`\r\n\r\n**Types**:\r\n- `feat`: A new feature\r\n- `fix`: A bug fix\r\n- `docs`: Documentation only changes\r\n- `style`: Code style changes (formatting, etc.)\r\n- `refactor`: Code refactoring\r\n- `perf`: Performance improvements\r\n- `test`: Adding or updating tests\r\n- `chore`: Maintenance tasks\r\n- `ci`: CI/CD changes\r\n- `build`: Build system changes\r\n- `revert`: Reverting a previous commit\r\n\r\n**Validation Rules**:\r\n1. Must start with type (required)\r\n2. Scope is optional (in parentheses)\r\n3. Subject is required (after colon and space)\r\n4. Use imperative, present tense (\"add\" not \"added\")\r\n5. Don't capitalize first letter\r\n6. No period at end\r\n7. Can include body and footer (separated by blank line)\r\n</execution_process>\r\n</instructions>\r\n\r\n<examples>\r\n<code_example>\r\n**Implementation**\r\n\r\nUse this regex pattern for validation:\r\n\r\n```javascript\r\nconst CONVENTIONAL_COMMIT_REGEX = /^(feat|fix|docs|style|refactor|perf|test|chore|ci|build|revert)(\\(.+\\))?: .{1,72}/;\r\n\r\nfunction validateCommitMessage(message) {\r\n  const lines = message.trim().split('\\n');\r\n  const header = lines[0];\r\n  \r\n  // Check format\r\n  if (!CONVENTIONAL_COMMIT_REGEX.test(header)) {\r\n    return {\r\n      valid: false,\r\n      error: 'Commit message does not follow Conventional Commits format'\r\n    };\r\n  }\r\n  \r\n  // Check length\r\n  if (header.length > 72) {\r\n    return {\r\n      valid: false,\r\n      error: 'Commit header exceeds 72 characters'\r\n    };\r\n  }\r\n  \r\n  return { valid: true };\r\n}\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Valid Examples**:\r\n\r\n```\r\nfeat(auth): add OAuth2 login support\r\nfix(api): resolve timeout issue in user endpoint\r\ndocs(readme): update installation instructions\r\nrefactor(components): extract common button logic\r\ntest(utils): add unit tests for date formatting\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Invalid Examples**:\r\n\r\n```\r\nAdded new feature  # Missing type\r\nfeat:new feature   # Missing space after colon\r\nFEAT: Add feature  # Type should be lowercase\r\nfeat: Added feature  # Should use imperative tense\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**Pre-commit Hook** (`.git/hooks/pre-commit`):\r\n\r\n```bash\r\n#!/bin/bash\r\ncommit_msg=$(git log -1 --pretty=%B)\r\nif ! node .claude/tools/validate-commit.js \"$commit_msg\"; then\r\n  echo \"Commit message validation failed\"\r\n  exit 1\r\nfi\r\n```\r\n</code_example>\r\n\r\n<code_example>\r\n**CI/CD Integration**:\r\n\r\n```yaml\r\n# .github/workflows/validate-commits.yml\r\n- name: Validate commit messages\r\n  run: |\r\n    git log origin/main..HEAD --pretty=%B | while read msg; do\r\n      node .claude/tools/validate-commit.js \"$msg\" || exit 1\r\n    done\r\n```\r\n</code_example>\r\n</examples>\r\n\r\n<examples>\r\n<formatting_example>\r\n**Output Format**\r\n\r\nReturns structured validation result:\r\n\r\n```json\r\n{\r\n  \"valid\": true,\r\n  \"type\": \"feat\",\r\n  \"scope\": \"auth\",\r\n  \"subject\": \"add OAuth2 login support\",\r\n  \"warnings\": []\r\n}\r\n```\r\n\r\nOr for invalid messages:\r\n\r\n```json\r\n{\r\n  \"valid\": false,\r\n  \"error\": \"Commit message does not follow Conventional Commits format\",\r\n  \"suggestions\": [\r\n    \"Use format: <type>(<scope>): <subject>\",\r\n    \"Valid types: feat, fix, docs, style, refactor, perf, test, chore, ci, build, revert\"\r\n  ]\r\n}\r\n```\r\n\r\nOr for invalid messages:\r\n\r\n```json\r\n{\r\n  \"valid\": false,\r\n  \"error\": \"Commit message does not follow Conventional Commits format\",\r\n  \"suggestions\": [\r\n    \"Use format: <type>(<scope>): <subject>\",\r\n    \"Valid types: feat, fix, docs, style, refactor, perf, test, chore, ci, build, revert\"\r\n  ]\r\n}\r\n```\r\n</formatting_example>\r\n</examples>\r\n\r\n<instructions>\r\n<best_practices>\r\n1. **Validate Early**: Check commit messages before pushing\r\n2. **Provide Feedback**: Show clear error messages with suggestions\r\n3. **Enforce in CI**: Add validation to CI/CD pipelines\r\n4. **Team Training**: Educate team on Conventional Commits format\r\n5. **Tool Integration**: Integrate with Git hooks and IDEs\r\n</best_practices>\r\n</instructions>\r\n\r\n",
          "tokens": 1178
        }
      }
    }
  }
}
