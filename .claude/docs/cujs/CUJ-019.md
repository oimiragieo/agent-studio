# CUJ-019: Performance Optimization

## User Goal

Optimize performance of system or component.

## Trigger

- `/performance --target api/users`
- "Optimize performance"
- "Performance tuning"

## Workflow

**Execution Mode**: `performance-flow.yaml`

### Baseline Measurement (Step 0.5)

- Performance Engineer captures baseline metrics before optimization
- Measures response time, throughput, resource utilization
- Stores baseline in `baseline-metrics.json` artifact
- Used for before/after comparison

### Step 0: Planning Phase

- Planner creates optimization plan
- Analyzes performance requirements and targets
- Coordinates with Performance Engineer for analysis strategy
- Defines optimization goals and success criteria
- Outputs: `plan-{{workflow_id}}.md`, `plan-{{workflow_id}}.json`

### Step 0.1: Plan Rating Gate

- Agent: orchestrator
- Type: validation
- Skill: response-rater
- Validates plan quality (minimum score: 7/10)
- Rubric: completeness, feasibility, risk mitigation, agent coverage, integration
- If score < 7: Return to Planner with feedback
- If score >= 7: Proceed to execution
- Records rating in `.claude/context/runs/<run_id>/plans/<plan_id>-rating.json`

### Step 1: Performance Analysis

- Performance Engineer profiles system
- Identifies bottlenecks
- Measures baseline

### Step 2: Optimization Planning

- Architect reviews strategy
- Plans optimizations
- Validates approach

### Step 3: Implementation

- Developer implements optimizations
- Applies performance improvements
- Validates changes

### Step 4: Validation

- QA validates improvements
- Measures performance gains
- Confirms optimization

### Step 4.5: Publish Artifacts

- **Agent**: orchestrator
- **Skill**: artifact-publisher
- **Condition**: `validation_status == 'pass'`
- **Policy**: auto-on-pass
- **Inputs**: All validated artifacts from workflow (performance analysis report, optimization plan, optimized code, performance metrics)
- **Outputs**: Published artifacts in project feed
- **Description**: Publish all validated performance optimization artifacts to project feed for cross-platform visibility. Includes baseline measurements, bottleneck analysis, optimization implementations, and before/after performance comparisons.

## Agents Used

- Performance Engineer → Architect → Developer → QA

## Skills Used

- Performance profiling tools
- `response-rater` - Plan quality validation

## Expected Outputs

- Performance analysis report
- Optimization plan
- Optimized code
- Performance metrics

## Success Criteria

| Criterion              | Measurement                     | Target                                                                            |
| ---------------------- | ------------------------------- | --------------------------------------------------------------------------------- |
| Bottlenecks identified | Artifact exists                 | Bottlenecks documented in `bottleneck-report.json`                                |
| Plan rating            | response-rater skill score      | >= 7/10 (recorded in `.claude/context/runs/<run_id>/plans/<plan_id>-rating.json`) |
| Rating recorded        | Rating file exists in run state | File present at `.claude/context/runs/<run_id>/plans/<plan_id>-rating.json`       |
| Optimizations applied  | Artifact exists                 | Optimizations listed in `dev-manifest.json`                                       |
| Performance improved   | Comparison validation           | Performance gains validated in `performance-comparison.json` by gate file         |
| Metrics validated      | Benchmark results               | Validated metrics in `benchmark-results.json`                                     |

## Example Prompts

```
/performance --target api/users
"Optimize the authentication flow"
"Performance tuning for the dashboard"
```

## Error Recovery

### Retry Strategy

- **Max Retries**: 3 attempts per step
- **Backoff**: Exponential (1s, 2s, 4s)
- **Retry Triggers**: Transient failures, timeouts, rate limits

### Rollback Procedures

1. **Partial Completion**: Save checkpoint to `.claude/context/runs/{{run_id}}/checkpoint.json`
2. **Failed Validation**: Return to previous passing gate (restore performance baseline if optimization fails)
3. **Critical Failure**: Escalate to human with full context

### Fallback Options

- **Alternative Agent**: If primary agent fails 3x, route to backup agent
  - Performance-Engineer → Developer (optimization implementation fallback)
  - Architect → Performance-Engineer (strategy fallback)
  - QA → Performance-Engineer (validation fallback)
- **Manual Override**: User can force-proceed with documented risks
- **Graceful Degradation**: Apply partial optimizations with performance impact documented

### Recovery Artifacts

- Error log: `.claude/context/runs/{{run_id}}/errors.log`
- Recovery state: `.claude/context/runs/{{run_id}}/recovery-state.json`
- Checkpoint: `.claude/context/runs/{{run_id}}/checkpoint.json`
- Baseline metrics: `.claude/context/runs/{{run_id}}/baseline-metrics.json`
