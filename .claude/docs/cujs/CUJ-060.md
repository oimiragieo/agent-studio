# CUJ-060: Cross-Platform CUJ Testing

## User Goal

Validate that Customer User Journeys (CUJs) work consistently across Claude Code, Cursor, and Factory Droid platforms.

## Trigger

- "Test CUJ across platforms"
- "Validate cross-platform CUJ consistency"
- "Run CUJ on all platforms"
- "Test platform compatibility"

## Workflow

**Execution Mode**: `workflow`

### Step 0: Planning Phase

- **Agent**: Planner
- **Input**: Cross-platform testing requirements
- **Output**: Test execution plan (`plan-{id}.json`)

### Step 0.1: Plan Rating Gate

- **Agent**: Orchestrator
- **Skill**: response-rater
- **Minimum Score**: 7/10

### Step 1: Platform Environment Setup

- **Agent**: DevOps
- **Actions**:
  - Configure Claude Code environment
  - Configure Cursor environment
  - Configure Factory Droid environment
  - Verify platform-specific configurations
- **Output**: Platform configs (`platform-configs-{id}.json`)

### Step 2: CUJ Selection and Preparation

- **Agent**: QA
- **Actions**:
  - Select CUJs for cross-platform testing
  - Prepare test data for each CUJ
  - Define success criteria per platform
  - Create test execution matrix
- **Output**: Test matrix (`cuj-test-matrix-{id}.json`)

### Step 3: Claude Code Execution

- **Agent**: QA
- **Platform**: Claude Code
- **Actions**:
  - Execute selected CUJs
  - Capture execution logs
  - Record artifacts produced
  - Measure performance metrics
- **Output**: Claude Code results (`claude-code-results-{id}.json`)

### Step 4: Cursor Execution

- **Agent**: Cursor-Validator
- **Platform**: Cursor
- **Actions**:
  - Execute same CUJs
  - Capture execution logs
  - Record artifacts produced
  - Measure performance metrics
- **Output**: Cursor results (`cursor-results-{id}.json`)

### Step 5: Factory Droid Execution

- **Agent**: QA
- **Platform**: Factory Droid
- **Actions**:
  - Execute same CUJs
  - Capture execution logs
  - Record artifacts produced
  - Measure performance metrics
- **Output**: Factory results (`factory-results-{id}.json`)

### Step 6: Cross-Platform Comparison

- **Agent**: Analyst
- **Actions**:
  - Compare artifacts across platforms
  - Analyze execution time differences
  - Identify platform-specific issues
  - Document compatibility gaps
- **Output**: Comparison report (`cross-platform-comparison-{id}.json`)

### Step 7: Context Synchronization Testing

- **Agent**: Developer
- **Skill**: context-bridge
- **Actions**:
  - Test context sync from Claude Code to Cursor
  - Test context sync from Cursor to Factory
  - Test bidirectional sync
  - Verify artifact consistency
- **Output**: Sync validation report (`context-sync-results-{id}.json`)

### Step 8: Issue Resolution

- **Agent**: Developer
- **Actions**:
  - Fix platform-specific issues
  - Implement platform compatibility shims
  - Update platform configurations
  - Re-test failed CUJs
- **Output**: Updated code and configs

### Step 9: Final Validation

- **Agent**: Code-Reviewer
- **Actions**:
  - Review platform compatibility fixes
  - Validate CUJ consistency
  - Approve cross-platform execution
  - Document platform-specific notes

## Agents Used

- Planner (test strategy)
- DevOps (environment setup)
- QA (test execution, validation)
- Cursor-Validator (Cursor-specific testing)
- Analyst (cross-platform comparison)
- Developer (issue resolution)
- Code-Reviewer (final validation)

## Skills Used

- `context-bridge` - Cross-platform context synchronization
- `plan-generator` - Test planning
- `response-rater` - Plan validation
- `artifact-publisher` - Artifact verification

## Expected Outputs

- Platform configs: `.claude/context/artifacts/platform-configs-{id}.json`
- Test matrix: `.claude/context/artifacts/cuj-test-matrix-{id}.json`
- Claude Code results: `.claude/context/artifacts/claude-code-results-{id}.json`
- Cursor results: `.claude/context/artifacts/cursor-results-{id}.json`
- Factory results: `.claude/context/artifacts/factory-results-{id}.json`
- Comparison report: `.claude/context/artifacts/cross-platform-comparison-{id}.json`
- Sync validation: `.claude/context/artifacts/context-sync-results-{id}.json`

## Success Criteria

| Criterion                          | Measurement                | Target                                        |
| ---------------------------------- | -------------------------- | --------------------------------------------- |
| All platforms configured           | Platform config validation | Claude Code, Cursor, Factory Droid configured |
| CUJs execute on all platforms      | Execution validation       | Same CUJs successful on all platforms         |
| Artifacts functionally equivalent  | Artifact comparison        | Functionally equivalent outputs               |
| Execution time variance acceptable | Performance comparison     | < 20% variance across platforms               |
| Context sync bidirectional         | Sync validation            | Claude ↔ Cursor ↔ Factory sync works          |
| No platform-specific failures      | Failure analysis           | All CUJs pass on all platforms                |
| Compatibility issues resolved      | Issue resolution           | Issues documented and fixed                   |
| Test suite created                 | Test suite validation      | Cross-platform test suite complete            |

## Test Matrix Example

```json
{
  "cujs_tested": [
    "CUJ-001: Quick Code Fix",
    "CUJ-004: New Feature Planning",
    "CUJ-008: Full-Stack Feature",
    "CUJ-026: Multi-Phase Project"
  ],
  "platforms": ["claude-code", "cursor", "factory-droid"],
  "test_criteria": {
    "artifact_equivalence": true,
    "performance_threshold_ms": 1000,
    "context_sync": true,
    "error_tolerance": 0
  }
}
```

## Platform-Specific Testing

### Claude Code

- Test MCP integrations
- Validate artifact generation
- Test skill invocations
- Verify context management

### Cursor

- Test IDE integration
- Validate file editing
- Test context sync from Claude Code
- Verify Cursor-specific commands

### Factory Droid

- Test automation workflows
- Validate batch processing
- Test context sync from Cursor
- Verify Droid-specific features

## Context Synchronization Tests

### Test 1: Claude Code → Cursor

```
1. Execute CUJ-004 in Claude Code
2. Generate plan-{id}.json artifact
3. Use context-bridge skill to sync to Cursor
4. Verify Cursor has access to plan-{id}.json
5. Continue execution in Cursor
```

### Test 2: Cursor → Factory Droid

```
1. Execute CUJ-008 in Cursor
2. Generate implementation artifacts
3. Use context-bridge skill to sync to Factory
4. Verify Factory has access to all artifacts
5. Continue execution in Factory
```

### Test 3: Bidirectional Sync

```
1. Start in Claude Code, create plan
2. Sync to Cursor, implement feature
3. Sync back to Claude Code, run tests
4. Verify all artifacts available in both platforms
```

## Performance Comparison Metrics

**Metrics to Compare**:

- CUJ execution time
- Artifact generation time
- Context loading time
- Skill invocation time
- Platform-specific overhead

**Acceptable Variance**:

- Execution time: ±20%
- Artifact size: ±10%
- Context sync time: < 5 seconds

## Test Scenarios

### Scenario 1: Full CUJ Execution Across All Platforms

```
1. Select CUJ-008 (Full-Stack Feature)
2. Execute in Claude Code, capture results
3. Execute in Cursor, capture results
4. Execute in Factory Droid, capture results
5. Compare artifacts and performance
Expected: Functionally equivalent artifacts, <20% time variance
```

### Scenario 2: Context Sync During Multi-Platform Workflow

```
1. Start CUJ-026 in Claude Code (planning phase)
2. Sync to Cursor for implementation
3. Sync to Factory for deployment
4. Verify context integrity at each transition
Expected: All artifacts accessible, no data loss
```

### Scenario 3: Platform-Specific Feature Testing

```
1. Test MCP-only features in Claude Code
2. Test IDE integrations in Cursor
3. Test automation features in Factory Droid
4. Document platform-specific capabilities
Expected: Platform-specific features documented, no conflicts
```

## Example Prompts

```
"Run CUJ-004 across all platforms and compare results"
"Test context synchronization between Claude Code and Cursor"
"Validate that CUJ-008 produces equivalent artifacts on all platforms"
"Execute cross-platform test suite for all core CUJs"
```

## Related Documentation

- [context-bridge Skill](../../skills/context-bridge/SKILL.md)
- [artifact-publisher Skill](../../skills/artifact-publisher/SKILL.md)
- [Cursor Setup Guide](../../docs/setup-guides/CURSOR_SETUP_GUIDE.md)
- [Factory Droid Setup Guide](../../docs/setup-guides/FACTORY_SETUP_GUIDE.md)
- [CUJ Index](./CUJ-INDEX.md)

## Platform Compatibility Matrix

| Feature               | Claude Code | Cursor     | Factory Droid    |
| --------------------- | ----------- | ---------- | ---------------- |
| MCP Integrations      | ✅ Full     | ⚠️ Partial | ❌ Not Supported |
| Skill Invocations     | ✅ Full     | ✅ Full    | ✅ Full          |
| Context Bridge        | ✅ Full     | ✅ Full    | ✅ Full          |
| Artifact Publishing   | ✅ Full     | ✅ Full    | ✅ Full          |
| IDE Integration       | ❌ N/A      | ✅ Full    | ❌ N/A           |
| Batch Automation      | ⚠️ Partial  | ⚠️ Partial | ✅ Full          |
| Multi-Agent Workflows | ✅ Full     | ✅ Full    | ✅ Full          |

## Error Recovery

### Retry Strategy

- **Max Retries**: 3 attempts per step
- **Backoff**: Exponential (1s, 2s, 4s)
- **Retry Triggers**: Transient failures, timeouts, rate limits

### Rollback Procedures

1. **Partial Completion**: Save checkpoint to `.claude/context/runs/{{run_id}}/checkpoint.json`
2. **Failed Validation**: Return to previous passing gate
3. **Critical Failure**: Escalate to human with full context

### Fallback Options

- **Alternative Agent**: If primary agent fails 3x, route to backup agent
  - Cursor-Validator → QA (Cursor testing fallback)
  - Developer → Analyst (issue resolution fallback)
  - Code-Reviewer → QA (validation fallback)
- **Manual Override**: User can force-proceed with documented risks
- **Graceful Degradation**: Continue with reduced platform coverage (skip problematic platforms)

### Recovery Artifacts

- Error log: `.claude/context/runs/{{run_id}}/errors.log`
- Recovery state: `.claude/context/runs/{{run_id}}/recovery-state.json`
- Checkpoint: `.claude/context/runs/{{run_id}}/checkpoint.json`
- Platform state: `.claude/context/runs/{{run_id}}/platform-state.json`

## Implementation Checklist

- [ ] Platform environments configured
- [ ] Test matrix defined
- [ ] CUJs selected for cross-platform testing
- [ ] Execution scripts created for each platform
- [ ] Context sync tests implemented
- [ ] Performance comparison metrics defined
- [ ] Compatibility issues documented
- [ ] Platform-specific features tested
- [ ] Cross-platform test suite validated
- [ ] Documentation updated
