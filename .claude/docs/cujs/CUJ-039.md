# CUJ-039: Cross-Agent Validation

## User Goal

Test cross-agent validation protocol to ensure agents can validate each other's work, resolve conflicts, and enforce quality gates with multiple validators.

## Trigger

- "Test cross-agent validation"
- "Validate conflict resolution"
- "Test quality gates"

## Workflow

**Execution Mode**: `workflow`

### Step 0: Planning Phase

- Planner creates plan with cross-agent validation scenarios
- Identifies validation checkpoints
- Defines conflict resolution strategy

### Step 0.1: Plan Rating Gate

- Agent: orchestrator
- Type: validation
- Skill: response-rater
- Validates plan quality (minimum score: 7/10)
- Rubric: completeness, feasibility, risk mitigation, agent coverage, integration
- If score < 7: Return to Planner with feedback
- If score >= 7: Proceed to execution
- Records rating in `.claude/context/runtime/runs/<run_id>/plans/<plan_id>-rating.json`

### Step 1: Primary Agent Output

- Primary agent (e.g., PM) creates output artifact
- Artifact saved to `.claude/context/artifacts/`
- Primary validation (schema) passes

### Step 2: Cross-Agent Validation

- Validator agents (e.g., Analyst, Architect) review output
- Each validator checks assigned criteria:
  - Analyst validates: technical_feasibility, market_assumptions
  - Architect validates: technical_constraints, scalability_requirements
- Validators provide validation scores (0.0-1.0)
- Validation results saved to gate file

### Step 3: Consensus Calculation

- System calculates consensus:
  - 2/3+ validators agree: Consensus issue (route to Developer)
  - 1/3 validator finds issue: Low-priority warning
  - All disagree: Flag for human review
- Consensus issues categorized by severity

### Step 4: Conflict Resolution

- If validators disagree:
  - Check conflict resolution matrix
  - Apply resolution method (consensus_building, authority, etc.)
  - Facilitator agent (e.g., Analyst) coordinates resolution
  - Max iterations: 3
  - Document resolution in reasoning file

### Step 5: Quality Gate Enforcement

- Quality gates evaluated:
  - Threshold: 0.8 for Analyst validation
  - Threshold: 0.7 for Architect validation
- If thresholds not met:
  - Route back to primary agent for correction
  - Re-validate after correction
  - Track retry attempts

### Step 6: Validation Report

- Generate validation report with:
  - Consensus issues (2/3+ agreement)
  - Disagreements (1/3 or all disagree)
  - Quality gate results
  - Conflict resolution outcomes
  - Recommendations

## Agents Used

- Planner (planning)
- Primary Agent (e.g., PM) - Creates output
- Validator Agents (e.g., Analyst, Architect) - Validate output
- Facilitator Agent (e.g., Analyst) - Resolves conflicts
- Developer (fixes consensus issues)

## Skills Used

- `conflict-resolution` - Multi-agent conflict resolution protocol
- `response-rater` - Plan quality validation

## Capabilities/Tools Used

- Cross-agent validation (orchestrator capability)
- Consensus calculation (model-orchestrator capability)
- Quality gate enforcement (workflow gate system)

## Expected Outputs

- Primary agent output artifact
- Validation results from each validator
- Consensus calculation results
- Conflict resolution documentation
- Quality gate evaluation
- Validation report

## Success Criteria

| Criterion                       | Measurement                     | Target                                                                                    |
| ------------------------------- | ------------------------------- | ----------------------------------------------------------------------------------------- |
| Cross-agent validation executes | Validation execution logs       | Validation process completes correctly                                                    |
| Plan rating                     | response-rater skill score      | >= 7/10 (recorded in `.claude/context/runtime/runs/<run_id>/plans/<plan_id>-rating.json`) |
| Rating recorded                 | Rating file exists in run state | File present at `.claude/context/runtime/runs/<run_id>/plans/<plan_id>-rating.json`       |
| Validators provide scores       | Validation results              | Scores (0.0-1.0) for assigned criteria                                                    |
| Consensus calculated            | Consensus calculation           | 2/3+ agreement correctly identified                                                       |
| Conflicts resolved              | Resolution matrix application   | Conflicts resolved per matrix rules                                                       |
| Quality gates enforced          | Threshold validation            | Gates enforced with defined thresholds                                                    |
| Consensus issues routed         | Issue routing                   | Routed to Developer for resolution                                                        |
| Disagreements flagged           | Disagreement detection          | Appropriately flagged for review                                                          |
| Max iterations enforced         | Iteration counter               | Maximum 3 iterations enforced                                                             |
| Validation report generated     | Report artifact                 | Complete validation report created                                                        |

## Example Prompts

```
"Test cross-agent validation for PRD"
"Validate conflict resolution between PM and Architect"
"Test quality gates with multiple validators"
```

## Related Documentation

- [agent-coordination.md](../../instructions/agent-coordination.md) - Cross-Agent Validation Protocol
- [Model-Orchestrator Agent](../../agents/model-orchestrator.md) - Consensus Calculation
- [WORKFLOW-GUIDE.md](../../workflows/WORKFLOW-GUIDE.md) - Validation section

## Conflict Resolution Matrix

### Technical Feasibility Conflict

- **Participants**: PM, Architect
- **Resolution**: Architect has final authority
- **Escalation**: Create technical spike

### User Requirements Conflict

- **Participants**: Analyst, PM, UX Expert
- **Resolution**: Majority vote with user research
- **Escalation**: Additional user interviews

### Implementation Approach Conflict

- **Participants**: Architect, Developer
- **Resolution**: Developer implementation preference
- **Escalation**: Prototype both approaches

## Quality Gate Configuration

### Example Workflow Configuration

```yaml
validation:
  schema: .claude/schemas/prd.schema.json
  gate: .claude/context/history/gates/{{workflow_id}}/02-pm.json
  cross_agent_validators:
    - agent: analyst
      validates: ['technical_feasibility', 'market_assumptions']
      threshold: 0.8
    - agent: architect
      validates: ['technical_constraints', 'scalability_requirements']
      threshold: 0.7
  conflict_resolution:
    method: 'consensus_building'
    facilitator: 'analyst'
    max_iterations: 3
```

## Test Scenarios

### Scenario 1: Consensus (2/3+ Agreement)

- Analyst finds issue (score: 0.6)
- Architect finds same issue (score: 0.5)
- Codex Validator finds same issue (score: 0.7)
- Consensus: 3/3 agree → Route to Developer

### Scenario 2: Disagreement (1/3 Finding)

- Analyst finds issue (score: 0.6)
- Architect finds no issue (score: 0.9)
- Codex Validator finds no issue (score: 0.8)
- Consensus: 1/3 finding → Log as low-priority warning

### Scenario 3: Complete Disagreement

- Analyst finds issue A (score: 0.6)
- Architect finds issue B (score: 0.5)
- Codex Validator finds issue C (score: 0.7)
- Consensus: All disagree → Flag for human review

### Scenario 4: Conflict Resolution

- PM and Architect disagree on technical approach
- Facilitator (Analyst) coordinates consensus building
- Resolution reached after 2 iterations
- Documented in reasoning file
