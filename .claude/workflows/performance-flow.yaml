name: Performance Optimization Workflow
description: Performance profiling, optimization, and load testing initiatives
type: performance
project_type: optimization

# Error Recovery Configuration
recovery:
  enabled: true
  checkpoint_dir: ".claude/context/runs/{{run_id}}/checkpoints"

retry_config:
  max_attempts: 3
  backoff_strategy: exponential
  initial_delay_ms: 1000
  retryable_errors: [timeout, network_error, rate_limit]

fallback_agents:
  developer: [code-reviewer, qa]
  architect: [developer, security-architect]
  qa: [developer, code-reviewer]
  planner: [architect, pm]
  performance-engineer: [developer, architect]
  code-reviewer: [developer, performance-engineer]
  devops: [architect, developer]
  technical-writer: [developer, pm]

# NOTE: trigger_keywords here are for documentation only.
# The actual workflow selection uses keywords from .claude/config.yaml workflow_selection section.
# See .claude/config.yaml for the authoritative keyword list used by the routing system.
trigger_keywords:
  - "performance"
  - "optimize"
  - "profiling"
  - "benchmark"
  - "load test"
  - "slow"
  - "latency"

steps:
  - step: 0
    name: "Planning Phase"
    agent: planner
    inputs:
      - target_system
      - performance_requirements
      - current_metrics
    outputs:
      - plan-{{workflow_id}}.md
      - plan-{{workflow_id}}.json
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/00-planner.json
    validation:
      schema: .claude/schemas/plan.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/00-planner.json
    description: |
      Plan performance optimization workflow:
      - Analyze performance requirements
      - Coordinate optimization strategy
      - Create structured improvement plan

  - step: 0.5
    name: "Baseline Measurement"
    agent: performance-engineer
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - target_system
      - performance_requirements
    outputs:
      - baseline-metrics.json
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/00.5-performance-engineer.json
    validation:
      schema: .claude/schemas/baseline-metrics.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/00.5-performance-engineer.json
    description: |
      Capture baseline performance metrics before optimization:
      - Response time measurements
      - Throughput metrics
      - Resource utilization (CPU, memory, disk, network)
      - Database query performance
      - Error rates
      - Store baseline in artifact for comparison

  - step: 1
    name: "Performance Analysis"
    agent: performance-engineer
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - baseline-metrics.json (from step 0.5)
      - target_system
      - performance_requirements
      - current_metrics
    outputs:
      - performance-analysis.json
      - bottleneck-report.json
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/01-performance-engineer.json
    validation:
      schema: .claude/schemas/performance-metrics.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/01-performance-engineer.json
    description: |
      Comprehensive performance analysis:
      - Profiling and bottleneck identification
      - Resource utilization assessment
      - Latency hotspots
      - Memory and CPU analysis
      - Database query performance
      - Compare against baseline metrics

  - step: 2
    name: "Architecture Review"
    agent: architect
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - performance-analysis.json (from step 1)
      - bottleneck-report.json (from step 1)
    outputs:
      - optimization-architecture.json
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/02-architect.json
    validation:
      schema: .claude/schemas/system_architecture.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/02-architect.json
    description: |
      Architectural optimization planning:
      - Caching strategy design
      - Load balancing recommendations
      - Async processing patterns
      - Database optimization strategies
      - CDN and edge computing

  - step: 3
    name: "Implementation"
    agent: developer
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - optimization-architecture.json (from step 2)
      - performance-analysis.json (from step 1)
    outputs:
      - dev-manifest.json
      - code-artifacts
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/03-developer.json
    validation:
      schema: .claude/schemas/artifact_manifest.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/03-developer.json
    description: |
      Optimization implementation:
      - Performance-critical code changes
      - Caching implementation
      - Query optimization
      - Resource pooling
      - Async refactoring

  - step: 4
    name: "Code Review"
    agent: code-reviewer
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - dev-manifest.json (from step 3)
      - optimization-architecture.json (from step 2)
      - performance-analysis.json (from step 1)
    outputs:
      - code-review-{{workflow_id}}.json
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/04-code-reviewer.json
    validation:
      schema: .claude/schemas/code-review.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/04-code-reviewer.json
    on_failure: "Return to implementation step with feedback"
    description: |
      Review performance optimization implementation for quality, security, and codebase impact:
      - Verify optimization techniques are correctly applied
      - Check for potential side effects or regressions
      - Review caching strategies and configurations
      - Validate async/await patterns and concurrency
      - Ensure database query optimizations are safe

  - step: 5
    name: "Performance Validation"
    agent: qa
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - baseline-metrics.json (from step 0.5)
      - dev-manifest.json (from step 3)
      - code-review-{{workflow_id}}.json (from step 4)
      - performance-analysis.json (from step 1)
    outputs:
      - benchmark-results.json
      - load-test-report.json
      - performance-comparison.json
    validation:
      schema: .claude/schemas/test-results.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/05-qa.json
    description: |
      Performance validation:
      - Benchmark comparison (before/after using baseline-metrics.json)
      - Load testing
      - Stress testing
      - Regression verification
      - SLA compliance check
      - Generate performance-comparison.json showing improvements

  - step: 5.5
    name: "Publish Artifacts"
    agent: orchestrator
    skill: artifact-publisher
    condition: "validation_status == 'pass'"
    inputs:
      - artifact-registry.json
    policy: auto-on-pass
    retry:
      max_attempts: 3
      on_failure: log_and_continue

completion_criteria:
  - Performance improvements measured and documented
  - Benchmarks show improvement over baseline
  - Load tests pass with target thresholds
  - No regression in functionality
