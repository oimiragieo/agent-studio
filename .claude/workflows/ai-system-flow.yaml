name: AI/LLM System Development Workflow
description: AI and LLM system design, RAG implementation, and intelligent feature development
type: ai-system
project_type: ai

# Error Recovery Configuration
recovery:
  enabled: true
  checkpoint_dir: '.claude/context/runtime/runs/{{run_id}}/checkpoints'

retry_config:
  max_attempts: 3
  backoff_strategy: exponential
  initial_delay_ms: 1000
  retryable_errors: [timeout, network_error, rate_limit]

fallback_agents:
  developer: [code-reviewer, qa]
  architect: [developer, security-architect]
  qa: [developer, code-reviewer]
  planner: [architect, pm]
  llm-architect: [architect, developer]
  pm: [analyst, llm-architect]
  database-architect: [architect, developer]
  security-architect: [compliance-auditor, code-reviewer]
  code-reviewer: [developer, security-architect]
  technical-writer: [developer, pm]

# NOTE: trigger_keywords here are for documentation only.
# The actual workflow selection uses keywords from .claude/config.yaml workflow_selection section.
# See .claude/config.yaml for the authoritative keyword list used by the routing system.
trigger_keywords:
  - 'ai system'
  - 'llm'
  - 'rag'
  - 'embeddings'
  - 'chatbot'
  - 'ai feature'
  - 'machine learning'
  - 'vector database'

steps:
  - step: 0
    name: 'Planning Phase'
    agent: planner
    inputs:
      - ai_requirements
      - use_cases
      - constraints
    outputs:
      - plan-{{workflow_id}}.md
      - plan-{{workflow_id}}.json
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/00-planner.json
    validation:
      schema: .claude/schemas/plan.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/00-planner.json
    description: |
      Plan AI/LLM system development:
      - Analyze AI requirements and use cases
      - Coordinate with AI specialists
      - Create structured development plan

  - step: 0.1
    name: 'Plan Rating Gate'
    agent: orchestrator
    type: validation
    skill: response-rater
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
    outputs:
      - .claude/context/runtime/runs/{{run_id}}/plans/{{plan_id}}-rating.json
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/00.1-orchestrator.json
    validation:
      minimum_score: 7
      rubric_file: .claude/context/artifacts/standard-plan-rubric.json
      schema: .claude/schemas/plan-rating.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/00.1-orchestrator.json
    retry:
      max_attempts: 3
      on_failure: escalate_to_human
    description: |
      Rate plan quality using response-rater skill.
      - Rubric: completeness, feasibility, risk mitigation, agent coverage, integration
      - Minimum passing score: 7/10
      - If score < 7: Return to Planner with feedback, request improvements, re-rate until passing
      - If score >= 7: Proceed with workflow execution
      - Log rating in reasoning file and artifact metadata
      - Never execute an unrated plan - this is a hard requirement

  - step: 1
    name: 'Model Strategy'
    agent: model-orchestrator
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - ai_requirements
      - use_cases
      - constraints
    outputs:
      - model-strategy.json
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/01-model-orchestrator.json
    validation:
      schema: .claude/schemas/model-strategy.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/01-model-orchestrator.json
    description: |
      Multi-model strategy planning:
      - Model selection for different tasks
      - Cost/performance trade-offs
      - Fallback strategies
      - Provider diversification
      - Rate limiting considerations

  - step: 2
    name: 'LLM Architecture Design'
    agent: llm-architect
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - model-strategy.json (from step 1)
      - ai_requirements
    outputs:
      - llm-architecture.json
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/02-llm-architect.json
    validation:
      schema: .claude/schemas/system_architecture.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/02-llm-architect.json
    description: |
      LLM system architecture:
      - RAG pipeline design
      - Embedding strategy
      - Vector database selection
      - Prompt engineering patterns
      - Context management
      - Guardrails and safety

  - step: 3
    name: 'API Design'
    agent: api-designer
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - llm-architecture.json (from step 2)
      - model-strategy.json (from step 1)
    outputs:
      - api-specification.json
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/03-api-designer.json
    validation:
      schema: .claude/schemas/api-design.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/03-api-designer.json
    description: |
      AI API design:
      - Streaming endpoint patterns
      - Request/response schemas
      - Error handling for AI failures
      - Rate limiting and quotas
      - Webhook integrations

  - step: 4
    name: 'Implementation'
    agent: developer
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - llm-architecture.json (from step 2)
      - api-specification.json (from step 3)
    outputs:
      - dev-manifest.json
      - code-artifacts
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/04-developer.json
    validation:
      schema: .claude/schemas/artifact_manifest.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/04-developer.json
    description: |
      AI system implementation:
      - LLM integration code
      - RAG pipeline implementation
      - Embedding generation
      - Vector store integration
      - Prompt templates

  - step: 5
    name: 'Code Review'
    agent: code-reviewer
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - dev-manifest.json (from step 4)
      - llm-architecture.json (from step 2)
      - api-specification.json (from step 3)
    outputs:
      - code-review-{{workflow_id}}.json
      - reasoning: .claude/context/history/reasoning/{{workflow_id}}/05-code-reviewer.json
    validation:
      schema: .claude/schemas/code-review.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/05-code-reviewer.json
    on_failure: 'Return to implementation step with feedback'
    description: |
      Review AI/LLM implementation for quality, security, and codebase impact:
      - Verify prompt engineering best practices
      - Check API error handling and retry logic
      - Review data privacy and security controls
      - Validate RAG pipeline implementation
      - Ensure proper token usage monitoring

  - step: 6
    name: 'AI Quality Validation'
    agent: qa
    inputs:
      - plan-{{workflow_id}}.json (from step 0)
      - dev-manifest.json (from step 4)
      - code-review-{{workflow_id}}.json (from step 5)
      - llm-architecture.json (from step 2)
    outputs:
      - ai-test-results.json
      - quality-report.json
    validation:
      schema: .claude/schemas/ai-quality-validation.schema.json
      gate: .claude/context/history/gates/{{workflow_id}}/06-qa.json
    secondary_outputs:
      - artifact: quality-report.json
        schema: .claude/schemas/quality-report.schema.json
    description: |
      AI-specific validation:
      - Prompt testing
      - Response quality assessment
      - Hallucination detection
      - Edge case handling
      - Performance benchmarks

  - step: 6.5
    name: 'Publish Artifacts'
    agent: orchestrator
    skill: artifact-publisher
    condition: "validation_status == 'pass'"
    inputs:
      - artifact-registry.json
    policy: auto-on-pass
    validation:
      schema: .claude/schemas/artifact-registry.schema.json
    retry:
      max_attempts: 3
      on_failure: log_and_continue

completion_criteria:
  - LLM integration functional
  - RAG pipeline returns relevant results
  - API endpoints operational
  - Quality thresholds met
  - Safety guardrails validated
